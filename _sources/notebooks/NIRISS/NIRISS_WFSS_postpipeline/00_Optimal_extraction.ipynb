{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WFSS Spectra Part 0: Optimal Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use case:** optimal extraction of grism spectra; redshift measurement; emission-line maps.  Simplified version of [JDox Science Use Case # 33](https://jwst-docs.stsci.edu/near-infrared-imager-and-slitless-spectrograph/niriss-example-science-programs/niriss-wfss-with-nircam-parallel-imaging-of-galaxies-in-lensing-clusters).<br>\n",
    "**Data:** JWST simulated NIRISS images from [MIRAGE](https://jwst-docs.stsci.edu/jwst-other-tools/mirage-data-simulator), run through the [JWST calibration pipeline](https://jwst-pipeline.readthedocs.io/en/latest/); galaxy cluster.<br>\n",
    "**Tools:**  specutils, astropy, pandas, emcee, lmfit, corner, h5py.<br>\n",
    "**Cross-intrument:** NIRSpec <br>\n",
    "**Documentation:** This notebook is part of a STScI's larger [post-pipeline Data Analysis Tools Ecosystem](https://jwst-docs.stsci.edu/jwst-post-pipeline-data-analysis).<br>\n",
    "\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This notebook is 1 of 4 in a set focusing on NIRISS WFSS data:\n",
    "    1. 1D optimal extraction since the JWST pipeline only provides a box extraction.  Optimal extraction improves S/N of spectra for faint sources.\n",
    "    2. Combine and normalize 1D spectra.\n",
    "    3. Cross correlate galaxy with template to get redshift.\n",
    "    4. Spatially resolved emission line map.\n",
    "\n",
    "This notebook will start with [post-pipeline](https://jwst-docs.stsci.edu/jwst-data-reduction-pipeline) products of NIRISS WFSS, 2D rectified spectra, from spec level3.\n",
    "\n",
    "Optimal extraction requires source morphology along the cross-dispersion direction, which will be retrieved from direct images taken along with WFSS observations.  Morphology along dispersion direction is also essential to infer the spectral resolution, which will be obtained using template fitting to get redshift and stellar population in notebook #3 of this set.\n",
    "\n",
    "**Note:** We here assume reduction of the 2D rectified spectrum has been performed at a decent level, i.e. there is no contaminating flux from other sources on the target 2D spectrum, and that background is already subtracted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from scipy.ndimage import rotate\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "from astropy.io import fits\n",
    "import astropy.units as u\n",
    "import astropy.wcs as wcs\n",
    "from astropy.io import ascii\n",
    "\n",
    "from specutils import Spectrum1D\n",
    "from astropy.nddata import StdDevUncertainty\n",
    "\n",
    "import specutils\n",
    "print('specutils', specutils.__version__)\n",
    "\n",
    "import astropy\n",
    "print('astropy', astropy.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The version should be \n",
    "- specutils 1.11.0\n",
    "- astropy 5.3.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "mpl.rcParams['savefig.dpi'] = 80\n",
    "mpl.rcParams['figure.dpi'] = 80"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.Download and load data:\n",
    "These include pipeline processed data for NIRISS, as well as photometric catalog from image step3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('./pipeline_products'):\n",
    "    import zipfile\n",
    "    import urllib.request\n",
    "    boxlink = 'https://data.science.stsci.edu/redirect/JWST/jwst-data_analysis_tools/NIRISS_lensing_cluster/pipeline_products.zip'\n",
    "    boxfile = './pipeline_products.zip'\n",
    "    urllib.request.urlretrieve(boxlink, boxfile)\n",
    "    zf = zipfile.ZipFile(boxfile, 'r')\n",
    "    zf.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_DATA = './pipeline_products/'\n",
    "\n",
    "# Output directory;\n",
    "DIR_OUT = './output/'\n",
    "if not os.path.exists(DIR_OUT):\n",
    "    os.mkdir(DIR_OUT)\n",
    "\n",
    "# Filter for detection and science image;\n",
    "filt_det = 'f200w'\n",
    "\n",
    "# Image array from direct image. This is for optimal extraction and masking.\n",
    "# This image should already be sky-subtracted; otherwise, you will encounter a wrong result with optimal extraction.\n",
    "\n",
    "infile = f'{DIR_DATA}l3_nis_{filt_det}_i2d_skysub.fits'\n",
    "hdu = fits.open(infile)\n",
    "\n",
    "# This is just for error array;\n",
    "infile = f'{DIR_DATA}l3_nis_{filt_det}_i2d.fits'\n",
    "hdu_err = fits.open(infile)\n",
    "\n",
    "data = hdu[0].data\n",
    "imwcs = wcs.WCS(hdu[0].header, hdu)\n",
    "\n",
    "err = hdu_err[2].data\n",
    "weight = 1/np.square(err)\n",
    "\n",
    "# Segmentation map;\n",
    "# This can be prepared by running Photutils, if the pipeline does not generate one.\n",
    "segfile = f'{DIR_DATA}l3_nis_{filt_det}_i2d_seg.fits'\n",
    "seghdu = fits.open(segfile)\n",
    "segdata = seghdu[0].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load catalog from image level3;\n",
    "# to obtain source position in pixel coordinate.\n",
    "catfile = f'{DIR_DATA}l3_nis_{filt_det}_cat.ecsv'\n",
    "fd = ascii.read(catfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a broadband flux catalog.\n",
    "- For a convenient reason, here we compile catalogs into a flux catalog, which will be used in the following notebook (01b).\n",
    "- To run this cell, you will need a photometric catalog of sources, that list sources position and flux for each filter. For now, I use this catalog prepared in another notebook. (\"sources_extend_01.cat\")\n",
    "- This catalog can also be used for generic phot-z/SED fitting softwares, like EAZY and gsf (see notebook No.04).\n",
    "\n",
    "#### For now, we use an input catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filts = ['f115w', 'f150w', 'f200w', 'f090w', 'f435w', 'f606w', 'f814w', 'f105w', 'f125w', 'f140w', 'f160w']\n",
    "eazy_filts = [309, 310, 311, 308, 1, 4, 6, 202, 203, 204, 205]\n",
    "magzp = 25.0 # magnitude zeropoint in the catalog.\n",
    "\n",
    "# Read catalog;\n",
    "fd_input = ascii.read(f'{DIR_DATA}sources_extend_01.cat')\n",
    "ra_input = fd_input['x_or_RA']\n",
    "dec_input = fd_input['y_or_Dec']\n",
    "\n",
    "# Header;\n",
    "fw = open(f'{DIR_OUT}l3_nis_flux.cat', 'w')\n",
    "fw.write('# id')\n",
    "for ff in range(len(filts)):\n",
    "    fw.write(f' F{eazy_filts[ff]} E{eazy_filts[ff]}')\n",
    "fw.write('\\n')\n",
    "\n",
    "# Contents;\n",
    "for ii in range(len(fd['id'])):\n",
    "    \n",
    "    rtmp = np.sqrt((fd['sky_centroid'].ra.value[ii] - ra_input[:])**2 + (fd['sky_centroid'].dec.value[ii] - dec_input[:])**2)\n",
    "    iix = np.argmin(rtmp)\n",
    "    \n",
    "    for ff in range(len(filts)):\n",
    "        if ff == 0:\n",
    "            fw.write(f\"{fd['id'][ii]}\")\n",
    "\n",
    "        mag = fd_input[f'niriss_{filts[ff]}_magnitude'][iix]\n",
    "        flux_nu = 10**((mag-magzp)/(-2.5))\n",
    "\n",
    "        # Currently, the catalog does not provide proper error;\n",
    "        # Assuming a 5% error for flux.\n",
    "        \n",
    "        flux_err_nu = flux_nu * 0.05\n",
    "\n",
    "        fw.write(f' {flux_nu:.5e} {flux_err_nu:.5e}') \n",
    "\n",
    "    fw.write('\\n')\n",
    "fw.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Load 2D spectrum;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Which filter, grating, and object?\n",
    "filt = 'f200w'\n",
    "\n",
    "# grism = 'G150R'\n",
    "grism = 'G150C'\n",
    "\n",
    "id = '00004'\n",
    "\n",
    "# Zero-indexed number for dither --- the test data here has two dither positions, so 0 or 1.\n",
    "ndither = 0\n",
    "\n",
    "file_2d = f'{DIR_DATA}l3_nis_{filt}_{grism}_s{id}_cal.fits'\n",
    "hdu_2d = fits.open(file_2d)\n",
    "\n",
    "# Align grism direction\n",
    "#   - x-direction = Dispersion (wavelength) direction.\n",
    "#   - y-direction = Cross-dispersion.\n",
    "# in this notebook.\n",
    "    \n",
    "if grism == 'G150C':\n",
    "    # If spectrum is horizontal;\n",
    "    data_2d = hdu_2d[ndither*7+1].data\n",
    "    dq_2d = hdu_2d[ndither*7+2].data\n",
    "    err_2d = hdu_2d[ndither*7+3].data\n",
    "    wave_2d = hdu_2d[ndither*7+4].data\n",
    "else:\n",
    "    data_2d = rotate(hdu_2d[ndither*7+1].data, 90)\n",
    "    dq_2d = rotate(hdu_2d[ndither*7+2].data, 90)\n",
    "    err_2d = rotate(hdu_2d[ndither*7+3].data, 90)\n",
    "    wave_2d = rotate(hdu_2d[ndither*7+4].data, 90)\n",
    "\n",
    "# Get position angle of observation;\n",
    "hd_2d = hdu_2d[1].header\n",
    "PA_V3 = hd_2d['PA_V3']\n",
    "PA_V3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(data_2d, vmin=0, vmax=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get light profile of the source;\n",
    "\n",
    "# Again, y is for cross-dispersion, and x is for dispersion directions.\n",
    "y2d, x2d = data_2d.shape[:]\n",
    "\n",
    "# Cut out segmentation map;\n",
    "iix = np.where(fd['id'] == int(id))[0][0]\n",
    "\n",
    "# Target position from image 3 catalog;\n",
    "ycen = fd['ycentroid'][iix].value\n",
    "xcen = fd['xcentroid'][iix].value\n",
    "\n",
    "# Cutout size = y direction of 2D spectrum;\n",
    "rsq = y2d\n",
    "\n",
    "sci_cut = data[int(ycen-rsq/2.+0.5):int(ycen+rsq/2.+0.5), int(xcen-rsq/2.+0.5):int(xcen+rsq/2.+0.5)]\n",
    "seg_cut = segdata[int(ycen-rsq/2.+0.5):int(ycen+rsq/2.+0.5), int(xcen-rsq/2.+0.5):int(xcen+rsq/2.+0.5)]\n",
    "\n",
    "# Rotate image for PA of Grism observation;\n",
    "if grism == 'G150C':\n",
    "    sci_rot = rotate(sci_cut, PA_V3)\n",
    "else:\n",
    "    sci_rot = rotate(sci_cut, PA_V3+90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WFSS grism is dispersed in a direction of x-axis in the plot below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(sci_rot, vmin=0, vmax=1.0)\n",
    "plt.title('Direct image')\n",
    "plt.xlabel('Wavelength direction >>>', color='r', fontsize=18)\n",
    "plt.ylabel('Cross-dispersion direction >>>', color='r', fontsize=18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Get light profile at different x position --- This will be used for optimal extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ii in range(sci_rot.shape[1]):\n",
    "    flux_tmp = sci_rot[:, ii]\n",
    "    xx_tmp = np.arange(0, len(sci_rot[:, ii]), 1)\n",
    "    plt.plot(xx_tmp, flux_tmp, label='x={}'.format(ii))\n",
    "plt.legend(loc=0, fontsize=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum along x (disperse) direction\n",
    "flux_y = np.zeros(len(sci_rot[:, 0]), 'float')\n",
    "for ii in range(sci_rot.shape[0]):\n",
    "    flux_y[ii] = np.sum(sci_rot[ii, :])\n",
    "\n",
    "# Sky subtraction, if needed.\n",
    "# sky = np.mean([flux_y[0], flux_y[-1]])\n",
    "\n",
    "# Normalize;\n",
    "flux_y[:] /= flux_y.sum()\n",
    "\n",
    "plt.plot(xx_tmp, flux_y)\n",
    "plt.xlabel('y-position')\n",
    "plt.ylabel('Source Flux')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.One-dimensional extraction;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show pipeline 1D extraction as an example;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normal extraction;\n",
    "flux_disp1 = np.zeros(x2d, 'float')\n",
    "err_disp1 = np.zeros(x2d, 'float')\n",
    "wave_disp1 = np.zeros(x2d, 'float')\n",
    "    \n",
    "for ii in range(x2d): # Wavelength direction.\n",
    "    mask_tmp = (dq_2d[:, ii] == 0) & (err_2d[:, ii] > 0)\n",
    "\n",
    "    # Sum within a box;\n",
    "    flux_disp1[ii] = np.sum(data_2d[:, ii][mask_tmp]) \n",
    "    err_disp1[ii] = np.sqrt(np.sum(err_2d[:, ii][mask_tmp]**2)) \n",
    "    wave_disp1[ii] = wave_2d[0, ii]\n",
    "\n",
    "plt.errorbar(wave_disp1, flux_disp1, yerr=err_disp1)\n",
    "plt.xlim(1.7, 2.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimal extraction;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Following Horne(1986, PASP, 98, 609);\n",
    "flux_disp = np.zeros(x2d, 'float')\n",
    "err_disp = np.zeros(x2d, 'float')\n",
    "wave_disp = np.zeros(x2d, 'float')\n",
    "\n",
    "# Sigma clipping.\n",
    "sig = 5.0\n",
    "\n",
    "for ii in range(x2d): # ii : wavelength element.\n",
    "    # Mask; \n",
    "    # 1. DQ array\n",
    "    # 2. error value\n",
    "    # 3. CR detection\n",
    "    mask_tmp = (dq_2d[:, ii] == 0) & (err_2d[:, ii] > 0) & ((data_2d[:, ii] - flux_y[:] * flux_disp1[ii])**2 < sig**2 * err_2d[:, ii]**2)\n",
    "    ivar = 1. / err_2d[:, ii]**2\n",
    "\n",
    "    num = flux_y[:] * data_2d[:, ii] * ivar\n",
    "    den = flux_y[:]**2 * ivar\n",
    "    flux_disp[ii] = num[mask_tmp].sum(axis=0) / den[mask_tmp].sum(axis=0)\n",
    "    err_disp[ii] = np.sqrt(1./den[mask_tmp].sum(axis=0))\n",
    "    wave_disp[ii] = wave_2d[0, ii]\n",
    "    \n",
    "plt.errorbar(wave_disp, flux_disp, yerr=err_disp)\n",
    "plt.xlim(1.7, 2.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare;\n",
    "plt.errorbar(wave_disp, flux_disp, yerr=err_disp, color='r', label='Optimal')\n",
    "plt.errorbar(wave_disp1, flux_disp1, yerr=err_disp1, color='b', alpha=0.5, label='Box')\n",
    "plt.ylim(-10, 20000)\n",
    "plt.legend(loc=0)\n",
    "plt.xlabel('Wavelength')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.Write 1d spectrum out to a file;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_1d = f'{DIR_OUT}l3_nis_{filt}_{grism}_s{id}_1d_opt.fits'\n",
    "\n",
    "# Now make it into a Spectrum1D instance.\n",
    "obs = Spectrum1D(spectral_axis=wave_disp*u.um,\n",
    "                 flux=flux_disp*u.MJy,\n",
    "                 uncertainty=StdDevUncertainty(err_disp), unit='MJy')\n",
    "obs.write(file_1d, format='tabular-fits', overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.Light profile along x-axis = Resolution of dispersed spectrum;\n",
    "As WFSS does not have a slit, any dispersed spectrum is affected by source morphology. The estimate on the effective spectral resolution will be needed in the following notebook. And we here try to estimate it beforehand;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ii in range(sci_rot.shape[0]):\n",
    "    flux_tmp = sci_rot[ii, :]\n",
    "    xx_tmp = np.arange(0, len(sci_rot[ii, :]), 1)\n",
    "    plt.plot(xx_tmp, flux_tmp, label=f'y={ii}')\n",
    "    \n",
    "plt.legend(loc=1, fontsize=8)\n",
    "plt.xlabel('Wavelength direction')\n",
    "plt.title('Source light profile along dispersed direction', fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Unless you are interested in spatially resolved spectra, you can stack and get light profile as a good approximation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum along cross-disperse direction\n",
    "flux_x = np.zeros(len(sci_rot[0, :]), 'float')\n",
    "for ii in range(sci_rot.shape[0]):\n",
    "    flux_x[ii] = np.sum(sci_rot[:, ii])\n",
    "\n",
    "# Normalize;\n",
    "flux_x[:] /= flux_x.sum()\n",
    "\n",
    "plt.plot(xx_tmp, flux_x, label='Convolution kernel')\n",
    "plt.legend(loc=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit with a moffat function;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting function with Moffat\n",
    "# Moffat fnc.\n",
    "\n",
    "def moffat(xx, A, x0, gamma, alp):\n",
    "    yy = A * (1. + (xx-x0)**2/gamma**2)**(-alp)\n",
    "    return yy\n",
    "\n",
    "\n",
    "def fit_mof(xx, lsf):\n",
    "    # xx = lsf * 0\n",
    "    # for ii in range(len(lsf)):\n",
    "    #    xx[ii] = ii - len(lsf)/2.\n",
    "    popt, pcov = curve_fit(moffat, xx, lsf)\n",
    "    return popt\n",
    "\n",
    "\n",
    "def LSF_mof(xsf, lsf, f_plot=True):\n",
    "    '''\n",
    "    Input:\n",
    "    =======\n",
    "    xsf : x axis for the profile.\n",
    "    lsf : light profile.    \n",
    "    '''\n",
    "    \n",
    "    # for ii in range(len(sci[0, :])):\n",
    "    #    lsf[ii] = np.mean(sci_rot[int(height/2.-5):int(height/2.+5), ii])\n",
    "    #    xsf[ii] = ii - len(lsf)/2.\n",
    "\n",
    "    try:\n",
    "        A, xm, gamma, alpha = fit_mof(xsf, lsf)\n",
    "    except RuntimeError:\n",
    "        print('Fitting failed.')\n",
    "        A, xm, gamma, alpha = -1, -1, -1, -1\n",
    "        pass\n",
    "\n",
    "    if A > 0:\n",
    "        lsf_mod = moffat(xsf, A, 0, gamma, alpha)\n",
    "        \n",
    "    if f_plot:\n",
    "        yy = moffat(xsf, A, xm, gamma, alpha)\n",
    "        plt.plot(xsf, yy, 'r.', ls='-', label='Data')\n",
    "        plt.plot(xsf, lsf_mod, 'b+', ls='-', label=f'Model: gamma={gamma:2f}\\nalpha={alpha:2f}')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    \n",
    "    return A, xm, gamma, alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSF, line spread function\n",
    "iix_peak = np.argmax(flux_x)\n",
    "xx_tmp_shift = xx_tmp - xx_tmp[iix_peak]\n",
    "A, xm, gamma, alpha = LSF_mof(xx_tmp_shift, flux_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write it down;\n",
    "# Tha parameters are in unit of pixel.\n",
    "fm = open(f'{DIR_OUT}l3_nis_{filt}_{grism}_s{id}_moffat.txt', 'w')\n",
    "fm.write('# A x0 gamma alp\\n')\n",
    "fm.write('# Moffat function\\n')\n",
    "fm.write(f'{A:.3f} {xm:.3f} {gamma:.3f} {alpha:.3f}\\n')\n",
    "\n",
    "fm.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repeat for other filters, other objects.\n",
    "### The following big colum executes the same processes above for other filters and dither position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grism = 'G150C'\n",
    "id = '00004'\n",
    "DIR_OUT = './output/'\n",
    "if not os.path.exists(DIR_OUT):\n",
    "    os.mkdir(DIR_OUT)\n",
    "\n",
    "filts = ['f115w', 'f150w', 'f200w']\n",
    "ndithers = np.arange(0, 2, 1)\n",
    "\n",
    "sig = 5.0\n",
    "\n",
    "for filt in filts:\n",
    "    print(filt)\n",
    "    \n",
    "    # 2d spectrum;\n",
    "    file_2d = f'{DIR_DATA}l3_nis_{filt}_{grism}_s{id}_cal.fits'\n",
    "    hdu_2d = fits.open(file_2d)\n",
    "\n",
    "    for ndither in ndithers:\n",
    "        print(ndither)\n",
    "\n",
    "        if grism == 'G150C':\n",
    "            # If spectrum is horizontal;\n",
    "            data_2d = hdu_2d[ndither*7+1].data\n",
    "            dq_2d = hdu_2d[ndither*7+2].data\n",
    "            err_2d = hdu_2d[ndither*7+3].data\n",
    "            wave_2d = hdu_2d[ndither*7+4].data\n",
    "        else:\n",
    "            data_2d = rotate(hdu_2d[ndither*7+1].data, 90)\n",
    "            dq_2d = rotate(hdu_2d[ndither*7+2].data, 90)\n",
    "            err_2d = rotate(hdu_2d[ndither*7+3].data, 90)\n",
    "            wave_2d = rotate(hdu_2d[ndither*7+4].data, 90)\n",
    "\n",
    "        y2d, x2d = data_2d.shape[:]\n",
    "\n",
    "        plt.close()\n",
    "        plt.imshow(data_2d, vmin=0, vmax=300)\n",
    "        plt.show()\n",
    "\n",
    "        # Re-extract 2d image;\n",
    "        # if ndither == 0:\n",
    "        rsq = y2d\n",
    "        sci_cut = data[int(ycen-rsq/2.+0.5):int(ycen+rsq/2.+0.5), int(xcen-rsq/2.+0.5):int(xcen+rsq/2.+0.5)]\n",
    "        seg_cut = segdata[int(ycen-rsq/2.+0.5):int(ycen+rsq/2.+0.5), int(xcen-rsq/2.+0.5):int(xcen+rsq/2.+0.5)]\n",
    "\n",
    "        # Not sure if the offset in extractioin box is bug ;\n",
    "        if grism == 'G150C':\n",
    "            sci_rot = rotate(sci_cut, PA_V3+0)\n",
    "        else:\n",
    "            sci_rot = rotate(sci_cut, PA_V3+0+90)\n",
    "\n",
    "        # This is for spectral resolution;\n",
    "        # Get light profile along the x-axis\n",
    "        for ii in range(sci_rot.shape[0]):\n",
    "            flux_tmp = sci_rot[ii, :]\n",
    "            xx_tmp = np.arange(0, len(sci_rot[ii, :]), 1)\n",
    "\n",
    "        # Sum along cross-disperse direction\n",
    "        flux_x = np.zeros(len(sci_rot[0, :]), 'float')\n",
    "        for ii in range(sci_rot.shape[0]):\n",
    "            flux_x[ii] = np.sum(sci_rot[ii, :])\n",
    "\n",
    "        # Normalize;\n",
    "        flux_x[:] /= flux_x.sum()\n",
    "\n",
    "        # LSF\n",
    "        iix_peak = np.argmax(flux_x)\n",
    "        xx_tmp_shift = xx_tmp - xx_tmp[iix_peak]\n",
    "        A, xm, gamma, alpha = LSF_mof(xx_tmp_shift, flux_x)\n",
    "\n",
    "        if ndither == 0:\n",
    "            # Write it down;\n",
    "            fm = open(f'{DIR_OUT}l3_nis_{filt}_{grism}_s{id}_moffat.txt', 'w')\n",
    "            fm.write('# A x0 gamma alp\\n')\n",
    "            fm.write('# Moffat function\\n')\n",
    "            fm.write(f'{A:.3f} {xm:.3f} {gamma:.3f} {alpha:.3f}\\n')\n",
    "            fm.close()\n",
    "\n",
    "        # This is for Optimal extraction;\n",
    "        # Sum along x (disperse) direction\n",
    "        flux_y = np.zeros(len(sci_rot[:, 0]), 'float')\n",
    "        for ii in range(sci_rot.shape[0]):\n",
    "            flux_y[ii] = np.sum(sci_rot[ii, :])\n",
    "            \n",
    "        # Normalize;\n",
    "        flux_y[:] /= flux_y.sum()\n",
    "\n",
    "        # Following Horne;\n",
    "        flux_disp = np.zeros(x2d, 'float')\n",
    "        err_disp = np.zeros(x2d, 'float')\n",
    "        wave_disp = np.zeros(x2d, 'float')\n",
    "\n",
    "        for ii in range(x2d):\n",
    "            # Mask; \n",
    "            # 1. DQ array\n",
    "            # 2. error value\n",
    "            # 3. CR detection\n",
    "            mask_tmp = (dq_2d[:, ii] == 0) & (err_2d[:, ii] > 0)\n",
    "            ivar = 1. / err_2d[:, ii]**2\n",
    "\n",
    "            num = flux_y[:] * data_2d[:, ii] * ivar \n",
    "            den = flux_y[:]**2 * ivar\n",
    "            flux_disp[ii] = num[mask_tmp].sum(axis=0)/den[mask_tmp].sum(axis=0)\n",
    "            err_disp[ii] = np.sqrt(1./den[mask_tmp].sum(axis=0))\n",
    "            wave_disp[ii] = wave_2d[0, ii]\n",
    "\n",
    "        plt.close()\n",
    "        con_plot = (wave_disp > 0)\n",
    "        plt.errorbar(wave_disp[con_plot], flux_disp[con_plot], yerr=err_disp[con_plot])\n",
    "        plt.ylim(-0, 3000)\n",
    "        plt.show()\n",
    "\n",
    "        # Wirte:\n",
    "        # Now make it into a Spectrum1D instance.\n",
    "        file_1d = f'{DIR_OUT}l3_nis_{filt}_{grism}_s{id}_ndither{ndither}_1d_opt.fits'\n",
    "\n",
    "        if wave_disp[1] - wave_disp[0] < 0:\n",
    "            obs = Spectrum1D(spectral_axis=wave_disp[::-1]*u.um,\n",
    "                             flux=flux_disp[::-1]*u.MJy,\n",
    "                             uncertainty=StdDevUncertainty(err_disp[::-1]), unit='MJy')\n",
    "        else:\n",
    "            obs = Spectrum1D(spectral_axis=wave_disp*u.um,\n",
    "                             flux=flux_disp*u.MJy,\n",
    "                             uncertainty=StdDevUncertainty(err_disp), unit='MJy')\n",
    "            \n",
    "        obs.write(file_1d, format='tabular-fits', overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another object;\n",
    "Absorption line galaxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grism = 'G150C'\n",
    "id = '00003'\n",
    "DIR_OUT = './output/'\n",
    "\n",
    "filts = ['f115w', 'f150w', 'f200w']\n",
    "ndithers = np.arange(0, 2, 1) # There are four dithers in the data set;\n",
    "\n",
    "sig = 5.0\n",
    "\n",
    "for filt in filts:\n",
    "    print(filt)\n",
    "    # 2d spectrum;\n",
    "    file_2d = f'{DIR_DATA}l3_nis_{filt}_{grism}_s{id}_cal.fits'\n",
    "    hdu_2d = fits.open(file_2d)\n",
    "\n",
    "    for ndither in ndithers:\n",
    "        print(ndither)\n",
    "        if grism == 'G150C':\n",
    "            # If spectrum is horizontal;\n",
    "            data_2d = hdu_2d[ndither*7+1].data\n",
    "            dq_2d = hdu_2d[ndither*7+2].data\n",
    "            err_2d = hdu_2d[ndither*7+3].data\n",
    "            wave_2d = hdu_2d[ndither*7+4].data\n",
    "        else:\n",
    "            data_2d = rotate(hdu_2d[ndither*7+1].data, 90)\n",
    "            dq_2d = rotate(hdu_2d[ndither*7+2].data, 90)\n",
    "            err_2d = rotate(hdu_2d[ndither*7+3].data, 90)\n",
    "            wave_2d = rotate(hdu_2d[ndither*7+4].data, 90)\n",
    "\n",
    "        y2d, x2d = data_2d.shape[:]\n",
    "\n",
    "        plt.close()\n",
    "        plt.imshow(data_2d, vmin=0, vmax=20)\n",
    "        plt.show()\n",
    "\n",
    "        # Re-extract 2d image;\n",
    "        # if ndither == 0:\n",
    "        rsq = y2d\n",
    "        sci_cut = data[int(ycen-rsq/2.+0.5):int(ycen+rsq/2.+0.5), int(xcen-rsq/2.+0.5):int(xcen+rsq/2.+0.5)]\n",
    "        seg_cut = segdata[int(ycen-rsq/2.+0.5):int(ycen+rsq/2.+0.5), int(xcen-rsq/2.+0.5):int(xcen+rsq/2.+0.5)]\n",
    "\n",
    "        # Not sure if the offset in extraction box is bug ;\n",
    "        if grism == 'G150C':\n",
    "            sci_rot = rotate(sci_cut, PA_V3+0)\n",
    "        else:\n",
    "            sci_rot = rotate(sci_cut, PA_V3+0+90)\n",
    "\n",
    "        # This is for spectral resolution;\n",
    "        # Get light profile along the x-axis\n",
    "        for ii in range(sci_rot.shape[0]):\n",
    "            flux_tmp = sci_rot[ii, :]\n",
    "            xx_tmp = np.arange(0, len(sci_rot[ii, :]), 1)\n",
    "\n",
    "        # Sum along cross-disperse direction\n",
    "        flux_x = np.zeros(len(sci_rot[0, :]), 'float')\n",
    "        for ii in range(sci_rot.shape[0]):\n",
    "            flux_x[ii] = np.sum(sci_rot[ii, :])\n",
    "\n",
    "        # Normalize;\n",
    "        flux_x[:] /= flux_x.sum()\n",
    "\n",
    "        # LSF\n",
    "        iix_peak = np.argmax(flux_x)\n",
    "        xx_tmp_shift = xx_tmp - xx_tmp[iix_peak]\n",
    "        A, xm, gamma, alpha = LSF_mof(xx_tmp_shift, flux_x)\n",
    "\n",
    "        if ndither == 0:\n",
    "            # Write it down;\n",
    "            fm = open(f'{DIR_OUT}l3_nis_{filt}_{grism}_s{id}_moffat.txt', 'w')\n",
    "            fm.write('# A x0 gamma alp\\n')\n",
    "            fm.write('# Moffat function\\n')\n",
    "            fm.write(f'{A:.3f} {xm:.3f} {gamma:.3f} {alpha:.3f}\\n')\n",
    "            fm.close()\n",
    "\n",
    "        # This is for Optimal extraction;\n",
    "        # Sum along x (disperse) direction\n",
    "        flux_y = np.zeros(len(sci_rot[:, 0]), 'float')\n",
    "        for ii in range(sci_rot.shape[0]):\n",
    "            flux_y[ii] = np.sum(sci_rot[ii, :])\n",
    "    \n",
    "        # Normalize;\n",
    "        flux_y[:] /= flux_y.sum()\n",
    "\n",
    "        # Following Horne;\n",
    "        flux_disp = np.zeros(x2d, 'float')\n",
    "        err_disp = np.zeros(x2d, 'float')\n",
    "        wave_disp = np.zeros(x2d, 'float')\n",
    "\n",
    "        for ii in range(x2d):\n",
    "            # Mask; \n",
    "            # 1. DQ array\n",
    "            # 2. error value\n",
    "            # 3. CR detection\n",
    "            mask_tmp = (dq_2d[:, ii] == 0) & (err_2d[:, ii] > 0) \n",
    "            ivar = 1. / err_2d[:, ii]**2\n",
    "\n",
    "            num = flux_y[:] * data_2d[:, ii] * ivar \n",
    "            den = flux_y[:]**2 * ivar\n",
    "            flux_disp[ii] = num[mask_tmp].sum(axis=0)/den[mask_tmp].sum(axis=0)\n",
    "            err_disp[ii] = np.sqrt(1./den[mask_tmp].sum(axis=0))\n",
    "            wave_disp[ii] = wave_2d[0, ii]\n",
    "\n",
    "        plt.close()\n",
    "        con_plot = (wave_disp > 0)\n",
    "        plt.errorbar(wave_disp[con_plot], flux_disp[con_plot], yerr=err_disp[con_plot])\n",
    "        plt.ylim(-20, 100)\n",
    "        plt.show()\n",
    "\n",
    "        # Write:\n",
    "        # Now, make it into a Spectrum1D instance.\n",
    "        file_1d = f'{DIR_OUT}l3_nis_{filt}_{grism}_s{id}_ndither{ndither}_1d_opt.fits'\n",
    "\n",
    "        if wave_disp[1] - wave_disp[0] < 0:\n",
    "            obs = Spectrum1D(spectral_axis=wave_disp[::-1]*u.um,\n",
    "                             flux=flux_disp[::-1]*u.MJy,\n",
    "                             uncertainty=StdDevUncertainty(err_disp[::-1]), unit='MJy')\n",
    "        else:\n",
    "            obs = Spectrum1D(spectral_axis=wave_disp*u.um,\n",
    "                             flux=flux_disp*u.MJy,\n",
    "                             uncertainty=StdDevUncertainty(err_disp), unit='MJy')\n",
    "\n",
    "        obs.write(file_1d, format='tabular-fits', overwrite=True)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
