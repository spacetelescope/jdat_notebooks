{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Composite Model Spectral Fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use case:** Fitting the complex continuum around Lyman-alpha in the spectrum of an active galaxy NGC 5548.<br>\n",
    "**Data:** 3-column ECSV file with units for each column.<br>\n",
    "**Tools:** specutils, numpy.<br>\n",
    "**Cross-intrument:** all instruments.<br>\n",
    "**Documentation:** This notebook is part of a STScI's larger [post-pipeline Data Analysis Tools Ecosystem](https://jwst-docs.stsci.edu/jwst-post-pipeline-data-analysis).<br>\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this example, we are fitting the complex continuum around Lyman-alpha in the spectrum of an active galaxy (NGC 5548). This involves a powerlaw, extinction, emission lines of various widths and absorption lines. Only certain regions of the spectrum (away from strong absorption lines) are fit. The model has some fixed and some free parameters, as well as parameters that are linked together. We are using the Astropy compound-model machinery to add fit all the components simultaneously. \n",
    "\n",
    "The example makes only partial use of specutils. It reads the data into the Spectrum1D data structure. However, when we get to actually fitting the model, we are just grabbing the numpy arrays (without units, because that caused some errors). \n",
    "\n",
    "#### Developer Notes\n",
    "Todo: \n",
    " \n",
    " - Move useful stuff from fit_functions upstream to astropy?\n",
    " - Use units and quantities all the way through\n",
    " - Illustrate fixing and freeing parameters\n",
    " - Illustrate locking and unlocking parameters\n",
    " - Figure out how to introspect the tied parameters (may need a helper class for Astropy modeling)\n",
    " - This model doesn't fit very well. Change the example. \n",
    " - The covariance cell is returning nothing. Is that intended?\n",
    "     - might be nice to show a triangle diagram of convariances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import specutils\n",
    "import time\n",
    "import astropy.modeling.fitting as fitting\n",
    "from astropy.table import Table, QTable\n",
    "from astropy.nddata import StdDevUncertainty\n",
    "import astropy.units as u\n",
    "from astropy.visualization import quantity_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import astropy\n",
    "# import matplotlib\n",
    "# print(\"Astropy Version: \",astropy.__version__)\n",
    "# print(\"Numpy Version: \",np.__version__)\n",
    "# print(\"Specutils Version: \",specutils.__version__)\n",
    "# print(\"Matplotlib Version: \",matplotlib.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Developer notes: \n",
    "\n",
    "Versions:\n",
    "\n",
    " - Astropy Version:  3.2.3\n",
    " - Numpy Version:  1.17.3\n",
    " - Specutils Version:  0.6\n",
    " - Matplotlib Version:  3.1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# inline -- noninteractive cells, notebook -- interactive cells \n",
    "%matplotlib inline \n",
    "# %matplotlib notebook\n",
    "%config InlineBackend.figure_format ='retina' # Mackbook optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data input\n",
    "\n",
    " - spectrum: simple 3-column ECSV file with units for each column\n",
    " - wavelength regions to be included in fit: simple 2-column ASCII file with lower & upper bounds\n",
    " \n",
    "First set up pathnames. \n",
    "\n",
    "##### Developer note\n",
    "\n",
    " - These data files are small ASCII files, so they are in the github repo with the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafile = \"./n5548_mean_g130mb4.ecsv\"\n",
    "regionsfile = \"./n5548_lyalpha_sample.dat\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the tables using astropy's QTable, so that we preserve the units.\n",
    "\n",
    "#### Developer notes\n",
    "It would be good if this example provided an example of recommended practice for encoding uncertainties in tables. Questions:\n",
    "\n",
    " - Should the uncertainties have units?\n",
    " - Seems like the name \"uncertainty\" is generally understood to mean standard deviation (or the equivalent). So if one wants to have these be, e.g., variance, the user should name the column `variance`. \n",
    " - It's a bit ugly to have to either add a table column to make these an astropy uncertainty object, or just store that as as a separate variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = QTable.read(datafile, format='ascii.ecsv')\n",
    "data[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Put the spectrum into a Spectrum1D object\n",
    "\n",
    "We need to convert the uncertainty into an astropy uncertainty object first.\n",
    "\n",
    "##### Developer notes\n",
    "\n",
    "I think it might be simpler to hide the uncertainty type as options to the Spectrum1D call, defaulting to standard-deviation. \n",
    "\n",
    "For example...I first tried what I thought would make sense:\n",
    "```\n",
    "    data['stdev'] = StdDevUncertainty(data['uncertainty'])\n",
    "    spectrum = specutils.Spectrum1D(spectral_axis=data['wavelength']\n",
    "                                ,flux=data['flux'],uncertainty=data['stdev'])\n",
    "```\n",
    "That raises an ```IncompatibleUncertaintiesException```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uncertainty = StdDevUncertainty(data['uncertainty'])\n",
    "spectrum = specutils.Spectrum1D(spectral_axis=data['wavelength'],\n",
    "                                flux=data['flux'], uncertainty=uncertainty)\n",
    "print(spectrum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in the spectral regions\n",
    "\n",
    "Convert these into specutils SpectralRegions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regionstab = QTable.read(regionsfile,format='ascii')\n",
    "subregions = []\n",
    "for x0,x1 in zip(regionstab['col1'],regionstab['col2']):\n",
    "    subregions += [(x0*u.AA, x1*u.AA)]\n",
    "regions=specutils.SpectralRegion(subregions)\n",
    "regions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a mask from the regions\n",
    "\n",
    "##### Developer note\n",
    "We could probably do the whole workflow extracting regions, but I think it would end up being uglier than using a mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_from_regions(spectrum,regions):\n",
    "    mask = np.zeros(spectrum.spectral_axis.shape,dtype=np.bool)\n",
    "    for r in regions:\n",
    "        submask = (spectrum.spectral_axis>r.lower) & (spectrum.spectral_axis<=r.upper)\n",
    "        mask = mask | submask\n",
    "    spectrum.mask = mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_from_regions(spectrum,regions)\n",
    "print(spectrum.mask.min(), spectrum.mask.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convenience routine for plotting a spectrum and highlighting the mask\n",
    "\n",
    "##### Developer notes\n",
    " \n",
    " - I think this way of illustrating the mask is reasonably elegant. I sort of like it better than having the shaded regions extend all the way up to the top. (I do that later when showing the residuals, for comparison).\n",
    " - Another way to do it might be to change the line color to grey, or change the opacity, in the masked regions, but that would be harder to implement and probably slower.\n",
    " - This routine exposes both a benefit of using units and Spectrum1D -- you can automatically put the units on the axis\n",
    " - This also exposes a limitation: Right now, while quantity_support() puts the units on the axis automaticall, it doesn't put the label. It is the standard convention to give `label (units)` when labeling axes. The trick used here of adding in the label using `get_label()` and `set_label()` is liable to be too obscure for most users. \n",
    " - Are we going to keep all visualization for specviz, or should there be some tools for visualization in specutils?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_spectrum(spectrum,color='b',alpha=0.5,figsize=(15,6),\n",
    "                  label=None,ax=None,plot_mask=True,\n",
    "                  mask_color='g',mask_alpha=0.1,title=None):\n",
    "    with quantity_support():\n",
    "        if ax is None:\n",
    "            fig, ax = plt.subplots(figsize=figsize)\n",
    "        ax.plot(spectrum.spectral_axis,spectrum.flux,color=color,alpha=alpha,label=label)\n",
    "        if plot_mask: \n",
    "            if spectrum.mask is not None:\n",
    "                ax.fill_between(spectrum.spectral_axis,0,spectrum.flux*spectrum.mask,\n",
    "                        alpha=mask_alpha,color=mask_color)\n",
    "    ax.set_xlabel(r\"Wavelength (\" + ax.get_xlabel() + \")\")\n",
    "    ax.set_ylabel(r\"Flux (\" + ax.get_ylabel() + \")\")\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plot_spectrum(spectrum)\n",
    "ax.set_title('NGC 5548 spectrum and mask to be used for fitting the model');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>First guess model</h1>\n",
    "\n",
    "The model is imported directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import n5548_models as models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The .py module defined above builds one or more instances of a special type of function defined in the astropy.modeling.models package, called a \"compound model\". \n",
    "\n",
    "A compound model is just a combination of astropy.modeling.models functions, using as combination operators such things as addition, multiplication, and others.\n",
    "\n",
    "Example: \n",
    "\n",
    "<code>compound_model = models.PowerLaw1D(1.,1.) + models.Gaussian1D(1.,1.,1.)</code>\n",
    "\n",
    "will create an instance of a compound model with two components.\n",
    "\n",
    "An actual, importable model definition will look like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from custom_models import gaussian, powerlaw, ccmext\n",
    "\n",
    "model1 = \\\n",
    "    powerlaw(name = 'powerlaw1',\n",
    "             amp =   6.586200E-14,\n",
    "             x_0 =   1000.0,\n",
    "             alpha = 0.4819233,\n",
    "             bounds = {'amp':   (0., 1.00E-11),\n",
    "                       'x_0':   (0., 1.00E-11),\n",
    "                       'alpha': (-5., 5.)},\n",
    "             fixed = {'x_0': True}\n",
    "             ) \\\n",
    "+ \\\n",
    "    gaussian(name = 'C III 1176',\n",
    "             norm = 2.000000E-14,\n",
    "             mean = 1195.006,\n",
    "             fwhm = 861.4926,\n",
    "             bounds = {'norm': (0., 1.00E-10),\n",
    "                       'mean': (1000., 2000.),\n",
    "                       'fwhm': (1000., 2000.),\n",
    "                       'skew': (1., 1.)},\n",
    "             fixed = {'norm': True,\n",
    "                      'mean': True,\n",
    "                      'fwhm': True,\n",
    "                      'skew': True},\n",
    "             ) \\\n",
    "```             \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this exercise, we pick the model named 'model1':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "compound_model = models.model1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The module uses some special function types, defined by overriding the standard functions in asytropy.modeling.models in module custom_models. \n",
    "\n",
    "This overriding is necessary because the spectral components in specfit do not conform with the standards defined in astropy.modeling.models. For example, a Gaussian in specfit is defined by an amplitude, a central wavelength, a FWHM in km/s, and a skweness parameter. In astropy.modeling.models a Gaussian is defined by an amplitude, a central wavelength, and a width in units consistent with the units of the central wavelength. And no skewness parameter. These incompatibilities are addressed by the sub-classes defined in the fit_functions module. \n",
    "\n",
    "##### Developer notes\n",
    "\n",
    " - Seems useful to have a Gaussian with skew as an Astropy model, so that should probably be moved upstream.\n",
    " - Not sure about the FWHM. It's probably cleaner for that to be the width parameter when there is skewness, since it's more intuitive than standard deviation.\n",
    " - The print statement for the compound model below is okay but not great. Might be worth having a pretty print for notebooks that makes this more readable.\n",
    "   - This print statement does not indicate which parameters are fixed or floating\n",
    "   - It does not indicate which parameters are tied to others and how\n",
    "   - There is an ellipsis in the table at the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(compound_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plot_spectrum(spectrum,label='data')\n",
    "ax.plot(spectrum.spectral_axis, compound_model(spectrum.spectral_axis.value), 'r',label='initial model')\n",
    "ax.legend()\n",
    "ax.set_title(\"Data and initial model\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting\n",
    "\n",
    "We have the data and the model, now we need to fit one to the other. We can use that by instantiating an Astropy fitter, in this case the `LevMarLSQFitter` which uses the Levenberg-Marquardt algorithm for least-squares fitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitter = fitting.LevMarLSQFitter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we have access to the errors for the data points, so we can use their inverse as weights for the fit. To include the mask, which is `1` for pixels we want to fit and `0` for pixels we want to exclude, we take $\\rm {mask} / \\sigma$, as the weight to give to the fitter.\n",
    "\n",
    "##### Developer notes\n",
    "\n",
    " - Because the compound model fitting didn't work out of the box feeding it the Specutils `spectral_axis` and `flux` Quanitities, I'm getting rid of the units. In conversation, it seems like there is some machinery for removing the units and putting them back in `fit_line` (which is more general than just fitting a line), but I didn't think to look there.\n",
    " - While it agrees with the scipy fitter conventions, I think it is quite confusing to call $w = 1/\\sigma$ the *weight*. I checked the code and for this fitter, indeed it is squaring this to use as the weight, so the calculation is correct. But I think it is more common to think of the correct weight as being $w = 1/\\sigma^2$ for least-squares fitting. I've now gone down the rabbit hole of trying to double-check that Astropy is doing the weighting correctly twice because of this unusual use of the word \"weight.\"\n",
    " - Nadia Dencheva is going to check that the non-least-squares fitters are using weight when their instructions say use $1/\\sigma$ -- i.e. are they squaring it or not before computing the merit function?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavelength = spectrum.spectral_axis.value\n",
    "flux = spectrum.flux.value\n",
    "inverse_sigma = spectrum.mask/spectrum.uncertainty.array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do the fit, call the fitter instance with the data, weights, and some control parameters if needed. Let's do some timing as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "fit_result = fitter(compound_model, wavelength, flux, weights=inverse_sigma, acc=1.E-30, maxiter=6000)\n",
    "end_time = time.time()\n",
    "print(\"Elapsed time: \", end_time - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Developer note\n",
    "\n",
    " - I'm not sure how to interpret the fit_info message below that \n",
    " \n",
    " ```Both actual and predicted relative reductions in the sum of squares\n",
    "  are at most 0.0000001```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fitter.fit_info['message'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is another instance of a compound model, with the fitted values set into the  parameter values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fit_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets print some derived results:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Looking at the fit results\n",
    "\n",
    "Create a little routine to estimate chisq. It needs to compute the number of degrees of freedom taking into account the mask and the number of free parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chisq(x, y, err, mask, model, nfree):\n",
    "    chisq = (y - model(x))**2 / err**2\n",
    "    chisq = np.sum(chisq * mask)\n",
    "    npoints = np.sum(mask)\n",
    "    return np.sqrt(chisq / (npoints - nfree - 1)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure out how many fixed and free parameters there are.\n",
    "\n",
    "##### Developer note\n",
    "\n",
    " - This is pretty ugly and involved. The fitter knows how many data points and free parameters there are, but I don't think it passes that information along as \"metadata\" to the fit results. The fit_info is a dictionary returned from `scipy.optimize.leastsq`, but it doesn't have the number of free parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'fixed' in fit_result.parameter_constraints:\n",
    "    fix = np.asarray(fit_result.fixed.values())\n",
    "    n_fixed_parameters = np.sum(np.where(fix, 1, 0))\n",
    "else:\n",
    "    n_fixed_parameters = 0\n",
    "\n",
    "if 'tied' in fit_result.parameter_constraints:\n",
    "    tie = np.asarray(fit_result.tied.values())\n",
    "    n_tied_parameters = np.sum(np.where(tie, 1, 0))\n",
    "else:\n",
    "    n_tied_parameters = 0\n",
    "    \n",
    "n_free_par = len(fit_result.parameters) - n_fixed_parameters - n_tied_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print out $\\chi^2$ and other relevant info.\n",
    "\n",
    "##### Developer note\n",
    " - This kind of thing ought to be standard output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chisq_in = chisq(wavelength, flux, spectrum.uncertainty.array, spectrum.mask, compound_model, n_free_par)\n",
    "chisq_out = chisq(wavelength, flux, spectrum.uncertainty.array, spectrum.mask, fit_result, n_free_par)\n",
    "print(\"chisq from input model:  %f\" % chisq_in)\n",
    "print(\"chisq from output model: %f\" % chisq_out)\n",
    "print(\"Total data points: %d\" % len(wavelength))\n",
    "print(\"Data points in wavelength ranges: %d\" % np.sum(spectrum.mask))\n",
    "print(\"Number of free parameters: %d\" % n_free_par)\n",
    "print(\"Number of iterations: %d\" % fitter.fit_info['nfev'])\n",
    "print (\"Fit engine took %d elapsed seconds.\" % (end_time - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Errors associated with each free parameter from the covariance matrix.\n",
    "\n",
    "##### Developer note\n",
    "\n",
    " - This is empty. But it actually is in the fit_info from this fitter, so we could grab it.\n",
    " - It would be nice in a more advanced version of this notebook to show someone how to plot the error ellipses in a triangle (corner) plot, which is a good way to visualize correlations between pairs of parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov = fitter.fit_info['param_cov']\n",
    "\n",
    "param_errors = {}\n",
    "i = 0\n",
    "if cov is not None:\n",
    "    # extract variances from covariance matrix\n",
    "    fit_errors = {}\n",
    "    for param_name in fit_result.param_names:\n",
    "        fixed = fit_result.fixed[param_name]\n",
    "        tied = fit_result.tied[param_name]\n",
    "        if not fixed and not tied:\n",
    "            fit_errors[param_name] = math.sqrt(cov[i,i])\n",
    "            i += 1\n",
    "            \n",
    "    # map errors to input model's components and parameters.\n",
    "    for param_name in fit_errors.keys():\n",
    "        index, target_param_name = fit_result._param_map[param_name]\n",
    "        component_name = fit_result._submodels_names[index]\n",
    "        param_errors[(component_name, target_param_name)] = fit_errors[param_name]\n",
    "\n",
    "print(param_errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Plots</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input and output compound models\n",
    "\n",
    "##### Developer notes\n",
    " - A fancy, but *very* useful interactive version of this plot might have the following features\n",
    "   - Zoom & pan, etc (could get that by using %matplotlib notebook, but scrolling is a pain with that) \n",
    "   - Ability to toggle from curves to histograms for the data\n",
    "   - Ability to toggle on and off the mask, change alpha, etc\n",
    "   - Ability to toggle on and off errorbars on the data, change alpha, etc\n",
    "   - Hover information: data, residual, percent contribution to chisq for that one point\n",
    "   - Ability to toggle on and off individual components of the compound model\n",
    "      - That wouldn't be all that useful in this example, since it's better to see them on top of the powerlaw*extinction, but that's a pretty special use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plot_spectrum(spectrum,label='data')\n",
    "ax.plot(wavelength, compound_model(wavelength), 'r',label='initial model')\n",
    "ax.plot(wavelength, fit_result(wavelength), 'g',label='fitted model')\n",
    "ax.set_xlim((1200,1275))\n",
    "ax.set_ylim((0,7e-13))\n",
    "ax.legend()\n",
    "ax.set_title(\"Data and models\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the residuals\n",
    "\n",
    "Focus in on the most interesting region. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ylim = (-2.e-13, 2.e-13)\n",
    "fig,ax = plt.subplots(figsize=(15,6))\n",
    "ax.plot(wavelength,flux-compound_model(wavelength),label='original')\n",
    "ax.plot(wavelength,flux-fit_result(wavelength),label='original')\n",
    "ax.fill_between(wavelength,ylim[0]*spectrum.mask,ylim[1]*spectrum.mask,\n",
    "                        alpha=0.1,color='g')\n",
    "ax.set_xlim((1185., 1270.))\n",
    "ax.set_ylim(ylim)\n",
    "ax.legend()\n",
    "ax.set_xlabel(r'Wavelength ($\\rm \\AA$)',fontsize='large')\n",
    "ax.set_ylabel(r'Flux ($\\rm erg\\, cm^{-2}\\, s^{-1}\\, \\AA^{-1}$)',fontsize='large')\n",
    "ax.set_title('Residuals',fontsize='large');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot individual components\n",
    "\n",
    "Here we plot them on top of the basic powerlaw*extinction \n",
    "\n",
    "##### Developer notes\n",
    "\n",
    " - I was trying to label or otherwise indicate which ones are tied together, but it seems like this information gets lost because because tying parameters is just done by passing a function. It might be better for Astropy to have a base class that people can use that would have the name of the referenced parameter as an attribute and has a `__call__` method. Then one could at least recommend that people use this when tying parameters, to facilitate later introspection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plot_spectrum(spectrum,label='data')\n",
    "ax.plot(wavelength, fit_result(wavelength), 'g',label='fitted model')\n",
    "plext = fit_result['powerlaw1'] * fit_result['extinction']\n",
    "ax.plot(wavelength,plext(wavelength),'--',alpha=0.5,linewidth=5,label=\"powerlaw + extinction\")\n",
    "for component in fit_result:\n",
    "    if component.name != 'powerlaw1' and component.name != 'extinction':\n",
    "        ax.plot(wavelength,(plext+component)(wavelength),label=component.name,alpha=0.5)\n",
    "ax.set_xlim((1200,1275))\n",
    "ax.set_ylim((0,9e-13))\n",
    "ax.legend(loc='upper right',fontsize='small')\n",
    "ax.set_title(\"Data and models\");"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
