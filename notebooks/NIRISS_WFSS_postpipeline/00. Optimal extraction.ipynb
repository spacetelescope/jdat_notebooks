{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 00 Optimal extraction of NIRISS WFSS spectrum;\n",
    "\n",
    "This notebook aims to do 1D optimal extraction, whereas the JWST pipeline only provides a box extraction, which improves S/N of spectra for faint sources.\n",
    "\n",
    "This notebook will start with post-pipeline products of NIRISS WFSS, 2D rectified spectra, from spec level3.\n",
    "\n",
    "\n",
    "- Optimal extraction requires source morphology along the cross-dispersion direction, where we will retrieve from direct images taken along with WFSS observations.\n",
    "\n",
    "- Morphology along dispersion direction is also essential to infer the spectral resolution, where we will aim at template fitting to get redshift and stellar population in the following notebook.\n",
    "\n",
    "<font color='red'>We here assume reduction by the pipeline, or by any other softwares, on 2D rectification has been performed at a decent level, i.e. no contaminating flux from other sources on the target 2D spectrum, as well as background is already subtracted.<font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from scipy.ndimage import rotate\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "\n",
    "from astropy.convolution import Gaussian2DKernel\n",
    "from astropy.io import fits\n",
    "from astropy.stats import gaussian_fwhm_to_sigma\n",
    "from astropy.table import QTable\n",
    "import astropy.units as u\n",
    "from astropy.visualization import make_lupton_rgb, SqrtStretch, ImageNormalize, simple_norm\n",
    "import astropy.wcs as wcs\n",
    "from astropy.io import ascii\n",
    "\n",
    "from specutils import Spectrum1D\n",
    "from astropy.nddata import StdDevUncertainty\n",
    "\n",
    "import specutils\n",
    "print('specutils', specutils.__version__)\n",
    "\n",
    "import astropy\n",
    "print('astropy', astropy.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The version should be \n",
    "- specutils 1.0\n",
    "- astropy 4.0.1.post1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "mpl.rcParams['savefig.dpi'] = 80\n",
    "mpl.rcParams['figure.dpi'] = 80"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.Download and load data:\n",
    "These include pipeline processed data for NIRISS, as well as photometric catalog from image step3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('./pipeline_products'):\n",
    "    import zipfile\n",
    "    import urllib.request\n",
    "    boxlink = 'https://data.science.stsci.edu/redirect/JWST/jwst-data_analysis_tools/NIRISS_lensing_cluster/pipeline_products.zip'\n",
    "    boxfile = './pipeline_products.zip'\n",
    "    urllib.request.urlretrieve(boxlink, boxfile)\n",
    "    zf = zipfile.ZipFile(boxfile, 'r')\n",
    "    zf.extractall()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_DATA = './pipeline_products/'\n",
    "\n",
    "# Output directory;\n",
    "DIR_OUT  = './output/'\n",
    "if not os.path.exists(DIR_OUT):\n",
    "    os.mkdir(DIR_OUT)\n",
    "\n",
    "# Filter for detection and science image;\n",
    "filt_det = 'f200w'\n",
    "\n",
    "# Image array from direct image. This is for optimal extraction and masking.\n",
    "# This image should already be sky-subtracted; otherwise, you will encounter a wrong result with optimal extraction.\n",
    "infile = '%sl3_nis_%s_i2d_skysub.fits'%(DIR_DATA,filt_det)\n",
    "hdu = fits.open(infile)\n",
    "\n",
    "# This is just for error array;\n",
    "infile = '%sl3_nis_%s_i2d.fits'%(DIR_DATA,filt_det)\n",
    "hdu_err = fits.open(infile)\n",
    "\n",
    "data = hdu[0].data\n",
    "imwcs = wcs.WCS(hdu[0].header, hdu)\n",
    "\n",
    "err = hdu_err[2].data\n",
    "weight = 1/np.square(err)\n",
    "\n",
    "# Segmentation map;\n",
    "# This can be prepared by running Photutils, if the pipeline does not generate one.\n",
    "segfile = '%sl3_nis_%s_i2d_seg.fits'%(DIR_DATA, filt_det)\n",
    "seghdu = fits.open(segfile)\n",
    "segdata = seghdu[0].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load catalog from image level3;\n",
    "# to obtain source position in pixel coordinate.\n",
    "catfile = '%sl3_nis_%s_cat.ecsv'%(DIR_DATA, filt_det)\n",
    "fd = ascii.read('%s'%catfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a broadband flux catalog.\n",
    "- For a convenient reason, here we compile catalogs into a flux catalog, which will be used in the following notebook (01b).\n",
    "- To run this cell, you will need a photometric catalog of sources, that list sources position and flux for each filter. For now, I use this catalog prepared in another notebook. (\"sources_extend_01.cat\")\n",
    "- This catalog can also be used for generic phot-z/SED fitting softwares, like EAZY and gsf (see notebook No.04).\n",
    "\n",
    "#### For now, we use an input catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filts = ['f115w', 'f150w', 'f200w', 'f090w', 'f435w', 'f606w', 'f814w', 'f105w', 'f125w', 'f140w', 'f160w']\n",
    "eazy_filts = [309, 310, 311, 308, 1, 4, 6, 202, 203, 204, 205]\n",
    "magzp = 25.0 # magnitude zeropoint in the catalog.\n",
    "\n",
    "# Read catalog;\n",
    "fd_input = ascii.read('%ssources_extend_01.cat'%(DIR_DATA))\n",
    "ra_input = fd_input['x_or_RA']\n",
    "dec_input = fd_input['y_or_Dec']\n",
    "\n",
    "# Header;\n",
    "fw = open('%sl3_nis_flux.cat'%(DIR_OUT), 'w')\n",
    "fw.write('# id')\n",
    "for ff in range(len(filts)):\n",
    "    fw.write(' F%d E%d'%(eazy_filts[ff], eazy_filts[ff]))\n",
    "fw.write('\\n')\n",
    "\n",
    "# Contents;\n",
    "for ii in range(len(fd['id'])):\n",
    "    \n",
    "    rtmp = np.sqrt((fd['sky_centroid'].ra.value[ii] - ra_input[:])**2 + (fd['sky_centroid'].dec.value[ii] - dec_input[:])**2)\n",
    "    iix = np.argmin(rtmp)\n",
    "    \n",
    "    for ff in range(len(filts)):\n",
    "        if ff == 0:\n",
    "            fw.write('%d'%(fd['id'][ii]))\n",
    "\n",
    "        mag = fd_input['niriss_%s_magnitude'%filts[ff]][iix]\n",
    "        flux_nu = 10**((mag-magzp)/(-2.5))\n",
    "\n",
    "        # Currently, the catalog does not provide proper error;\n",
    "        # Assuming 5% error for flux.\n",
    "        \n",
    "        flux_err_nu = flux_nu * 0.05\n",
    "\n",
    "        fw.write(' %.5e %.5e'%(flux_nu, flux_err_nu))\n",
    "\n",
    "    fw.write('\\n')\n",
    "fw.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.Load 2D spectrum;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Which filter, grating, and object?\n",
    "filt = 'f200w'\n",
    "\n",
    "#grism = 'G150R'\n",
    "grism = 'G150C'\n",
    "\n",
    "id = '00004'\n",
    "\n",
    "# Zero-indexed number for dither --- the test data here has two dither positions, so 0 or 1.\n",
    "ndither = 0\n",
    "\n",
    "file_2d = '%sl3_nis_%s_%s_s%s_cal.fits'%(DIR_DATA, filt, grism, id)\n",
    "hdu_2d = fits.open(file_2d)\n",
    "\n",
    "# Align grism direction\n",
    "#   - x-direction = Dispersion (wavelength) direction.\n",
    "#   - y-direction = Cross-dispersion.\n",
    "# in this notebook.\n",
    "    \n",
    "if grism == 'G150C':\n",
    "    # If spectrum is horizontal;\n",
    "    data_2d = hdu_2d[ndither*7+1].data\n",
    "    dq_2d = hdu_2d[ndither*7+2].data\n",
    "    err_2d = hdu_2d[ndither*7+3].data\n",
    "    wave_2d = hdu_2d[ndither*7+4].data\n",
    "else:\n",
    "    data_2d = rotate(hdu_2d[ndither*7+1].data, 90)\n",
    "    dq_2d = rotate(hdu_2d[ndither*7+2].data, 90)\n",
    "    err_2d = rotate(hdu_2d[ndither*7+3].data, 90)\n",
    "    wave_2d = rotate(hdu_2d[ndither*7+4].data, 90)\n",
    "\n",
    "# Get position angle of observation;\n",
    "hd_2d = hdu_2d[1].header\n",
    "PA_V3 = hd_2d['PA_V3']\n",
    "PA_V3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(data_2d, vmin=0, vmax=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get light profile of the source;\n",
    "\n",
    "# Again, y is for cross-dispersion, and x is for dispersion directions.\n",
    "y2d,x2d = data_2d.shape[:]\n",
    "\n",
    "# Cut out segmentation map;\n",
    "iix = np.where(fd['id']==int(id))[0][0]\n",
    "\n",
    "# Target position from image 3 catalog;\n",
    "ycen = fd['ycentroid'][iix].value\n",
    "xcen = fd['xcentroid'][iix].value\n",
    "\n",
    "# Cutout size = y direction of 2D spectrum;\n",
    "rsq = y2d\n",
    "\n",
    "sci_cut = data[int(ycen-rsq/2.+0.5):int(ycen+rsq/2.+0.5), int(xcen-rsq/2.+0.5):int(xcen+rsq/2.+0.5)]\n",
    "seg_cut = segdata[int(ycen-rsq/2.+0.5):int(ycen+rsq/2.+0.5), int(xcen-rsq/2.+0.5):int(xcen+rsq/2.+0.5)]\n",
    "\n",
    "# Rotate image for PA of Grism observation;\n",
    "if grism == 'G150C':\n",
    "    sci_rot = rotate(sci_cut, PA_V3)\n",
    "else:\n",
    "    sci_rot = rotate(sci_cut, PA_V3+90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### WFSS grism is dispersed in a direction of x-axis in the plot below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(sci_rot, vmin=0, vmax=1.0)\n",
    "plt.title('Direct image')\n",
    "plt.xlabel('Wavelength direction >>>', color='r', fontsize=18)\n",
    "plt.ylabel('Cross-dispersion direction >>>', color='r', fontsize=18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.Get light profile at different x position --- This will be used for optimal extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ii in range(sci_rot.shape[1]):\n",
    "    flux_tmp = sci_rot[:,ii]\n",
    "    xx_tmp = np.arange(0, len(sci_rot[:,ii]), 1)\n",
    "    plt.plot(xx_tmp, flux_tmp, label='x=%d'%ii)\n",
    "plt.legend(loc=0, fontsize=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum along x (disperse) direction\n",
    "flux_y = np.zeros(len(sci_rot[:,0]), 'float')\n",
    "for ii in range(sci_rot.shape[0]):\n",
    "    flux_y[ii] = np.sum(sci_rot[ii,:])\n",
    "\n",
    "# Sky subtraction, if needed.\n",
    "#sky = np.mean([flux_y[0], flux_y[-1]])\n",
    "\n",
    "# Normalize;\n",
    "flux_y[:] /= flux_y.sum()\n",
    "\n",
    "plt.plot(xx_tmp, flux_y)\n",
    "plt.xlabel('y-position')\n",
    "plt.ylabel('Source Flux')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.One-dimensional extraction;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show pipeline 1D extraction as an example;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normal extraction;\n",
    "flux_disp1 = np.zeros(x2d, 'float')\n",
    "err_disp1 = np.zeros(x2d, 'float')\n",
    "wave_disp1 = np.zeros(x2d, 'float')\n",
    "    \n",
    "for ii in range(x2d): # Wavelength direction.\n",
    "    mask_tmp = (dq_2d[:,ii] == 0) & (err_2d[:,ii]>0)\n",
    "\n",
    "    # Sum within a box;\n",
    "    flux_disp1[ii] = np.sum(data_2d[:,ii][mask_tmp]) \n",
    "    err_disp1[ii] = np.sqrt(np.sum(err_2d[:,ii][mask_tmp]**2)) \n",
    "    wave_disp1[ii] = wave_2d[0,ii]\n",
    "\n",
    "plt.errorbar(wave_disp1, flux_disp1, yerr=err_disp1)\n",
    "plt.xlim(1.7,2.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimal extraction;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Following Horne(1986, PASP, 98, 609);\n",
    "flux_disp = np.zeros(x2d, 'float')\n",
    "err_disp = np.zeros(x2d, 'float')\n",
    "wave_disp = np.zeros(x2d, 'float')\n",
    "\n",
    "# Sigma clipping.\n",
    "sig = 5.0\n",
    "\n",
    "for ii in range(x2d): # ii : wavelength element.\n",
    "    # Mask; \n",
    "    # 1. DQ array\n",
    "    # 2. error value\n",
    "    # 3. CR detection\n",
    "    mask_tmp = (dq_2d[:,ii] == 0) & (err_2d[:,ii]>0) & ( (data_2d[:,ii] - flux_y[:] * flux_disp1[ii])**2 < sig**2 * err_2d[:,ii]**2)\n",
    "    ivar = 1. / err_2d[:,ii]**2\n",
    "\n",
    "    num = flux_y[:] * data_2d[:,ii] * ivar\n",
    "    den = flux_y[:]**2 * ivar\n",
    "    flux_disp[ii] = num[mask_tmp].sum(axis=0) / den[mask_tmp].sum(axis=0)\n",
    "    err_disp[ii] = np.sqrt(1./den[mask_tmp].sum(axis=0))\n",
    "    wave_disp[ii] = wave_2d[0,ii]\n",
    "    \n",
    "plt.errorbar(wave_disp, flux_disp, yerr=err_disp)\n",
    "plt.xlim(1.7,2.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare;\n",
    "plt.errorbar(wave_disp, flux_disp, yerr=err_disp, color='r', label='Optimal')\n",
    "plt.errorbar(wave_disp1, flux_disp1, yerr=err_disp1, color='b', alpha=0.5, label='Box')\n",
    "plt.ylim(-10, 20000)\n",
    "plt.legend(loc=0)\n",
    "plt.xlabel('Wavelength')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.Write 1d spectrum out to a file;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_1d = '%sl3_nis_%s_%s_s%s_1d_opt.fits'%(DIR_OUT, filt, grism, id)\n",
    "\n",
    "# Now make it into a Spectrum1D instance.\n",
    "obs = Spectrum1D(spectral_axis=wave_disp*u.um,\n",
    "                 flux=flux_disp*u.MJy,\n",
    "                 uncertainty=StdDevUncertainty(err_disp), unit='MJy')\n",
    "obs.write(file_1d, format='tabular-fits', overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.Light profile along x-axis = Resolution of dispersed spectrum;\n",
    "As WFSS does not have a slit, any dispersed spectrum is affected by source morphology. The estimate on the effective spectral resolution will be needed in the following notebook. And we here try to estimate it beforehand;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ii in range(sci_rot.shape[0]):\n",
    "    flux_tmp = sci_rot[ii,:]\n",
    "    xx_tmp = np.arange(0, len(sci_rot[ii,:]), 1)\n",
    "    plt.plot(xx_tmp, flux_tmp, label='y=%d'%(ii))\n",
    "    \n",
    "plt.legend(loc=1, fontsize=8)\n",
    "plt.xlabel('Wavelength direction')\n",
    "plt.title('Source light profile along dispersed direction', fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Unless you are interested in spatially resolved spectra, you can stack and get light profile as a good approximation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum along cross-disperse direction\n",
    "flux_x = np.zeros(len(sci_rot[0,:]), 'float')\n",
    "for ii in range(sci_rot.shape[0]):\n",
    "    flux_x[ii] = np.sum(sci_rot[:,ii])\n",
    "\n",
    "# Normalize;\n",
    "flux_x[:] /= flux_x.sum()\n",
    "\n",
    "plt.plot(xx_tmp, flux_x, label='Convolution kernel')\n",
    "plt.legend(loc=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit with a moffat function;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting function with Moffat\n",
    "\n",
    "# Moffat fnc.\n",
    "def moffat(xx, A, x0, gamma, alp):\n",
    "    yy = A * (1. + (xx-x0)**2/gamma**2)**(-alp)\n",
    "    return yy\n",
    "\n",
    "def fit_mof(xx, lsf):\n",
    "    #xx = lsf * 0\n",
    "    #for ii in range(len(lsf)):\n",
    "    #    xx[ii] = ii - len(lsf)/2.\n",
    "    popt, pcov = curve_fit(moffat, xx, lsf)\n",
    "    return popt\n",
    "\n",
    "def LSF_mof(xsf, lsf, f_plot=True):\n",
    "    '''\n",
    "    Input:\n",
    "    =======\n",
    "    xsf : x axis for the profile.\n",
    "    lsf : light profile.    \n",
    "    '''\n",
    "    \n",
    "    #for ii in range(len(sci[0,:])):\n",
    "    #    lsf[ii] = np.mean(sci_rot[int(height/2.-5):int(height/2.+5), ii])\n",
    "    #    xsf[ii] = ii - len(lsf)/2.\n",
    "\n",
    "    try:\n",
    "        A, xm, gamma, alpha = fit_mof(xsf, lsf)\n",
    "    except RuntimeError:\n",
    "        print('Fitting failed.')\n",
    "        A, xm, gamma, alpha = -1, -1, -1, -1\n",
    "        pass\n",
    "\n",
    "    if A>0:\n",
    "        lsf_mod = moffat(xsf, A, 0, gamma, alpha)\n",
    "        \n",
    "    if f_plot:\n",
    "        yy = moffat(xsf, A, xm, gamma, alpha)\n",
    "        plt.plot(xsf, yy, 'r.', ls='-', label='Data')\n",
    "        plt.plot(xsf, lsf_mod, 'b+', ls='-', label='Model:$gamma=%.2f$\\n$alpha=%.2f$'%(gamma, alpha))\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    \n",
    "    return A, xm, gamma, alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSF, line spread function\n",
    "iix_peak = np.argmax(flux_x)\n",
    "xx_tmp_shift = xx_tmp - xx_tmp[iix_peak]\n",
    "A, xm, gamma, alpha = LSF_mof(xx_tmp_shift, flux_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write it down;\n",
    "# Tha parameters are in unit of pixel.\n",
    "fm = open('%sl3_nis_%s_%s_s%s_moffat.txt'%(DIR_OUT, filt, grism, id), 'w')\n",
    "fm.write('# A x0 gamma alp\\n')\n",
    "fm.write('# Moffat function\\n')\n",
    "fm.write('%.3f %.3f %.3f %.3f\\n'%(A, xm, gamma, alpha))\n",
    "\n",
    "fm.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repeat for other filters, other objects.\n",
    "### The following big colum executes the same processes above for other filters and dither position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grism = 'G150C'\n",
    "id = '00004'\n",
    "DIR_OUT = './output/'\n",
    "if not os.path.exists(DIR_OUT):\n",
    "    os.mkdir(DIR_OUT)\n",
    "\n",
    "filts = ['f115w', 'f150w', 'f200w']\n",
    "ndithers = np.arange(0, 2, 1)\n",
    "\n",
    "sig = 5.0\n",
    "\n",
    "for filt in filts:\n",
    "    print(filt)\n",
    "    \n",
    "    # 2d spectrum;\n",
    "    file_2d = '%sl3_nis_%s_%s_s%s_cal.fits'%(DIR_DATA, filt, grism, id)\n",
    "    hdu_2d = fits.open(file_2d)\n",
    "\n",
    "    for ndither in ndithers:\n",
    "        print(ndither)\n",
    "\n",
    "        if grism == 'G150C':\n",
    "            # If spectrum is horizontal;\n",
    "            data_2d = hdu_2d[ndither*7+1].data\n",
    "            dq_2d = hdu_2d[ndither*7+2].data\n",
    "            err_2d = hdu_2d[ndither*7+3].data\n",
    "            wave_2d = hdu_2d[ndither*7+4].data\n",
    "        else:\n",
    "            data_2d = rotate(hdu_2d[ndither*7+1].data, 90)\n",
    "            dq_2d = rotate(hdu_2d[ndither*7+2].data, 90)\n",
    "            err_2d = rotate(hdu_2d[ndither*7+3].data, 90)\n",
    "            wave_2d = rotate(hdu_2d[ndither*7+4].data, 90)\n",
    "\n",
    "        y2d,x2d = data_2d.shape[:]\n",
    "\n",
    "        plt.close()\n",
    "        plt.imshow(data_2d, vmin=0, vmax=300)\n",
    "        plt.show()\n",
    "\n",
    "        # Re-extract 2d image;\n",
    "        #if ndither == 0:\n",
    "        rsq = y2d\n",
    "        sci_cut = data[int(ycen-rsq/2.+0.5):int(ycen+rsq/2.+0.5), int(xcen-rsq/2.+0.5):int(xcen+rsq/2.+0.5)]\n",
    "        seg_cut = segdata[int(ycen-rsq/2.+0.5):int(ycen+rsq/2.+0.5), int(xcen-rsq/2.+0.5):int(xcen+rsq/2.+0.5)]\n",
    "\n",
    "        # Not sure if the offset in extractioin box is bug ;\n",
    "        if grism == 'G150C':\n",
    "            sci_rot = rotate(sci_cut, PA_V3+0)\n",
    "        else:\n",
    "            sci_rot = rotate(sci_cut, PA_V3+0+90)\n",
    "\n",
    "\n",
    "        #\n",
    "        # This is for spectral resolution;\n",
    "        #\n",
    "        # Get light profile along the x-axis\n",
    "        for ii in range(sci_rot.shape[0]):\n",
    "            flux_tmp = sci_rot[ii,:]\n",
    "            xx_tmp = np.arange(0, len(sci_rot[ii,:]), 1)\n",
    "\n",
    "        # Sum along cross-disperse direction\n",
    "        flux_x = np.zeros(len(sci_rot[0,:]), 'float')\n",
    "        for ii in range(sci_rot.shape[0]):\n",
    "            flux_x[ii] = np.sum(sci_rot[ii,:])\n",
    "\n",
    "        # Normalize;\n",
    "        flux_x[:] /= flux_x.sum()\n",
    "\n",
    "        # LSF\n",
    "        iix_peak = np.argmax(flux_x)\n",
    "        xx_tmp_shift = xx_tmp - xx_tmp[iix_peak]\n",
    "        A, xm, gamma, alpha = LSF_mof(xx_tmp_shift, flux_x)\n",
    "\n",
    "        if ndither == 0:\n",
    "            # Write it down;\n",
    "            fm = open('%sl3_nis_%s_%s_s%s_moffat.txt'%(DIR_OUT, filt, grism, id), 'w')\n",
    "            fm.write('# A x0 gamma alp\\n')\n",
    "            fm.write('# Moffat function\\n')\n",
    "            fm.write('%.3f %.3f %.3f %.3f\\n'%(A, xm, gamma, alpha))\n",
    "            fm.close()\n",
    "\n",
    "        #\n",
    "        # This is for Optimal extraction;\n",
    "        #\n",
    "        # Sum along x (disperse) direction\n",
    "        flux_y = np.zeros(len(sci_rot[:,0]), 'float')\n",
    "        for ii in range(sci_rot.shape[0]):\n",
    "            flux_y[ii] = np.sum(sci_rot[ii,:])\n",
    "            \n",
    "        # Normalize;\n",
    "        flux_y[:] /= flux_y.sum()\n",
    "\n",
    "\n",
    "        # Following Horne;\n",
    "        flux_disp = np.zeros(x2d, 'float')\n",
    "        err_disp = np.zeros(x2d, 'float')\n",
    "        wave_disp = np.zeros(x2d, 'float')\n",
    "\n",
    "        for ii in range(x2d):\n",
    "            # Mask; \n",
    "            # 1. DQ array\n",
    "            # 2. error value\n",
    "            # 3. CR detection\n",
    "            mask_tmp = (dq_2d[:,ii] == 0) & (err_2d[:,ii] > 0)\n",
    "            ivar = 1. / err_2d[:,ii]**2\n",
    "\n",
    "            num = flux_y[:] * data_2d[:,ii] * ivar \n",
    "            den = flux_y[:]**2 * ivar\n",
    "            flux_disp[ii] = num[mask_tmp].sum(axis=0)/den[mask_tmp].sum(axis=0)\n",
    "            err_disp[ii] = np.sqrt(1./den[mask_tmp].sum(axis=0))\n",
    "            wave_disp[ii] = wave_2d[0,ii]\n",
    "\n",
    "\n",
    "        plt.close()\n",
    "        con_plot = (wave_disp>0)\n",
    "        plt.errorbar(wave_disp[con_plot], flux_disp[con_plot], yerr=err_disp[con_plot])\n",
    "        plt.ylim(-0, 3000)\n",
    "        plt.show()\n",
    "\n",
    "        # Wirte:\n",
    "        # Now make it into a Spectrum1D instance.\n",
    "        file_1d = '%sl3_nis_%s_%s_s%s_ndither%d_1d_opt.fits'%(DIR_OUT, filt, grism, id, ndither)\n",
    "\n",
    "        if wave_disp[1] - wave_disp[0] < 0:\n",
    "            obs = Spectrum1D(spectral_axis=wave_disp[::-1]*u.um,\n",
    "                             flux=flux_disp[::-1]*u.MJy,\n",
    "                             uncertainty=StdDevUncertainty(err_disp[::-1]), unit='MJy')\n",
    "        else:\n",
    "            obs = Spectrum1D(spectral_axis=wave_disp*u.um,\n",
    "                             flux=flux_disp*u.MJy,\n",
    "                             uncertainty=StdDevUncertainty(err_disp), unit='MJy')\n",
    "            \n",
    "        obs.write(file_1d, format='tabular-fits', overwrite=True)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another object;\n",
    "Absorption line galaxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grism = 'G150C'\n",
    "id    = '00003'\n",
    "DIR_OUT = './output/'\n",
    "\n",
    "filts  = ['f115w', 'f150w', 'f200w']\n",
    "ndithers = np.arange(0,2,1) # There are four dithers in the data set;\n",
    "\n",
    "sig = 5.0\n",
    "\n",
    "for filt in filts:\n",
    "    print(filt)\n",
    "    # 2d spectrum;\n",
    "    file_2d = '%sl3_nis_%s_%s_s%s_cal.fits'%(DIR_DATA, filt, grism, id)\n",
    "    hdu_2d = fits.open(file_2d)\n",
    "\n",
    "    for ndither in ndithers:\n",
    "        print(ndither)\n",
    "        if grism == 'G150C':\n",
    "            # If spectrum is horizontal;\n",
    "            data_2d = hdu_2d[ndither*7+1].data\n",
    "            dq_2d   = hdu_2d[ndither*7+2].data\n",
    "            err_2d  = hdu_2d[ndither*7+3].data\n",
    "            wave_2d = hdu_2d[ndither*7+4].data\n",
    "        else:\n",
    "            data_2d = rotate(hdu_2d[ndither*7+1].data, 90)\n",
    "            dq_2d   = rotate(hdu_2d[ndither*7+2].data, 90)\n",
    "            err_2d  = rotate(hdu_2d[ndither*7+3].data, 90)\n",
    "            wave_2d = rotate(hdu_2d[ndither*7+4].data, 90)\n",
    "\n",
    "        y2d,x2d = data_2d.shape[:]\n",
    "\n",
    "        plt.close()\n",
    "        plt.imshow(data_2d, vmin=0, vmax=20)\n",
    "        plt.show()\n",
    "\n",
    "        # Re-extract 2d image;\n",
    "        #if ndither == 0:\n",
    "        rsq = y2d\n",
    "        sci_cut = data[int(ycen-rsq/2.+0.5):int(ycen+rsq/2.+0.5), int(xcen-rsq/2.+0.5):int(xcen+rsq/2.+0.5)]\n",
    "        seg_cut = segdata[int(ycen-rsq/2.+0.5):int(ycen+rsq/2.+0.5), int(xcen-rsq/2.+0.5):int(xcen+rsq/2.+0.5)]\n",
    "\n",
    "        # Not sure if the offset in extractioin box is bug ;\n",
    "        if grism == 'G150C':\n",
    "            sci_rot = rotate(sci_cut, PA_V3+0)\n",
    "        else:\n",
    "            sci_rot = rotate(sci_cut, PA_V3+0+90)\n",
    "\n",
    "        #\n",
    "        # This is for spectral resolution;\n",
    "        #\n",
    "        # Get light profile along the x-axis\n",
    "        for ii in range(sci_rot.shape[0]):\n",
    "            flux_tmp = sci_rot[ii,:]\n",
    "            xx_tmp = np.arange(0, len(sci_rot[ii,:]), 1)\n",
    "\n",
    "        # Sum along cross-disperse direction\n",
    "        flux_x = np.zeros(len(sci_rot[0,:]), 'float')\n",
    "        for ii in range(sci_rot.shape[0]):\n",
    "            flux_x[ii] = np.sum(sci_rot[ii,:])\n",
    "\n",
    "        # Normalize;\n",
    "        flux_x[:] /= flux_x.sum()\n",
    "\n",
    "        # LSF\n",
    "        iix_peak = np.argmax(flux_x)\n",
    "        xx_tmp_shift = xx_tmp - xx_tmp[iix_peak]\n",
    "        A, xm, gamma, alpha = LSF_mof(xx_tmp_shift, flux_x)\n",
    "\n",
    "        if ndither == 0:\n",
    "            # Write it down;\n",
    "            fm = open('%sl3_nis_%s_%s_s%s_moffat.txt'%(DIR_OUT, filt, grism, id), 'w')\n",
    "            fm.write('# A x0 gamma alp\\n')\n",
    "            fm.write('# Moffat function\\n')\n",
    "            fm.write('%.3f %.3f %.3f %.3f\\n'%(A, xm, gamma, alpha))\n",
    "            fm.close()\n",
    "\n",
    "\n",
    "        #\n",
    "        # This is for Optimal extraction;\n",
    "        #\n",
    "        # Sum along x (disperse) direction\n",
    "        flux_y = np.zeros(len(sci_rot[:,0]), 'float')\n",
    "        for ii in range(sci_rot.shape[0]):\n",
    "            flux_y[ii] = np.sum(sci_rot[ii,:])\n",
    "\n",
    "            \n",
    "        # Normalize;\n",
    "        flux_y[:] /= flux_y.sum()\n",
    "\n",
    "\n",
    "        # Following Horne;\n",
    "        flux_disp = np.zeros(x2d, 'float')\n",
    "        err_disp  = np.zeros(x2d, 'float')\n",
    "        wave_disp = np.zeros(x2d, 'float')\n",
    "\n",
    "        for ii in range(x2d):\n",
    "            # Mask; \n",
    "            # 1. DQ array\n",
    "            # 2. error value\n",
    "            # 3. CR detection\n",
    "            mask_tmp = (dq_2d[:,ii] == 0) & (err_2d[:,ii] > 0) \n",
    "            ivar = 1. / err_2d[:,ii]**2\n",
    "\n",
    "            num = flux_y[:] * data_2d[:,ii] * ivar \n",
    "            den = flux_y[:]**2 * ivar\n",
    "            flux_disp[ii] = num[mask_tmp].sum(axis=0)/den[mask_tmp].sum(axis=0)\n",
    "            err_disp[ii] = np.sqrt(1./den[mask_tmp].sum(axis=0))\n",
    "            wave_disp[ii] = wave_2d[0,ii]\n",
    "\n",
    "        plt.close()\n",
    "        con_plot = (wave_disp > 0)\n",
    "        plt.errorbar(wave_disp[con_plot], flux_disp[con_plot], yerr=err_disp[con_plot])\n",
    "        plt.ylim(-20, 100)\n",
    "        plt.show()\n",
    "\n",
    "        # Wirte:\n",
    "        # Now make it into a Spectrum1D instance.\n",
    "        file_1d = '%sl3_nis_%s_%s_s%s_ndither%d_1d_opt.fits'%(DIR_OUT, filt, grism, id, ndither)\n",
    "\n",
    "        if wave_disp[1] - wave_disp[0] < 0:\n",
    "            obs = Spectrum1D(spectral_axis=wave_disp[::-1]*u.um,\n",
    "                             flux=flux_disp[::-1]*u.MJy,\n",
    "                             uncertainty=StdDevUncertainty(err_disp[::-1]), unit='MJy')\n",
    "        else:\n",
    "            obs = Spectrum1D(spectral_axis=wave_disp*u.um,\n",
    "                             flux=flux_disp*u.MJy,\n",
    "                             uncertainty=StdDevUncertainty(err_disp), unit='MJy')\n",
    "\n",
    "        obs.write(file_1d, format='tabular-fits', overwrite=True)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
