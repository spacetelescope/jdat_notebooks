{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "continental-machinery",
   "metadata": {},
   "source": [
    "# Create list of files from MAST download\n",
    "\n",
    "Credit Jo Taylor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8489a5e-7c72-49e4-b666-e4ca21d42031",
   "metadata": {},
   "source": [
    "- the dataframe portion of this notebook is now in \"03_imviz_level2\"\n",
    "- moving the files was moved to 00_mas_query_progID\n",
    "\n",
    "Do no use this notebook anymore (depricated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nasty-belize",
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.io import fits\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d38a86",
   "metadata": {},
   "source": [
    "## Get list of files with header keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db7c79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up an empty dataframe initially to fill in\n",
    "df = pd.DataFrame(columns=[\"FILENAME\",\n",
    "                           \"TARG_RA\", \n",
    "                           \"TARG_DEC\", \n",
    "                           \"FILTER\", # Grism; GR150R/GR150C\n",
    "                           \"PUPIL\", # Filter used; F090W, F115W, F140M, F150W F158M, F200W\n",
    "                           \"PATT_NUM\", # Position number within dither pattern for WFSS\n",
    "                           \"NUMDTHPT\", # Total number of points in entire dither pattern\n",
    "                           \"XOFFSET\", # X offset from pattern starting position for NIRISS (arcsec)\n",
    "                           \"YOFFSET\"]) # Y offset from pattern starting position for NIRISS (arcsec)\n",
    "\n",
    "for ratefile in glob.glob(\"data/*rate.fits\"):\n",
    "    image = fits.open(ratefile)\n",
    "    \n",
    "    # create a new dataframe for each file\n",
    "    df2 = pd.DataFrame({\"FILENAME\"   : [image[0].header[\"FILENAME\"]],\n",
    "                        \"TARG_RA\"     : [image[0].header[\"TARG_RA\"]],\n",
    "                        \"TARG_DEC\"     : [image[0].header[\"TARG_DEC\"]],\n",
    "                        \"FILTER\"     : [image[0].header[\"FILTER\"]],\n",
    "                        \"PUPIL\"      : [image[0].header[\"PUPIL\"]],\n",
    "                        \"PATT_NUM\"   : [image[0].header[\"PATT_NUM\"]],\n",
    "                        \"NUMDTHPT\"   : [image[0].header[\"NUMDTHPT\"]],\n",
    "                        \"XOFFSET\"    : [image[0].header[\"XOFFSET\"]],\n",
    "                        \"YOFFSET\"    : [image[0].header[\"YOFFSET\"]]\n",
    "                       })\n",
    "    \n",
    "    # merge the two dataframes together to create a dataframe with all \n",
    "    df = pd.concat([df, df2], ignore_index = True, axis = 0)\n",
    "    \n",
    "dfsort = df.sort_values('FILENAME', ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7002e5c9",
   "metadata": {},
   "source": [
    "## Save to csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77d81da",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfsort.to_csv(\"./list_ngdeep_rate.csv\",sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719e5a24",
   "metadata": {},
   "source": [
    "## Move files to preferred location"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a195ca",
   "metadata": {},
   "source": [
    "At this point, I move the rate files and the association files to a preferred place on my machine:\n",
    "- all rate files under NGDEEP/rate\n",
    "- level 2 association files under NGDEEP/asn_level2\n",
    "- level 3 association files under NGDEEP/asn_level3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc1b5c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# first, make all of the new directories\n",
    "topdir = 'data/NGDEEP'\n",
    "if not os.path.exists(topdir):\n",
    "    os.mkdir(topdir)\n",
    "    print('Created:', topdir)\n",
    "\n",
    "for subdir in ['rate', 'asn_level2', 'asn_level3']:\n",
    "    new_subdir = os.path.join(topdir, subdir)\n",
    "    if not os.path.exists(new_subdir):\n",
    "        os.mkdir(new_subdir)\n",
    "        print('Created:', new_subdir)\n",
    "\n",
    "file_dict = {'rate' : 'rate',\n",
    "             'image3' : 'asn_level3',\n",
    "             'image2' : 'asn_level2'}\n",
    "\n",
    "# now move all of the files to the appropriate locations\n",
    "for filename in glob.glob('data/*.fits') + glob.glob('data/*.json'):\n",
    "    try:\n",
    "        index = filename.split('_')[2] # json files; looking for image2/image3\n",
    "        subdir = file_dict[index]\n",
    "    except KeyError:\n",
    "        try:\n",
    "            index2 = filename.split('_')[-1].split('.')[0] # rate files\n",
    "            subdir = file_dict[index2]\n",
    "        except KeyError:\n",
    "            print(f'Unrecognized index: {index} or {index2}')\n",
    "            continue\n",
    "    \n",
    "    new_file = os.path.join(topdir, subdir, os.path.basename(filename))\n",
    "    os.rename(filename, new_file)\n",
    "    print(f'Moved: {filename} to {new_file}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935d05d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
