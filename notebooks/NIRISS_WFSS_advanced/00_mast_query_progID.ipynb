{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "592da8da",
   "metadata": {},
   "source": [
    "# Get observations from program ID\n",
    "This notebook uses the python [astroquery.mast Observations](https://astroquery.readthedocs.io/en/latest/mast/mast_obsquery.html) class of the [MAST API](https://mast.stsci.edu/api/v0/) to query specific data products of a specific program. We are looking for NIRISS imaging and WFSS files of the [NGDEEP program](https://www.stsci.edu/jwst/phase2-public/2079.pdf) (ID 2079). The observations are in three [NIRISS filters](https://jwst-docs.stsci.edu/jwst-near-infrared-imager-and-slitless-spectrograph/niriss-instrumentation/niriss-pupil-and-filter-wheels): F115W, F150W, and F200W using both GR150R and GR150C grisms.\n",
    "\n",
    "**Use case**: use MAST to download data products.<br>\n",
    "**Data**: JWST/NIRISS images and spectra from program 2079.<br>\n",
    "**Tools**: astropy, astroquery, numpy, os, glob, (yaml)<br>\n",
    "**Cross-instrument**: all<br>\n",
    "\n",
    "**Content**\n",
    "- [Imports](#imports)\n",
    "- [Querying for Observations](#setup)\n",
    "  - [Search with Proposal ID](#propid)\n",
    "  - [Search with Observation ID](#obsid)\n",
    "- [Filter and Download Products](#filter)\n",
    "  - [Filtering Data Before Downloading](#filter_data)\n",
    "  - [Downloading Data](#downloading)\n",
    "- [Reorganize Directory Structure](#reorg)\n",
    "\n",
    "\n",
    "**Author**: Camilla Pacifici (cpacifici@stsci.edu) & Rachel Plesha (rplesha@stsci.edu)<br>\n",
    "**Last modified**: January 2024\n",
    "\n",
    "This notebook was inspired by the [JWebbinar session about MAST](https://github.com/spacetelescope/jwebbinar_prep/blob/main/mast_session/Crowded_Field/Crowded_Field.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff93c82c",
   "metadata": {},
   "source": [
    "<a id='imports'></a>\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e92dee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy import units as u\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy.io import fits\n",
    "from astroquery.mast import Observations\n",
    "import numpy as np\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008fcb1e",
   "metadata": {},
   "source": [
    "<a id='setup'></a>\n",
    "## Querying for Observations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9562f354",
   "metadata": {},
   "source": [
    "The observations class in ``astroquery.mast`` is used to download JWST data. Use the metadata function to see the available search options and their descriptions.\n",
    "\n",
    "Note that for JWST, the instrument names have a specific format. More information about that can be found at: https://outerspace.stsci.edu/display/MASTDOCS/JWST+Instrument+Names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3185204",
   "metadata": {},
   "outputs": [],
   "source": [
    "Observations.get_metadata(\"observations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9447551a",
   "metadata": {},
   "source": [
    "The two most common ways to download specific datasets are by using the [proposal ID](https://www.stsci.edu/jwst/science-execution/program-information) or by using the [observation ID](https://jwst-pipeline.readthedocs.io/en/latest/jwst/data_products/file_naming.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47efd71",
   "metadata": {},
   "source": [
    "<a id='propid'></a>\n",
    "#### Search with Proposal ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569efa6d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Select the proposal ID, instrument, and some useful keywords (filters in this case).\n",
    "obs_table = Observations.query_criteria(obs_collection=[\"JWST\"], \n",
    "                                        instrument_name=[\"NIRISS/IMAGE\", \"NIRISS/WFSS\"],\n",
    "                                        provenance_name=[\"CALJWST\"], # Executed observations\n",
    "                                        filters=['F115W','F150W','F200W'],\n",
    "                                        proposal_id=[2079],\n",
    "                                       )\n",
    "\n",
    "print(len(obs_table), 'files found')\n",
    "# look at what was obtained in this query for a select number of column names of interest\n",
    "obs_table[['obs_collection', 'instrument_name', 'filters', 'target_name', 'obs_id', 's_ra', 's_dec', 't_exptime', 'proposal_id']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d358734",
   "metadata": {},
   "source": [
    "<a id='obsid'></a>\n",
    "#### Search with Observation ID\n",
    "The observation ID (obs_id) allows for flexibility of searching by the proposal ID and the observation ID because of how the JWST filenames are structured. More information about the JWST file naming conventions can be found at: https://jwst-pipeline.readthedocs.io/en/latest/jwst/data_products/file_naming.html.\n",
    "\n",
    "Additionally, there is flexibility using wildcards inside of the search criteria. For example, instead of specifying both \"NIRISS/IMAGE\" and \"NIRISS/WFSS\", we can specify \"NIRISS*\", which picks up both file modes. The wildcard also works within the obs_id, so we do not have to list all of the different IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddce5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain a list to download from a specific list of observation IDs instead\n",
    "obs_id_table = Observations.query_criteria(instrument_name=[\"NIRISS*\"],\n",
    "                                           provenance_name=[\"CALJWST\"], # Executed observations\n",
    "                                           obs_id=['jw02079-o004*'], # Searching for PID 2079 observation 004\n",
    "                                          ) \n",
    "\n",
    "print(len(obs_id_table), 'files found')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e57c3c0",
   "metadata": {},
   "source": [
    "<a id='filter'></a>\n",
    "## Filter and Download Products"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9daaeaf9",
   "metadata": {},
   "source": [
    "If there are too many files to download, the API will time out. Instead, it is better to divide the observations in batches to download one at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a653a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5 # 5 files at a time maximizes the download speed.\n",
    "\n",
    "# Let's split up our list of files, ``obs_table``, into batches according to our batch size.\n",
    "obs_batches = [obs_table[i:i+batch_size] for i in range(0, len(obs_table), batch_size)]\n",
    "print(\"How many batches?\", len(obs_batches))\n",
    "\n",
    "single_group = obs_batches[0] # Useful to inspect the files obtained from one group\n",
    "print(\"Inspect the first batch to ensure that it matches expectations of what you want downloaded:\")\n",
    "single_group['obs_collection', 'instrument_name', 'filters', 'target_name', 'obs_id', 's_ra', 's_dec', 't_exptime', 'proposal_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c7d144",
   "metadata": {},
   "source": [
    "Select the type of products needed. The various levels are:\n",
    "- uncalibrated files\n",
    "    - productType=[\"SCIENCE\"]\n",
    "    - productSubGroupDescription=['UNCAL']\n",
    "    - calib_level=[1]\n",
    "- rate images\n",
    "    - productType=[\"SCIENCE\"]\n",
    "    - productSubGroupDescription=['RATE']\n",
    "    - calib_level=[2]\n",
    "- level 2 associations for both spectroscopy and imaging\n",
    "    - productType=[\"INFO\"]\n",
    "    - productSubGroupDescription=['ASN']\n",
    "    - calib_level=[2]\n",
    "- level 3 associations for imaging\n",
    "    - productType=[\"INFO\"]\n",
    "    - productSubGroupDescription=['ASN']\n",
    "    - dataproduct_type=[\"image\"]\n",
    "    - calib_level=[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179f01e4",
   "metadata": {},
   "source": [
    "<a id='filter_data'></a>\n",
    "#### Filtering Data Before Downloading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd82b142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a dictionary of the above information to use for inspection of the filtering function\n",
    "file_dict = {'uncal' : {'product_type' : 'SCIENCE',\n",
    "                        'productSubGroupDescription' : 'UNCAL',\n",
    "                        'calib_level' : [1]},\n",
    "             'rate' : {'product_type' : 'SCIENCE',\n",
    "                       'productSubGroupDescription' : 'RATE',\n",
    "                       'calib_level' : [2]},\n",
    "             'level2_association' : {'product_type' : 'INFO',\n",
    "                                     'productSubGroupDescription' : 'ASN',\n",
    "                                     'calib_level' : [2]},\n",
    "             'level3_association' : {'product_type' : 'INFO',\n",
    "                                     'productSubGroupDescription' : 'ASN',\n",
    "                                     'calib_level' : [3]},\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed7ca65",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Look at the files existing for each of these different levels\n",
    "files_to_download = []\n",
    "for index, batch_exposure in enumerate(single_group):\n",
    "    \n",
    "    print('*'*50)\n",
    "    print(f\"Exposure #{index+1} ({batch_exposure['obs_id']})\")\n",
    "    # pull out the product names from the list to filter\n",
    "    products = Observations.get_product_list(batch_exposure)\n",
    "    \n",
    "    for filetype, query_dict in file_dict.items():\n",
    "        print('File type:', filetype)\n",
    "        filtered_products = Observations.filter_products(products,\n",
    "                                                         productType=query_dict['product_type'],\n",
    "                                                         productSubGroupDescription=query_dict['productSubGroupDescription'],\n",
    "                                                         calib_level=query_dict['calib_level'],\n",
    "                                                         )\n",
    "        print(filtered_products['productFilename'])\n",
    "        files_to_download.extend(filtered_products['productFilename'])\n",
    "        print()\n",
    "    print('*'*50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98933e6",
   "metadata": {},
   "source": [
    "From above, we can see that for each exposure name in the observation list (`obs_table`), there are many associated files in the background that need to be downloaded as well. This is why we need to work in batches to download.\n",
    "\n",
    "<a id='downloading'></a>\n",
    "#### Downloading Data\n",
    "To actually download the products, provide ``Observations.download_products()`` with a list of the filtered products. \n",
    "\n",
    "If the data are proprietary, you may also need to set up your API token. **NEVER** commit your token to a public repository. An alternative is to create a separate configuration file (config_file.yaml) that is readable only to you and has a key: 'mast_token' : _API token_\n",
    "\n",
    "To make create a new API token visit to following link: \n",
    "    https://auth.mast.stsci.edu/token?suggested_name=Astroquery&suggested_scope=mast:exclusive_access"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fc1897a3",
   "metadata": {},
   "source": [
    "# if needed, create a separate configuration file and replace Observations.download_products() with the following:\n",
    "\n",
    "import yaml\n",
    "\n",
    "with open(config_file) as f:\n",
    "    mast_config = yaml.safe_load(f)\n",
    "        \n",
    "mysession = Observations(mast_config['mast_token'])\n",
    "mysession.download_products(filtered_products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616ff15c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "download_dir = 'data'\n",
    "\n",
    "# Now let's get the products for each batch of observations, and filter down to only the products of interest.\n",
    "for index, batch in enumerate(obs_batches):\n",
    "    \n",
    "    # Progress indicator...\n",
    "    print('\\n'+f'Batch #{index+1} / {len(obs_batches)}')\n",
    "    \n",
    "    # Make a list of the `obsid` identifiers from our Astropy table of observations to get products for.\n",
    "    obsids = batch['obsid']\n",
    "    print('Working with the following ``obsid``s:')\n",
    "    for number, obs_text in zip(obsids, batch['obs_id']):\n",
    "        print(f\"{number} : {obs_text}\")\n",
    "    \n",
    "    # Get list of products \n",
    "    products = Observations.get_product_list(obsids)\n",
    "    \n",
    "    # Filter the products to only get only the products of interest\n",
    "    filtered_products = Observations.filter_products(products, \n",
    "                                                     productType=[\"SCIENCE\", \"INFO\"],\n",
    "                                                     productSubGroupDescription=[\"RATE\", \"ASN\"], # Not using \"UNCAL\" here since we can start with the rate files\n",
    "                                                     calib_level=[2, 3] # not using 1 here since not getting the UNCAL files\n",
    "                                                    )\n",
    "    # Download products for these records.\n",
    "    manifest = Observations.download_products(filtered_products,\n",
    "                                              download_dir=download_dir,\n",
    "                                              flat=True, # astroquery v0.4.7 or later only\n",
    "                                              ) \n",
    "    print('Products downloaded:\\n', filtered_products['productFilename'])\n",
    "    \n",
    "    # only downloading the first batch of 5 observations\n",
    "    break # comment this out if you want to download everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39310ec6-f58c-4dd6-96ba-b5cda55ee7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "downloaded_files = glob.glob(os.path.join(download_dir, '*.fits')) + glob.glob(os.path.join(download_dir, '*.json'))\n",
    "print(len(downloaded_files), 'files downloaded to:', download_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1eb6450",
   "metadata": {},
   "source": [
    "<a id='reorg'></a>\n",
    "## Reorganize Directory Structure\n",
    "\n",
    "This section takes the downloaded data and sorts it into a slightly different file structure to work with later in the notebooks. The expected format for this section is that all downloaded data are in a single directory (`flat=True`). The new file stucture is as follows:\n",
    "- all rate files under NGDEEP/rate\n",
    "- level 2 association files under NGDEEP/asn_level2\n",
    "- level 3 association files under NGDEEP/asn_level3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5688a317",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, make all of the new directories\n",
    "topdir = 'data/NGDEEP'\n",
    "if not os.path.exists(topdir):\n",
    "    os.mkdir(topdir)\n",
    "    print('Created:', topdir)\n",
    "\n",
    "for subdir in ['rate', 'asn_level2', 'asn_level3']:\n",
    "    new_subdir = os.path.join(topdir, subdir)\n",
    "    if not os.path.exists(new_subdir):\n",
    "        os.mkdir(new_subdir)\n",
    "        print('Created:', new_subdir)\n",
    "\n",
    "file_dict = {'rate' : 'rate',\n",
    "             'image2' : 'asn_level2',\n",
    "             'spec2' : 'asn_level2',\n",
    "             'image3' : 'asn_level3',\n",
    "             'spec3' : 'asn_level3',\n",
    "            }\n",
    "\n",
    "# now move all of the files to the appropriate locations\n",
    "for filename in glob.glob('data/*.fits') + glob.glob('data/*.json'):\n",
    "    try:\n",
    "        index = filename.split('_')[2] # json files; looking for image2/image3 or spec2/spec3\n",
    "        subdir = file_dict[index]\n",
    "    except KeyError:\n",
    "        try:\n",
    "            index2 = filename.split('_')[-1].split('.')[0] # rate files\n",
    "            subdir = file_dict[index2]\n",
    "        except KeyError:\n",
    "            print(f'Unrecognized index: {index} or {index2}')\n",
    "            continue\n",
    "    \n",
    "    new_file = os.path.join(topdir, subdir, os.path.basename(filename))\n",
    "    os.rename(filename, new_file)\n",
    "    print(f'Moved: {filename} to {new_file}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0e1d71",
   "metadata": {},
   "source": [
    "<img style=\"float: right;\" src=\"https://raw.githubusercontent.com/spacetelescope/notebooks/master/assets/stsci_pri_combo_mark_horizonal_white_bkgd.png\" alt=\"Space Telescope Logo\" width=\"200px\"/>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
