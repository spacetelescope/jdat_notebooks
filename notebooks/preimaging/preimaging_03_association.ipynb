{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NIRCam Preimaging: Pipeline Stage 3\n",
    "\n",
    "\n",
    "**Use case:** Running JWST Pipeline on NIRCam Preimaging Simulations.<br>\n",
    "**Data:** JWST simulated NIRCam data from MIRAGE; LMC.<br>\n",
    "**Tools:**  jwst.<br>\n",
    "**Cross-intrument:** NIRCam. <br>\n",
    "**Documentation:** This notebook is part of a STScI's larger [post-pipeline Data Analysis Tools Ecosystem](https://jwst-docs.stsci.edu/jwst-post-pipeline-data-analysis).<br>\n",
    "\n ",
    "## Introduction\n",
    "\n",
    "In this Notebook we show how to create the association needed to execute calwebb_image3 and how to run calwebb_image3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting things up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "from astropy.io import fits\n",
    "from astropy import wcs\n",
    "from astropy.io import ascii\n",
    "from astropy.table import Table\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import json\n",
    "import yaml\n",
    "from sys import exit\n",
    "from shapely.geometry import Polygon \n",
    "import sys\n",
    "import shapely.ops as so\n",
    "\n",
    "from jwst.pipeline import Image3Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Polygon as leopolygon\n",
    "from matplotlib.collections import PatchCollection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='./.' # This is the working directory.\n",
    "\n",
    "os.chdir(path)\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change parameters here\n",
    "filtname = 'f150w'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather the F150W *cal.fits files back in the working directory\n",
    "cwd = os.getcwd()\n",
    "filter_pattern = os.path.join(cwd, '*_cal.fits') \n",
    "files = glob(filter_pattern)[:] \n",
    "namelist = []\n",
    "outlist = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This next cell only needs to be executed for this version of the notebook, which only runs the pipeline for one pointing due to file size limitations. You can comment out with more than one pointing or set of exposures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = files[:]+files[:]\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We convert corner pixel coordinates to world coordinates \n",
    "coord = []\n",
    "\n",
    "for file in files:\n",
    "    hdulist = fits.open(file)\n",
    "    \n",
    "    # Parse the WCS keywords in the primary HDU\n",
    "    w = wcs.WCS(hdulist[1].header, naxis=2)\n",
    "    \n",
    "    # Print out the \"name\" of the WCS, as defined in the FITS header\n",
    "    # print(w.wcs.name)\n",
    "\n",
    "    # Three pixel coordinates of interest.\n",
    "    # Note we've silently assumed a NAXIS=2 image here\n",
    "    pixcrd = np.array([[0, 0], [2048, 0], [2048, 2048], [0, 2048]], np.float_)\n",
    "    \n",
    "    # Convert pixel coordinates to world coordinates\n",
    "    world = w.wcs_pix2world(pixcrd, 0)\n",
    "    #world = w.wcs_pix2world([[0, 0], [2048, 0], [2048, 2048], [0, 2048]], 0)\n",
    "    coord.append(world)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we read the input source catalogue\n",
    "pointsource_catalog = Table.read('./preimaging/pointsource_LMCcalField_F150W.cat', format='ascii')\n",
    "pointsource_ra = pointsource_catalog['x_or_RA']\n",
    "pointsource_dec = pointsource_catalog['y_or_Dec']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We plot the field of view of the simulated images (blue) on top of the source catalogue (red)\n",
    "\n",
    "fig = plt.figure(num=None, figsize=(12, 12), dpi=80, facecolor='w', edgecolor='k')\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "ax.scatter(pointsource_ra, pointsource_dec, c='red', label='Catalog point sources', s=0.1)\n",
    "\n",
    "for m in range(len(files)):\n",
    "    rect1 = matplotlib.patches.Polygon(coord[m], edgecolor='red', \n",
    "                                       facecolor='blue', alpha=0.2)\n",
    "    ax.add_patch(rect1)\n",
    "rect1.set_label('Detector')\n",
    "\n",
    "# These limits correspond to the LMC \n",
    "plt.xlim([80.2, 80.8]) # alpha\n",
    "plt.ylim([-69.4, -69.6]) # delta\n",
    "plt.xlabel('RA (degrees)')\n",
    "plt.ylabel('Dec (degrees)')\n",
    "plt.title('F150W Mosaic')\n",
    "#plt.axis('scaled')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to create an association for stage 3 of the pipeline, we need to check that each image contains sources from the catalog and that the images overlap in such a way that they make a continuous mosaic.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "current_detector_idx = None\n",
    "current_detector = None\n",
    "current_detector_coords = None\n",
    "\n",
    "number_detectors = len(files)\n",
    "detectors = files[:]\n",
    "detector_coords = coord[:]\n",
    "referencia = None\n",
    "\n",
    "finallist = []\n",
    "finalcoords = []\n",
    "\n",
    "for iteration in range(number_detectors):\n",
    "    \n",
    "    # if this is the first iteration, initialize variables\n",
    "    if iteration == 0:\n",
    "        current_detector_idx = 0 # select first image\n",
    "        covfile = [100]\n",
    "    else:\n",
    "        covfile = []\n",
    "        \n",
    "        # calculate the overlap with all the rest of the files\n",
    "        maxcoverage = 0.0\n",
    "        best_overlap_index = None\n",
    "        for m in range(len(detectors)):\n",
    "            detector = Polygon(detector_coords[m])\n",
    "            coverage = detector.intersection(referencia).area\n",
    "\n",
    "            covfile.append(round(100 * coverage / detector.area))\n",
    "\n",
    "            if covfile[m] >= maxcoverage: \n",
    "                maxcoverage = covfile[m]\n",
    "                best_overlap_index = m\n",
    "                \n",
    "        if maxcoverage == 0.0:\n",
    "            print('Some images are excluded')\n",
    "            print('Number of excluded images: ', len(detectors))\n",
    "            break\n",
    "            \n",
    "        # select the file with the maximum overlap\n",
    "        \n",
    "        # print overlap values\n",
    "        # print(covfile)\n",
    "        # print(best_overlap_index, covfile[best_overlap_index])\n",
    "        \n",
    "        # we set current index to the best overlap\n",
    "        current_detector_idx = best_overlap_index\n",
    "\n",
    "    # remove the image from list and its coordinates\n",
    "    current_detector = detectors.pop(current_detector_idx)\n",
    "    current_detector_coords = detector_coords.pop(current_detector_idx)\n",
    "    \n",
    "    referencia = Polygon(current_detector_coords) if iteration == 0 else referencia.union(Polygon(current_detector_coords))\n",
    "         \n",
    "    print('removing current detector ' + current_detector)\n",
    "    finallist.append(current_detector)\n",
    "    finalcoords.append(current_detector_coords)\n",
    "\n",
    "\n",
    "    # Plot \n",
    "    # ----\n",
    "    fig = plt.figure(num=None, figsize=(12, 12), dpi=80, facecolor='w', edgecolor='k')\n",
    "    ax = fig.add_subplot(111)\n",
    "    \n",
    "    rect1 = leopolygon([\n",
    "        (80.3125, -69.4950), \n",
    "        (80.4958, -69.4392), \n",
    "        (80.6625, -69.5022), \n",
    "        (80.4792, -69.5564)], color='yellow')\n",
    "    \n",
    "    ax.add_patch(rect1)\n",
    "    \n",
    "    rect2 = leopolygon(current_detector_coords, edgecolor='navy', \n",
    "                       facecolor='navy', alpha=0.8)\n",
    "    \n",
    "    new_shape = so.cascaded_union(referencia)\n",
    "    xs, ys = new_shape.exterior.xy\n",
    "    \n",
    "    ax.fill(xs, ys, alpha=0.8, fc='red', ec='red')\n",
    "\n",
    "    ax.add_patch(rect2)\n",
    "    \n",
    "    plt.xlim([80.2, 80.8]) # RA\n",
    "    plt.ylim([-69.4, -69.6]) # Dec\n",
    "    \n",
    "    plt.title('coverage = {}% \\n {}'.format(str(covfile[current_detector_idx]), \n",
    "                                            current_detector), fontsize=15)\n",
    "    plt.xlabel('RA (degrees)')\n",
    "    plt.ylabel('Dec (degrees)')\n",
    "    \n",
    "    pdfname = 'figure_' + str(len(finallist)-1)\n",
    "    # plt.savefig(pdfname) \n",
    "  \n",
    "    plt.show()\n",
    "     \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finallist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we need to go through the final list and calculate the overlap \n",
    "with the stellar catalogue. We select the files that have an overlap of 99% or larger.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestlist = []\n",
    "\n",
    "# these coordinates represent the extent of the LMC catalogue\n",
    "referencia = Polygon([(80.3125, -69.4950), \n",
    "                      (80.4958, -69.4392), \n",
    "                      (80.6625, -69.5022), \n",
    "                      (80.4792, -69.5564)])\n",
    "\n",
    "rejected = 0\n",
    "for current_detector, current_detector_coords in zip(finallist, finalcoords):\n",
    "    detector = Polygon(current_detector_coords)\n",
    "    \n",
    "    coverage = detector.intersection(referencia).area\n",
    "    coverage = round(100 * coverage / detector.area)\n",
    "    \n",
    "    if coverage >= 50: #99 \n",
    "        bestlist.append(current_detector)\n",
    "    else:\n",
    "        rejected += 1\n",
    "        \n",
    "print('number of overlapping images = ', len(bestlist))\n",
    "print('number of rejected images = ', rejected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Detector List to an Association (JSON file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Developer Note:*\n",
    "\n",
    "There is a new way to implement the association introduced in version 0.16.0 of the JWST package. It might be worthwhile to explore."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following link provides a complete description of the association keywords.\n",
    "\n",
    "https://jwst-pipeline.readthedocs.io/en/latest/jwst/associations/level3_asn_technical.html#association-meta-keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we print a json file with the science files in the correct order\n",
    "\n",
    "association = {}\n",
    " \n",
    "association[\"asn_id\"] = \"a3001\"\n",
    "association[\"asn_pool\"] = \"none\" \n",
    "association[\"asn_rule\"] = \"Asn_Image\" \n",
    "association[\"program\"] = \"1069\" \n",
    "association[\"asn_type\"] = \"image3\" \n",
    "association[\"constraints\"] = \"No constraints\" \n",
    "association[\"target\"] = \"none\" \n",
    "association[\"version_id\"] = \"null\" \n",
    "association[\"degraded_status\"] = \"No known degraded exposures in association.\"\n",
    "    \n",
    "products_dict = {}\n",
    "\n",
    "products_dict[\"name\"] = \"lmc-\" + filtname \n",
    "products_dict[\"members\"] = []   \n",
    "for current_detector in bestlist:\n",
    "    obs_dict = {\n",
    "        \"expname\": current_detector,\n",
    "        \"exptype\": \"science\"\n",
    "    }\n",
    "    products_dict[\"members\"].append(obs_dict) \n",
    "\n",
    "association[\"products\"] = [products_dict] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save association file\n",
    "jsonfile = \"association-\" + filtname + \".json\"\n",
    "with open(jsonfile, 'w') as json_file:\n",
    "    json.dump(association, json_file, indent=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execute the third stage of the NIRCam pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we execute the third stage of the NIRCam pipeline. In this stage the pipeline creates a mosaic of the input images and extracts a source catalogue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute pipeline\n",
    "# ----------------\n",
    "\n",
    "# run Image3 pipeline to get source catalog\n",
    "im3 = Image3Pipeline()\n",
    "\n",
    "# Options \n",
    "# -------\n",
    "\n",
    "#im3.source_catalog.kernel_fwhm = # kernel_fwhm\n",
    "#im3.source_catalog.kernel_xsize = # kernel_xsize\n",
    "#im3.source_catalog.kernel_ysize = # kernel_ysize\n",
    "#im3.source_catalog.npixels = # npixels\n",
    "#im3.tweakreg_catalog.snr_threshold = 2000.0\n",
    "#im3.resample.blendheaders = False\n",
    "im3.tweakreg.skip = False\n",
    "im3.tweakreg.enforce_user_order = True\n",
    "im3.tweakreg.fitgeometry = 'shift' # valid values are 'shift', 'rscale', 'general'\n",
    "im3.tweakreg.expand_refcat = True\n",
    "im3.tweakreg.minobj = 5\n",
    "im3.tweakreg.use2dhist = True\n",
    "#im3.tweakreg.snr_threshold = 2000.0\n",
    "im3.tweakreg.save_catalogs = True\n",
    "#im3.tweakreg.xoffset = 7.5\n",
    "#im3.tweakreg.yoffset = -7.2\n",
    "im3.tweakreg.searchrad = 0.1 \n",
    "im3.skymatch.skymethod = 'global' # valid values are: 'local', 'global', 'match', or 'global+match'\n",
    "im3.source_catalog.skip = False \n",
    "im3.output_file = 'lmc-f150w-02.fits'\n",
    "\n",
    "# Execute \n",
    "# -------\n",
    "\n",
    "im3.run(jsonfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data into [Imviz](https://jdaviz.readthedocs.io/en/latest/imviz/index.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jdaviz import Imviz\n",
    "imviz = Imviz()\n",
    "imviz.show_in_sidecar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imviz.load_data('lmc-f150w-02_i2d.fits')\n",
    "viewer = imviz.default_viewer\n",
    "viewer.cuts = '95%'\n",
    "viewer.colormap_options\n",
    "viewer.set_colormap('viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
