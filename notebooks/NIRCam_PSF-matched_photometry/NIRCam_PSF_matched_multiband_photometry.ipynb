{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-Filter PSF Matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use case:** Measure galaxy photometry in an extragalactic \"blank\" field. Related to [JDox Science Use Case #22](https://jwst-docs.stsci.edu/near-infrared-camera/nircam-example-science-programs/nircam-deep-field-imaging-with-miri-imaging-parallels).<br>\n",
    "**Data:** JWST simulated NIRCam images from [JADES JWST GTO extragalactic blank field](http://fenrir.as.arizona.edu/jwstmock/).<br>\n",
    "(Williams et al. 2018) https://ui.adsabs.harvard.edu/abs/2018ApJS..236...33W.<br>\n",
    "**Tools:**  photutils, matplotlib.<br>\n",
    "**Cross-intrument:** potentially NIRISS, MIRI.<br>\n",
    "**Documentation:** This notebook is part of a STScI's larger [post-pipeline Data Analysis Tools Ecosystem](https://jwst-docs.stsci.edu/jwst-post-pipeline-data-analysis).<br>\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This notebook uses `photutils` to detect objects/galaxies in NIRCam deep imaging.  Detections are first made in a F200W image, then isophotal photometry is obtained in all 9 filters (F090W, F115W, F150W, F200W, F277W, F335M, F356W, F410M, F444W). PSF-matching is used to correct photometry measured in the Long Wavelength images (redder than F200W). \n",
    "\n",
    "After saving the photometry catalog, the notebook demonstrates how one would load the notebook in a new session. \n",
    "It demonstrates some simple analysis of the full catalog and on an individual galaxy. \n",
    "By comparing the measured colors to simulated input colors,\n",
    "it shows the measurements are more accurate after PSF corrections, though they could be improved further.\n",
    "\n",
    "The notebook analyzes only the central 1000 x 1000 pixels (30\" x 30\") of the full JADES simulation. These cutouts have been staged at STScI with permission from the authors (Williams et al.).\n",
    "\n",
    "**NOTES:** \n",
    "* This is a work in progress. More accurate photometry may be obtainable.\n",
    "\n",
    "* These JADES images are simulated using [Guitarra](https://github.com/cnaw/guitarra),\n",
    "not [MIRAGE](https://github.com/spacetelescope/mirage).\n",
    "They have different properties and units (e-/s) than JWST pipeline products (MJy/sr).\n",
    "\n",
    "* All images are aligned to the same 0.03\" pixel grid prior to analysis. This alignment can be done using [`reproject`](https://reproject.readthedocs.io), if needed.\n",
    "\n",
    "* The flux uncertainty calculations could be improved further by accounting for correlated noise and/or measuring the noise in each image more directly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Developer's Note:*  \n",
    "\n",
    "Summary of issues reported below:\n",
    "* units work with `plot` but are incompatible with `errorbar` and `text`\n",
    "* flux units can be automatically converted to AB magnitudes, \n",
    "but flux *uncertainties* cannot be automatically converted to magnitude uncertainties\n",
    "* secondary axis should automatically handle conversion between flux and AB magnitude units\n",
    "* `sharex` and `sharey` don't work with WCS `projection`\n",
    "\n",
    "And I couldn't figure out how to:  \n",
    "* Make plot axes autoscale to only *some* of plotted data\n",
    "* Make tooltips hover over data points under cursor in interactive plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check PEP 8 style formatting\n",
    "# %load_ext pycodestyle_magic\n",
    "# %flake8_on --ignore E261,E501,W291,W2,E302,E305"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages\n",
    "\n",
    "* Numpy for general array computations\n",
    "* Photutils for photometry calculations, PSF matching\n",
    "* Astropy for FITS, WCS, tables, units, color images, plotting, convolution\n",
    "* os and glob for file management\n",
    "* copy for table modfications\n",
    "* Matplotlib for plotting\n",
    "* Watermark to check versions of all imports (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from glob import glob\n",
    "from copy import deepcopy\n",
    "\n",
    "import astropy  # version 4.2 is required to write magnitudes to ecsv file\n",
    "from astropy.io import fits\n",
    "import astropy.wcs as wcs\n",
    "from astropy.table import QTable, Table\n",
    "import astropy.units as u\n",
    "from astropy.visualization import make_lupton_rgb, SqrtStretch, LogStretch, hist\n",
    "from astropy.visualization.mpl_normalize import ImageNormalize\n",
    "from astropy.convolution import Gaussian2DKernel\n",
    "from astropy.stats import gaussian_fwhm_to_sigma\n",
    "from astropy.coordinates import SkyCoord\n",
    "\n",
    "import photutils\n",
    "# print('photutils', photutils.__version__)\n",
    "from photutils import Background2D, MedianBackground, detect_sources, deblend_sources, source_properties\n",
    "from photutils.utils import calc_total_error\n",
    "\n",
    "from photutils.psf.matching import resize_psf\n",
    "from photutils import CosineBellWindow, create_matching_kernel\n",
    "from astropy.convolution import convolve, convolve_fft # , Gaussian2DKernel, Tophat2DKernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matplotlib setup for plotting\n",
    "There are two versions\n",
    " - `notebook` -- gives interactive plots, but makes the overall notebook a bit harder to scroll\n",
    " - `inline` -- gives non-interactive plots for better overall scrolling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Developer's Notes:*\n",
    "\n",
    "    `%matplotlib notebook` occasionally creates oversized plot; need to rerun cell to get it to settle back down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "# Use this version for non-interactive plots (easier scrolling of the notebook)\n",
    "%matplotlib inline\n",
    "\n",
    "# Use this version if you want interactive plots\n",
    "# %matplotlib notebook\n",
    "\n",
    "import matplotlib.ticker as ticker\n",
    "mpl_colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "\n",
    "# These gymnastics are needed to make the sizes of the figures\n",
    "# be the same in both the inline and notebook versions\n",
    "%config InlineBackend.print_figure_kwargs = {'bbox_inches': None}\n",
    "\n",
    "mpl.rcParams['savefig.dpi'] = 100\n",
    "mpl.rcParams['figure.dpi'] = 100\n",
    "\n",
    "import mplcursors  # optional to hover over plotted points and reveal ID number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show versions of Python and imported libraries\n",
    "try:\n",
    "    import watermark\n",
    "    %load_ext watermark\n",
    "    # %watermark -n -v -m -g -iv\n",
    "    %watermark -iv -v\n",
    "except ImportError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create list of images to be loaded and analyzed\n",
    "\n",
    "All data and weight images must be aligned to the same pixel grid. \n",
    "(If needed, use [`reproject`](https://reproject.readthedocs.io) to do so.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file_url = 'https://data.science.stsci.edu/redirect/JWST/jwst-data_analysis_tools/nircam_photometry/'\n",
    "\n",
    "filters = 'F090W F115W F150W F200W F277W F335M F356W F410M F444W'.split()\n",
    "wavelengths = np.array([int(filt[1:4]) / 100 for filt in filters]) * u.um  # e.g., F115W = 1.15 microns\n",
    "\n",
    "# Data images [e-/s], unlike JWST pipeline images that will have units [Myr/sr]\n",
    "image_files = {}\n",
    "for filt in filters:\n",
    "    filename = f'jades_jwst_nircam_goods_s_crop_{filt}.fits'\n",
    "    image_files[filt] = os.path.join(input_file_url, filename)\n",
    "\n",
    "# Weight images (Inverse Variance Maps; IVM)\n",
    "weight_files = {}\n",
    "for filt in filters:\n",
    "    filename = f'jades_jwst_nircam_goods_s_crop_{filt}_wht.fits'\n",
    "    weight_files[filt] = os.path.join(input_file_url, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load detection image: F200W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_filter = filt = 'F200W'\n",
    "infile = image_files[filt]\n",
    "hdu = fits.open(infile)\n",
    "data = hdu[0].data\n",
    "imwcs = wcs.WCS(hdu[0].header, hdu)\n",
    "\n",
    "weight = fits.open(weight_files[filt])[0].data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report image size and field of view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ny, nx = data.shape\n",
    "# image_pixel_scale = np.abs(hdu[0].header['CD1_1']) * 3600\n",
    "image_pixel_scale = wcs.utils.proj_plane_pixel_scales(imwcs)[0] \n",
    "image_pixel_scale *= imwcs.wcs.cunit[0].to('arcsec')\n",
    "outline = '%d x %d pixels' % (ny, nx)\n",
    "outline += ' = %g\" x %g\"' % (ny * image_pixel_scale, nx * image_pixel_scale)\n",
    "outline += ' (%.2f\" / pixel)' % image_pixel_scale\n",
    "print(outline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create color images (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 NIRCam short wavelength channel images\n",
    "r = fits.open(image_files['F200W'])[0].data\n",
    "g = fits.open(image_files['F150W'])[0].data\n",
    "b = fits.open(image_files['F090W'])[0].data\n",
    "color_image_short_wavelength = make_lupton_rgb(r, g, b, Q=5, stretch=0.02) # , minimum=-0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 NIRCam long wavelength channel images\n",
    "r = fits.open(image_files['F444W'])[0].data\n",
    "g = fits.open(image_files['F356W'])[0].data\n",
    "b = fits.open(image_files['F277W'])[0].data\n",
    "\n",
    "color_image_long_wavelength = make_lupton_rgb(r, g, b, Q=5, stretch=0.02) # , minimum=-0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Developer's Note:*\n",
    "\n",
    "    sharex & sharey appear to have some compatibility issues with projection=imwcs\n",
    "\n",
    "    As a workaround, I tried but was unable to turn off yticklabels in the right plot below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(9.5, 4))\n",
    "\n",
    "ax_sw = fig.add_subplot(1, 2, 1, projection=imwcs) # , sharex=True, sharey=True)\n",
    "ax_sw.imshow(color_image_short_wavelength, origin='lower')\n",
    "ax_sw.set_xlabel('Right Ascension')\n",
    "ax_sw.set_ylabel('Declination')\n",
    "ax_sw.set_title('Short Wavelength Channel')\n",
    "\n",
    "ax_lw = fig.add_subplot(1, 2, 2, projection=imwcs, sharex=ax_sw, sharey=ax_sw)\n",
    "ax_lw.imshow(color_image_long_wavelength, origin='lower')\n",
    "ax_lw.set_xlabel('Right Ascension')\n",
    "ax_lw.set_title('Long Wavelength Channel')\n",
    "ax_lw.set_ylabel('')\n",
    "# ax_lw.set(yticklabels=[])  # this didn't work\n",
    "\n",
    "# plt.subplots_adjust(left=0.15)\n",
    "print('Interactive zoom / pan controls both images simultaneously')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect Sources and Deblend using astropy.photutils\n",
    "https://photutils.readthedocs.io/en/latest/segmentation.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define all detection and measurement parameters here so that we do measurements consistently for every image\n",
    "\n",
    "class Photutils_Catalog:\n",
    "    def __init__(self, filt, image_file=None, verbose=True):\n",
    "        self.image_file = image_file or image_files[filt]\n",
    "        self.hdu = fits.open(self.image_file)\n",
    "        self.data = self.hdu[0].data\n",
    "        self.imwcs = wcs.WCS(self.hdu[0].header, self.hdu)\n",
    "        self.zeropoint = self.hdu[0].header['ABMAG'] * u.ABmag\n",
    "        self.weight_file = weight_files[filt]\n",
    "        self.weight = fits.open(weight_files[filt])[0].data\n",
    "        if verbose:\n",
    "            print(filt, '  zeropoint =', self.zeropoint)\n",
    "            print(self.image_file)\n",
    "            print(self.weight_file)\n",
    "        \n",
    "    def measure_background_map(self, bkg_size=50, filter_size=3, verbose=True):\n",
    "        # Calculate sigma-clipped background in cells of 50x50 pixels, then median filter over 3x3 cells\n",
    "        # For best results, the image should span an integer number of cells in both dimensions (here, 1000=20x50 pixels)\n",
    "        # https://photutils.readthedocs.io/en/stable/background.html\n",
    "        self.background_map = Background2D(self.data, bkg_size, filter_size=filter_size)\n",
    "\n",
    "    def run_detect_sources(self, nsigma, npixels, smooth_fwhm=2, kernel_size=5, \n",
    "                           deblend_levels=32, deblend_contrast=0.001, verbose=True):\n",
    "\n",
    "        # Set detection threshold map as nsigma times RMS above background pedestal\n",
    "        detection_threshold = (nsigma * self.background_map.background_rms) + self.background_map.background\n",
    "\n",
    "        # Before detection, convolve data with Gaussian\n",
    "        smooth_sigma = smooth_fwhm * gaussian_fwhm_to_sigma\n",
    "        smooth_kernel = Gaussian2DKernel(smooth_sigma, x_size=kernel_size, y_size=kernel_size)\n",
    "        smooth_kernel.normalize()\n",
    "\n",
    "        # Detect sources with npixels connected pixels at/above threshold in data smoothed by kernel\n",
    "        # https://photutils.readthedocs.io/en/stable/segmentation.html\n",
    "        self.segm_detect = detect_sources(self.data, detection_threshold, npixels=npixels, filter_kernel=smooth_kernel)\n",
    "\n",
    "        # Deblend: separate connected/overlapping sources\n",
    "        # https://photutils.readthedocs.io/en/stable/segmentation.html#source-deblending\n",
    "        self.segm_deblend = deblend_sources(self.data, self.segm_detect, npixels=npixels, filter_kernel=smooth_kernel,\n",
    "                                            nlevels=deblend_levels, contrast=deblend_contrast)\n",
    "        if verbose:\n",
    "            output = 'Cataloged %d objects' % self.segm_deblend.nlabels\n",
    "            output += ', deblended from %d detections' % self.segm_detect.nlabels\n",
    "            median_threshold = (nsigma * self.background_map.background_rms_median) \\\n",
    "                + self.background_map.background_median\n",
    "            output += ' with %d pixels above %g-sigma threshold' % (npixels, nsigma)\n",
    "            # Background outputs equivalent to those reported by SourceExtractor\n",
    "            output += '\\n'\n",
    "            output += 'Background median %g' % self.background_map.background_median\n",
    "            output += ', RMS %g' % self.background_map.background_rms_median\n",
    "            output += ', threshold median %g' % median_threshold\n",
    "            print(output)\n",
    "\n",
    "    def measure_source_properties(self, exposure_time, local_background_width=24):\n",
    "        # \"effective_gain\" = exposure time map (conversion from data rate units to counts)\n",
    "        # weight = inverse variance map = 1 / sigma_background**2 (without sources)\n",
    "        # https://photutils.readthedocs.io/en/latest/api/photutils.utils.calc_total_error.html\n",
    "        self.exposure_time_map = exposure_time * self.background_map.background_rms_median**2 * self.weight\n",
    "\n",
    "        # Data RMS uncertainty is combination of background RMS and source Poisson uncertainties\n",
    "        background_rms = 1 / np.sqrt(self.weight)\n",
    "        # effective gain parameter required to be positive everywhere (not zero), so adding small value 1e-8\n",
    "        self.data_rms = calc_total_error(self.data, background_rms, self.exposure_time_map+1e-8)\n",
    "\n",
    "        self.catalog = source_properties(self.data-self.background_map.background, self.segm_deblend, wcs=self.imwcs, \n",
    "                                         error=self.data_rms, background=self.background_map.background, \n",
    "                                         localbkg_width=local_background_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_catalog = Photutils_Catalog(detection_filter)\n",
    "detection_catalog.measure_background_map()\n",
    "detection_catalog.run_detect_sources(nsigma=2, npixels=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measure photometry (and more) in detection image\n",
    "https://photutils.readthedocs.io/en/latest/segmentation.html#centroids-photometry-and-morphological-properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exposure_time = hdu[0].header.get('EXPTIME')  # seconds\n",
    "exposure_time = 49500  # seconds; Adding by hand because it's missing from the image header\n",
    "detection_catalog.measure_source_properties(exposure_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save segmentation map of detected objects\n",
    "segm_hdu = fits.PrimaryHDU(detection_catalog.segm_deblend.data.astype(np.uint32), header=imwcs.to_header())\n",
    "segm_hdu.writeto('JADES_detections_segm.fits', overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show detections alongside images (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Developer's Note:*\n",
    "\n",
    "    Interactive plots zoom / pan all frames simultaneously. (User can zoom in on individual galaxies.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 3, sharex=True, sharey=True, figsize=(9.5, 6))\n",
    "# fig, ax = plt.subplots(2, 3, sharex=True, sharey=True, figsize=(9.5, 6), subplot_kw={'projection': imwcs})\n",
    "# For RA,Dec axes instead of pixels, add: , subplot_kw={'projection': imwcs})\n",
    "\n",
    "# Color image\n",
    "ax[0,0].imshow(color_image_short_wavelength, origin='lower')\n",
    "ax[0,0].set_title('Color Image')\n",
    "\n",
    "# Data\n",
    "norm = ImageNormalize(stretch=SqrtStretch(), vmin=0)\n",
    "ax[0,1].imshow(data, origin='lower', cmap='Greys_r', norm=norm)\n",
    "ax[0,1].set_title('Detection Image F200W')\n",
    "\n",
    "# Segmentation map\n",
    "cmap = detection_catalog.segm_deblend.make_cmap(seed=12345)  # ERROR\n",
    "ax[0,2].imshow(detection_catalog.segm_deblend, origin='lower', cmap=cmap, interpolation='none')\n",
    "ax[0,2].set_title('Detections (Segmentation Image)')\n",
    "\n",
    "# norm = ImageNormalize(stretch=SqrtStretch())\n",
    "# ax[1,0].imshow(weight, origin='lower', cmap='Greys_r', vmin=0)\n",
    "# ax[1,0].set_title('Weight Image F200W')\n",
    "\n",
    "ax[1,0].imshow(detection_catalog.exposure_time_map, origin='lower', cmap='Greys_r', vmin=0)\n",
    "ax[1,0].set_title('Exposure Time Map')\n",
    "\n",
    "# ax[1,0].imshow(background_map.background, origin='lower', cmap='Greys_r')\n",
    "# ax[1,0].set_title('Background Pedestal')\n",
    "\n",
    "# RMS\n",
    "# norm = ImageNormalize()\n",
    "vmin, vmax = 0.001, 0.0035\n",
    "ax[1,1].imshow(detection_catalog.background_map.background_rms, origin='lower', vmin=vmin, vmax=vmax)\n",
    "ax[1,1].set_title('Background RMS')\n",
    "\n",
    "# Total error including Poisson noise\n",
    "ax[1,2].imshow(detection_catalog.data_rms, origin='lower', vmin=vmin, vmax=vmax)\n",
    "ax[1,2].set_title('RMS + Poisson noise')\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "print('Interactive zoom / pan controls all images simultaneously')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View / save measured quantities in detection image (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Only keep some quantities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = 'id xcentroid ycentroid sky_centroid area semimajor_axis_sigma semiminor_axis_sigma'.split()\n",
    "columns += 'ellipticity orientation gini'.split()\n",
    "columns += 'kron_radius local_background source_sum source_sum_err kron_flux kron_fluxerr'.split()\n",
    "# columns += 'source_sum source_sum_err kron_flux kron_fluxerr kron_radius local_background'.split()\n",
    "\n",
    "source_table = detection_catalog.catalog.to_table(columns=columns)\n",
    "source_table.rename_column('semimajor_axis_sigma', 'a')\n",
    "source_table.rename_column('semiminor_axis_sigma', 'b')\n",
    "\n",
    "# Replace sky_centroid with ra, dec\n",
    "source_table['ra'] = source_table['sky_centroid'].ra.degree * u.degree\n",
    "source_table['dec'] = source_table['sky_centroid'].dec.degree * u.degree\n",
    "\n",
    "columns = list(source_table.columns)\n",
    "columns = columns[:3] + ['ra', 'dec'] + columns[4:-2]\n",
    "\n",
    "source_table = source_table[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If interested, view / save output, but photometry in other filters will be added soon!\n",
    "# source_table.write('JADES_detections.ecsv', overwrite=True)\n",
    "# source_table.write('JADES_detections.cat', format='ascii.fixed_width_two_line', delimiter=' ', overwrite=True)\n",
    "# source_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert measured fluxes (data units) to magnitudes\n",
    "\n",
    "https://docs.astropy.org/en/stable/units/\n",
    "\n",
    "https://docs.astropy.org/en/stable/units/equivalencies.html#photometric-zero-point-equivalency\n",
    "\n",
    "https://docs.astropy.org/en/stable/units/logarithmic_units.html#logarithmic-units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Developer note:*\n",
    "    \n",
    "    flux units can be automatically converted to magnitude units\n",
    "    but flux uncertainties *cannot* be automatically converted to magnitude uncertainties\n",
    "    thus I wrote this function to do so\n",
    "    \n",
    "    Note magnitude uncertainties for detections should probably be u.mag instead of u.ABmag\n",
    "    but magnitude uncertainties for non-detections quote u.ABmag upper limits\n",
    "    They need to be the same, so we go with u.ABmag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not detected: mag =  99; magerr = 1-sigma upper limit assuming zero flux\n",
    "# not observed: mag = -99; magerr = 0\n",
    "def fluxes2mags(flux, fluxerr):\n",
    "    nondet = flux < 0  # Non-detection if flux is negative\n",
    "    unobs = (fluxerr <= 0) + (fluxerr == np.inf)  # Unobserved if flux uncertainty is negative or infinity\n",
    "\n",
    "    mag = flux.to(u.ABmag)\n",
    "    magupperlimit = fluxerr.to(u.ABmag) # 1-sigma upper limit if flux=0\n",
    "\n",
    "    mag = np.where(nondet, 99 * u.ABmag, mag)\n",
    "    mag = np.where(unobs, -99 * u.ABmag, mag)\n",
    "\n",
    "    magerr = 2.5 * np.log10(1 + fluxerr/flux) \n",
    "    magerr = magerr.value * u.ABmag\n",
    "\n",
    "    magerr = np.where(nondet, magupperlimit, magerr)\n",
    "    magerr = np.where(unobs, 0 * u.ABmag, magerr)\n",
    "    \n",
    "    return mag, magerr\n",
    "\n",
    "# Includes features I couldn't find in astropy:\n",
    "# mag = 99 / -99 for non-detections / unobserved\n",
    "# flux uncertainties -> mag uncertainties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiband photometry using isophotal apertures defined in detection image\n",
    "(Similar to running SourceExtractor in double-image mode)  \n",
    "(No PSF corrections just yet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filters = 'F090W F200W F444W'.split()  # quicker for testing\n",
    "for filt in filters:\n",
    "    filter_catalog = Photutils_Catalog(filt)\n",
    "    filter_catalog.measure_background_map()\n",
    "\n",
    "    # Measure photometry in this filter for objects detected in detected image\n",
    "    # segmentation map will define isophotal apertures\n",
    "    filter_catalog.segm_deblend = detection_catalog.segm_deblend\n",
    "    filter_catalog.measure_source_properties(exposure_time)\n",
    "    \n",
    "    # Convert measured fluxes to fluxes in nJy and to AB magnitudes\n",
    "    filter_table = filter_catalog.catalog.to_table()\n",
    "    source_table[filt+'_flux'] = flux = filter_table['source_sum'] * filter_catalog.zeropoint.to(u.nJy)\n",
    "    source_table[filt+'_fluxerr'] = fluxerr = filter_table['source_sum_err'] * filter_catalog.zeropoint.to(u.nJy)\n",
    "\n",
    "    mag, magerr = fluxes2mags(flux, fluxerr)\n",
    "    source_table[filt+'_mag'] = mag\n",
    "    source_table[filt+'_magerr'] = magerr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aperture corrections: isophotal to total (Kron aperture) fluxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_flux_table = deepcopy(source_table) # copy to new table, which will include total magnitude corrections\n",
    "\n",
    "reference_flux_auto = total_flux_table['kron_flux']\n",
    "reference_flux_iso = total_flux_table['source_sum']\n",
    "kron_flux_corrections = reference_flux_auto / reference_flux_iso\n",
    "total_flux_table['total_flux_cor'] = kron_flux_corrections\n",
    "\n",
    "for filt in filters:\n",
    "    total_flux_table[filt+'_flux'] *= kron_flux_corrections\n",
    "    total_flux_table[filt+'_fluxerr'] *= kron_flux_corrections\n",
    "    # total_flux_table[filt+'_mag'] = total_flux_table[filt+'_flux'].to(u.ABmag)  # doesn't handle non-detections\n",
    "    total_flux_table[filt+'_mag'] = fluxes2mags(total_flux_table[filt+'_flux'], total_flux_table[filt+'_fluxerr'])[0]\n",
    "    # magnitude uncertainty magerr stays the same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reformat output catalog for readability (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Developer's Note:*\n",
    "\n",
    "    'd' format incompatible with units (pix2)\n",
    "    As a workaround, I set the format to '.0f' (a float with no decimals)\n",
    "\n",
    "    ValueError: Unable to parse format string \"d\" for entry \"101.0\" in column \"area\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isophotal_table = deepcopy(total_flux_table) # copy to new table, which will include PSF-corrections\n",
    "\n",
    "old_columns = list(isophotal_table.columns)\n",
    "\n",
    "# Reorder columns,\n",
    "i = old_columns.index('source_sum')\n",
    "j = old_columns.index(filters[0]+'_flux')\n",
    "columns = old_columns[:i] # detection catalog (except source_sum & kron_flux)\n",
    "columns += old_columns[-1:]  # total_flux_cor\n",
    "columns += old_columns[j:-1] # photometry in all filters\n",
    "        \n",
    "isophotal_table = isophotal_table[columns]\n",
    "\n",
    "for column in columns:\n",
    "    isophotal_table[column].info.format = '.4f'\n",
    "\n",
    "isophotal_table['ra'].info.format = '11.7f'\n",
    "isophotal_table['dec'].info.format = ' 11.7f'\n",
    "\n",
    "isophotal_table['id'].info.format = 'd'\n",
    "isophotal_table['area'].info.format = '.0f'  # 'd' raises error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Isophotal Photometry without PSF corrections complete\n",
    "\n",
    "We recommend proceeding with PSF corrections to photometry in the Long Wavelength Channel. But if you are interested, you may save the catalog now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# isophotal_table.write('JADES_isophotal_photometry.ecsv', overwrite=True)\n",
    "# isophotal_table.write('JADES_isophotal_photometry.cat', format='ascii.fixed_width_two_line', delimiter=' ', overwrite=True)\n",
    "# isophotal_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PSF magnitude corrections\n",
    "\n",
    "Color corrections are perfomed as described here:\n",
    "https://www.stsci.edu/~dcoe/ColorPro/color\n",
    "\n",
    "Note this is different from one common approach, which is to degrade every image to the broadest PSF.\n",
    "\n",
    "Photometry is only corrected in Long Wavelength images > 2.4 microns. The F200W detection image is convolved (blurred) to the PSF of each Long Wavelength image. Then we correct colors based on the magnitudes lost in that aperture:\n",
    "\n",
    "* PSF_magnitude_corrections = detection_image_magnitudes - blurred_detection_image_magnitudes\n",
    "\n",
    "In practice, we actually correct the fluxes:\n",
    "\n",
    "* PSF_flux_corrections = detection_image_fluxes / blurred_detection_image_fluxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load PSFs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PSF files used in this notebook were extracted from tar files available on JDox:  \n",
    "https://jwst-docs.stsci.edu/near-infrared-camera/nircam-predicted-performance/nircam-point-spread-functions#NIRCamPointSpreadFunctions-SimulatedNIRCamPSFs  \n",
    "PSFs_SW_filters (short wavelength channel): https://stsci.box.com/s/s2lepxr9086gq4sogr3kwftp54n1c5vl  \n",
    "PSFs_LW_filters (long wavelength channel): https://stsci.box.com/s/gzl7blxb1k3p4n66gs7jvt7xorfrotyb  \n",
    "\n",
    "Each FITS file contains:  \n",
    "– hdu[0]: a 4x oversampled PSF  \n",
    "– hdu[1]: PSF at detector pixel scale (0.031\" and 0.063\" in the short and long wavelength channels, respectively)  \n",
    "This notebook will use the latter: PSF at detector pixel scale. We find no advantage to the former for this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PSF_inputs = {}\n",
    "PSF_images = {}\n",
    "\n",
    "detector_pixel_scales = {'SW': 0.031, 'LW': 0.063}\n",
    "\n",
    "PSF_url = os.path.join(input_file_url, 'NIRCam_PSFs')\n",
    "\n",
    "for i, filt in enumerate(filters):\n",
    "    lam = wavelengths[i]\n",
    "    if lam < 2.4 * u.um:\n",
    "        channel = 'SW'  # Short Wavelength Channel < 2.4 microns\n",
    "    else:\n",
    "        channel = 'LW'  # Long Wavelength Channel > 2.4 microns\n",
    "\n",
    "    # Load PSF\n",
    "    PSF_file = 'PSF_%scen_G5V_fov299px_ISIM41.fits' % filt\n",
    "    # PSF_file = os.path.join('NIRCam_PSFs_' + channel, PSF_file)\n",
    "    PSF_file = os.path.join(PSF_url, PSF_file)\n",
    "\n",
    "    print(PSF_file)\n",
    "    PSF_hdu = fits.open(PSF_file)\n",
    "    PSF_inputs[filt] = data = PSF_hdu[1].data  # extension [1] is at pixel scale (not oversampled)\n",
    "    ny, nx = data.shape\n",
    "    \n",
    "    # Resize from detector pixel scale to image pixel scale (here 0.03\" / pix)\n",
    "    detector_pixel_scale = detector_pixel_scales[channel]\n",
    "    ny_resize = ny * detector_pixel_scale / image_pixel_scale  # Assume square PSF (ny = nx)\n",
    "    ny_resize = np.round(ny_resize)\n",
    "    ny_resize = np.int((ny_resize // 2) * 2 + 1)  # Make it an odd number of pixels to ensure PSF is centered\n",
    "    PSF_pixel_scale = ny_resize / ny * image_pixel_scale    \n",
    "    PSF_image = resize_psf(PSF_inputs[filt], PSF_pixel_scale, image_pixel_scale)  # Resize PSF here\n",
    "    r = (ny_resize - ny) // 2\n",
    "    PSF_images[filt] = PSF_image[r:-r, r:-r]  # Trim to same size as input PSFs\n",
    "    # Note PSF is no longer normalized but will be later in convolution step\n",
    "    # print(filt, ny, ny_resize, PSF_image.shape, PSF_images[filt].shape, PSF_pixel_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(PSF_images[filt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(PSF_image[r:-r, r:-r])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show PSFs (optional)\n",
    "\n",
    "fig, ax = plt.subplots(1, len(filters), figsize=(9.5, 1.5), sharex=True, sharey=True)\n",
    "\n",
    "r = 15  # PSF will be shown out to radius r (pixels)\n",
    "for i, filt in enumerate(filters):\n",
    "    data = PSF_images[filt]\n",
    "    ny, nx = data.shape\n",
    "    yc = ny // 2\n",
    "    xc = nx // 2\n",
    "    stamp = data[yc-r:yc+r+1, xc-r:xc+r+1]\n",
    "    norm = ImageNormalize(stretch=LogStretch())  # scale each filter individually\n",
    "    ax[i].imshow(stamp, cmap='Greys_r', norm=norm, origin='lower')\n",
    "    ax[i].set_title(filt.upper())\n",
    "    ax[i].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PSF Matching \n",
    "\n",
    "https://photutils.readthedocs.io/en/stable/psf_matching.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine PSF convolution kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PSF_kernels = {}\n",
    "reference_filter = 'F200W'\n",
    "reference_PSF = PSF_images[reference_filter]\n",
    "i_reference = filters.index(reference_filter)\n",
    "window = CosineBellWindow(alpha=0.35)\n",
    "for filt in filters[i_reference+1:]:\n",
    "    PSF_kernels[filt] = create_matching_kernel(reference_PSF, PSF_images[filt], window=window)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolve F200W detection image to Long Wavelength PSFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reference_image_hdu = fits.open(image_files[reference_filter])\n",
    "reference_image_data = reference_image_hdu[0].data[:]\n",
    "\n",
    "for output_filter in filters[i_reference+1:]:\n",
    "    output_image = 'jades_convolved_%s_to_%s.fits' % (reference_filter, output_filter)\n",
    "    if os.path.exists(output_image):\n",
    "        print(output_image, 'EXISTS')\n",
    "    else:\n",
    "        print(output_filter + '...')\n",
    "        PSF_kernel = PSF_kernels[output_filter][yc-r:yc+r+1, xc-r:xc+r+1]\n",
    "        # convolve_fft may be faster for larger images / kernels (but doesn't make much difference in this demo):\n",
    "        convolved_image = convolve(reference_image_data, PSF_kernel, normalize_kernel=True)\n",
    "        reference_image_hdu[0].data = convolved_image\n",
    "        print('SAVING %s' % output_image)\n",
    "        reference_image_hdu.writeto(output_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiband photometry in convolved images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measure and save the fluxes in each blurry image\n",
    "blurry_catalog = QTable()\n",
    "\n",
    "for blurry_filter in filters[i_reference+1:]:\n",
    "    image_file = 'jades_convolved_%s_to_%s.fits' % (reference_filter, blurry_filter)\n",
    "    filter_catalog = Photutils_Catalog(blurry_filter, image_file=image_file)\n",
    "    filter_catalog.measure_background_map()\n",
    "\n",
    "    # Measure photometry in this filter for objects detected in detected image\n",
    "    # segmentation map will define isophotal apertures\n",
    "    filter_catalog.segm_deblend = detection_catalog.segm_deblend\n",
    "    filter_catalog.measure_source_properties(exposure_time)\n",
    "\n",
    "    # Convert measured fluxes to fluxes in nJy\n",
    "    filter_table = filter_catalog.catalog.to_table()\n",
    "    blurry_catalog[blurry_filter+'_flux'] = filter_table['source_sum'] * filter_catalog.zeropoint.to(u.nJy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PSF magnitude corrections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.stsci.edu/~dcoe/ColorPro/color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PSF_corrected_table = deepcopy(isophotal_table)\n",
    "\n",
    "reference_fluxes = PSF_corrected_table[reference_filter+'_flux']  # det_flux_auto\n",
    "\n",
    "for filt in filters[i_reference+1:]:\n",
    "    # Convert isophotal fluxes to total fluxes\n",
    "    blurry_total_fluxes = blurry_catalog[filt+'_flux'] * kron_flux_corrections\n",
    "    PSF_flux_corrections = reference_fluxes / blurry_total_fluxes\n",
    "    PSF_corrected_table[filt+'_flux'] *= PSF_flux_corrections\n",
    "    PSF_corrected_table[filt+'_fluxerr'] *= PSF_flux_corrections\n",
    "    # PSF_corrected_table[filt+'_mag'] = PSF_corrected_fluxes.to(u.ABmag)  # doesn't handle non-detections\n",
    "    PSF_corrected_table[filt+'_mag'], PSF_corrected_table[filt+'_magerr'] = \\\n",
    "        fluxes2mags(PSF_corrected_table[filt+'_flux'], PSF_corrected_table[filt+'_fluxerr'])\n",
    "    PSF_corrected_table[filt+'_PSF_flux_cor'] = PSF_flux_corrections    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PSF_corrected_table.write('JADES_photometry.ecsv', overwrite=True)\n",
    "PSF_corrected_table.write('JADES_photometry.cat', format='ascii.fixed_width_two_line', delimiter=' ', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PSF_corrected_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !cat JADES_photometry.cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start new session and analyze results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just run the first few blocks above, including imports, defining file lists, and creating the color image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load catalog and segmentation map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Catalog: ecsv format preserves units for loading in Python notebooks\n",
    "output_catalog = QTable.read('JADES_photometry.ecsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstitute filter list\n",
    "filters = []\n",
    "for param in output_catalog.columns:\n",
    "    if param[-4:] == '_mag':\n",
    "        filters.append(param[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segmentation map\n",
    "segmfile = 'JADES_detections_segm.fits'\n",
    "segm = fits.open(segmfile)[0].data\n",
    "segm = photutils.segmentation.SegmentationImage(segm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input simulation JADES JAGUAR catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_catalog_file = 'JADES_SF_mock_r1_v1.1.fits.gz'  # not available in this demo\n",
    "# Cropped 302,515 simulated galaxies down to 653 in the smaller image region used in this demo\n",
    "cropped_catalog_file = 'JADES_SF_mock_r1_v1.1_crop.fits.gz'\n",
    "input_catalog_file = os.path.join(input_file_url, cropped_catalog_file)\n",
    "simulated_catalog = Table.read(input_catalog_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Match objects to photutils catalog\n",
    "\n",
    "https://docs.astropy.org/en/stable/coordinates/matchsep.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_coordinates = SkyCoord(ra=simulated_catalog['RA']*u.degree, dec=simulated_catalog['DEC']*u.degree)\n",
    "\n",
    "# Can use output_catalog['sky_centroid'] if saved in table, but this demo saved (ra,dec) instead:\n",
    "detected_coordinates = SkyCoord(ra=output_catalog['ra'], dec=output_catalog['dec'])\n",
    "\n",
    "# Match photutils detection sources to input object catalog:\n",
    "input_indices, separation2d, distance3d = detected_coordinates.match_to_catalog_sky(input_coordinates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine threshold maximum distance between input objects and matched output sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(9.5, 4))\n",
    "plt.plot(np.sort(separation2d.to(u.arcsec)), zorder=10)\n",
    "separation_max = 0.036 * u.arcsec  # determined by eye after plotting\n",
    "plt.axhline(0, c='k', ls=':')\n",
    "plt.axhline(separation_max.value, c='r', ls='--', label='\"good\" matches')\n",
    "plt.title('Matches between output (detected) and input (simulated) catalogs')\n",
    "plt.xlabel('Detected sources (sorted)')\n",
    "plt.ylabel('Separation (arcsec)')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_matches = separation2d < separation_max\n",
    "unique_matches, index_counts = np.unique(input_indices[good_matches], return_counts=True)\n",
    "\n",
    "print('%d matches (%d unique) between input catalog (%d galaxies) and photutils catalog (%d detected sources)'\n",
    "      % (np.sum(good_matches), len(unique_matches), len(simulated_catalog), len(output_catalog)))\n",
    "\n",
    "multiple_matches = unique_matches[index_counts > 1]\n",
    "if len(multiple_matches):\n",
    "    print('Input sources matched multiple times:', list(output_catalog['id'][multiple_matches]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Input vs. Output Color\n",
    "\n",
    "filt1, filt2 = 'F200W F444W'.split()\n",
    "\n",
    "input_flux1 = simulated_catalog['NRC_%s_fnu' % filt1][input_indices][good_matches]\n",
    "input_flux2 = simulated_catalog['NRC_%s_fnu' % filt2][input_indices][good_matches]\n",
    "\n",
    "input_mag1 = (input_flux1 * u.nJy).to(u.ABmag).value\n",
    "input_mag2 = (input_flux2 * u.nJy).to(u.ABmag).value\n",
    "\n",
    "output_mag1 = output_catalog[filt1 + '_mag'][good_matches].value\n",
    "output_mag2 = output_catalog[filt2 + '_mag'][good_matches].value\n",
    "output_ids = output_catalog['id'][good_matches].data.astype(int)\n",
    "\n",
    "# Only plot detections\n",
    "det1 = (0 < output_mag1) & (output_mag1 < 90)\n",
    "det2 = (0 < output_mag2) & (output_mag2 < 90)\n",
    "det = det1 * det2\n",
    "\n",
    "output_mag1 = output_mag1[det]\n",
    "output_mag2 = output_mag2[det]\n",
    "\n",
    "input_color = input_mag1 - input_mag2\n",
    "output_color = output_mag1 - output_mag2\n",
    "\n",
    "output_mag1_uncor = output_mag1\n",
    "PSF_flux_cor = output_catalog[filt2+'_PSF_flux_cor']\n",
    "PSF_mag_cor = -2.5 * np.log10(PSF_flux_cor)\n",
    "output_mag2_uncor = output_mag2 - PSF_mag_cor[good_matches][det].value\n",
    "output_color_uncor = output_mag1_uncor - output_mag2_uncor\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "plt.plot(input_mag1, output_color - input_color, 'bo', alpha=0.5, label='PSF corrected')\n",
    "plt.plot(input_mag1, output_color_uncor - input_color, 'r.', alpha=0.5, label='uncorrected')\n",
    "\n",
    "plt.axhline(0, c='g', label='correct')\n",
    "plt.xlabel('Input  ' + filt1 + '  (mag)')\n",
    "plt.ylabel('Measured $-$ Input colors  [%s $-$ %s]' % (filt1, filt2))\n",
    "plt.title('Accuracy of measured JADES photometry colors')\n",
    "\n",
    "plt.legend();\n",
    "# plt.savefig('JADES_color_deviation_%s-%s.png' % (filt1, filt2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot F200W vs. F090W magnitudes and look for dropouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mag1 = output_catalog['F090W_mag']\n",
    "mag2 = output_catalog['F200W_mag']\n",
    "\n",
    "# Only plot detections in F200W\n",
    "det2 = (0*u.ABmag < mag2) & (mag2 < 90*u.ABmag)\n",
    "\n",
    "mag1 = mag1[det2]\n",
    "mag2 = mag2[det2]\n",
    "ids = output_catalog['id'][det2].data.astype(int)\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "\n",
    "plt.scatter(mag1, mag2, c=ids)\n",
    "\n",
    "plt.xlabel('F090W AB magnitude')\n",
    "plt.ylabel('F200W AB magnitude')\n",
    "\n",
    "plt.xlim(plt.xlim()[::-1])  # brighter at right\n",
    "plt.ylim(plt.ylim()[::-1])  # brighter at top\n",
    "\n",
    "mplcursors.cursor(hover=mplcursors.HoverMode.Transient)\n",
    "print('Hover cursor over data point to reveal magnitudes and catalog ID number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select brightest F090W dropout\n",
    "dropouts = output_catalog['F090W_mag'] > 90 * u.ABmag\n",
    "i_brightest_dropout = output_catalog[dropouts]['F200W_mag'].argmin()\n",
    "output_id = output_catalog[dropouts][i_brightest_dropout]['id']\n",
    "output_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select object with id from catalog\n",
    "output_index = segm.get_index(output_id)\n",
    "output_obj = output_catalog[output_index]\n",
    "segmobj = segm[segm.get_index(output_id)]\n",
    "print(output_id, output_obj['F090W_mag'], output_obj['F200W_mag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternartively, could select an object by position\n",
    "# x, y = 905, 276\n",
    "# id = segm.data[y,x]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show selected object in all filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, len(filters)+1, figsize=(9.5, 3.5), sharex=True, sharey=True)\n",
    "\n",
    "ax[0, 0].imshow(color_image_short_wavelength[segmobj.bbox.slices], origin='lower', extent=segmobj.bbox.extent)\n",
    "ax[0, 0].set_title('Color')\n",
    "\n",
    "cmap = segm.make_cmap(seed=12345)  # ERROR\n",
    "ax[1, 0].imshow(segm.data[segmobj.bbox.slices], origin='lower', extent=segmobj.bbox.extent, cmap=cmap,\n",
    "                interpolation='nearest')\n",
    "ax[1, 0].set_title('Segment')\n",
    "\n",
    "for i in range(1, len(filters)+1):\n",
    "    filt = filters[i-1]\n",
    "\n",
    "    # Show data on top row\n",
    "    data = fits.open(image_files[filt])[0].data\n",
    "    stamp = data[segmobj.bbox.slices]\n",
    "    norm = ImageNormalize(stretch=SqrtStretch())  # scale each filter individually\n",
    "    ax[0, i].imshow(stamp, extent=segmobj.bbox.extent, cmap='Greys_r', norm=norm, origin='lower')\n",
    "    ax[0, i].set_title(filt.upper())\n",
    "\n",
    "    # Show weights on bottom row\n",
    "    weight = fits.open(weight_files[filt])[0].data\n",
    "    stamp = weight[segmobj.bbox.slices]\n",
    "    # set black to zero weight (no exposure time / bad pixel)\n",
    "    ax[1, i].imshow(stamp, extent=segmobj.bbox.extent, vmin=0, cmap='Greys_r', origin='lower')\n",
    "\n",
    "ax[0, 0].set_ylabel('Data')\n",
    "ax[1, 0].set_ylabel('Weight');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Spectral Energy Distribution (SED) for one object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_obj = output_catalog[index]  # already done above\n",
    "input_obj = simulated_catalog[input_indices][output_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_fluxes = np.array([input_obj['NRC_%s_fnu' % filt] for filt in filters])\n",
    "output_fluxes = np.array([output_obj[filt+'_flux'].value for filt in filters])\n",
    "output_flux_errs = np.array([output_obj[filt+'_fluxerr'].value for filt in filters])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measured flux does not recover total input flux\n",
    "# Given known simulation input, determine what fraction of the flux was recovered\n",
    "# Use this to scale measured SED to input SED for comparison, plotted below\n",
    "\n",
    "# Scale output to input flux using F200W only (other filters may have incorrect flux corrections)\n",
    "\n",
    "filt = 'F200W'\n",
    "flux_scale_factor = output_obj[filt+'_flux'].value / input_obj['NRC_%s_fnu' % filt]\n",
    "flux_factor = 1 / flux_scale_factor  # input / output\n",
    "print('%d%% of input flux recovered by photutils' % (100 * flux_scale_factor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0:\n",
    "    # Scale output to input flux considering all measured fluxes and uncertainties\n",
    "    # Benitez+00 Equations 8 & 9\n",
    "    FOT = np.sum(input_fluxes * output_fluxes / output_flux_errs**2)\n",
    "    FTT = np.sum(input_fluxes**2 / output_flux_errs**2)\n",
    "    flux_scale_factor = FOT / FTT  # a_m: observed / theoretical (output / input)\n",
    "    flux_factor = 1 / flux_scale_factor  # input / output\n",
    "    print('%d%% of input flux recovered by photutils' % (100 * flux_scale_factor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PSF_flux_corrections = np.ones(len(filters))\n",
    "for i, filt in enumerate(filters):\n",
    "    PSFcor_column = filt+'_PSF_flux_cor'\n",
    "    if PSFcor_column in list(output_obj.columns):\n",
    "        PSF_flux_corrections[i] = output_obj[PSFcor_column]\n",
    "\n",
    "PSF_flux_corrections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Developer's Note:*\n",
    "\n",
    "    automatic secondary axis magnitudes don't work when fluxes extend to negative values\n",
    "    so I wrote my own code to do this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_magnitude_axis(ax, flux_units=u.nJy, plothuge=True):\n",
    "    ylo, yhi = plt.ylim() * flux_units\n",
    "    maghi = yhi.to(u.ABmag).value\n",
    "    ytx1 = np.ceil(maghi * 10) / 10.  # 24.101 -> 24.2\n",
    "    ytx2 = np.ceil(maghi)  # 24.1 -> 25\n",
    "\n",
    "    fpart = ytx1 - int(ytx1)  # 0.2\n",
    "    if np.isclose(fpart, 0) or np.isclose(fpart, 0.9):\n",
    "        ytx1 = []\n",
    "    elif np.isclose(fpart, 0.1) or np.isclose(fpart, 0.2):\n",
    "        ytx1 = np.array([ytx1, ytx2-0.7, ytx2-0.5, ytx2-0.3])  # 24.1, 24.3, 24.5, 24.7\n",
    "    elif np.isclose(fpart, 0.3) or np.isclose(fpart, 0.4):\n",
    "        ytx1 = np.array([ytx1, ytx2-0.5, ytx2-0.3])  # 24.3, 24.5, 24.7\n",
    "    elif np.isclose(fpart, 0.5):\n",
    "        ytx1 = np.array([ytx1, ytx2-0.3])  # 24.5, 24.7\n",
    "    elif np.isclose(fpart, 0.6):\n",
    "        ytx1 = np.array([ytx1, ytx2-0.2])  # 24.6, 24.8\n",
    "\n",
    "    if isinstance(ytx1, float):\n",
    "        ytx1 = np.array([ytx1])\n",
    "\n",
    "    if plothuge:\n",
    "        ytx3 = ytx2 + np.array([0, 0.2, 0.5, 1, 2])\n",
    "    else:\n",
    "        ytx3 = ytx2 + np.array([0, 0.2, 0.5, 1, 1.5, 2, 3])\n",
    "\n",
    "    ytx2 = np.array([ytx2])\n",
    "    ytx = np.concatenate([ytx1, ytx3])\n",
    "    yts = ['%g' % mag for mag in ytx]\n",
    "\n",
    "    ytx = (ytx * u.ABmag).to(flux_units).value\n",
    "    \n",
    "    ax2 = ax.twinx()\n",
    "    ax.yaxis.set_label_position('left')\n",
    "    ax2.yaxis.set_label_position('right')\n",
    "    ax.yaxis.tick_left()\n",
    "    ax2.yaxis.tick_right()\n",
    "\n",
    "    ax2.set_yticks(ytx)\n",
    "    ax2.set_yticklabels(yts)\n",
    "    ax2.set_ylabel('Magnitude (AB)')\n",
    "    ax2.set_ylim(ylo.value, yhi.value)\n",
    "    ax2.set_zorder(-100)  # interactive cursor will output left axis ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Developer's Note:*\n",
    "\n",
    "    errorbar doesn't work with units either"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "plt.plot(wavelengths, input_fluxes, 'o-', label='Input fluxes', zorder=10)\n",
    "\n",
    "label = 'Measured PSF-corrected fluxes $\\\\times$ %.1f' % flux_factor\n",
    "plt.errorbar(wavelengths.value, output_fluxes * flux_factor, output_flux_errs * flux_factor,\n",
    "             ms=8, marker='s', mfc=mpl_colors[1], c='k', lw=3, alpha=0.5, ls='none', label=label)\n",
    "\n",
    "label = 'Measured uncorrected fluxes $\\\\times$ %.1f' % flux_factor\n",
    "plt.errorbar(wavelengths.value, output_fluxes * flux_factor / PSF_flux_corrections, output_flux_errs * flux_factor,\n",
    "             ms=8, marker='s', mfc='r', c='k', lw=3, alpha=0.5, ls='none', label=label, zorder=-10)\n",
    "\n",
    "plt.legend()\n",
    "plt.axhline(0, c='k', ls=':')\n",
    "plt.xlim(0, 5)\n",
    "plt.xlabel('Wavelength ($\\\\mu$m)')\n",
    "plt.ylabel('Flux (nJy)')\n",
    "add_magnitude_axis(ax)\n",
    "\n",
    "plt.savefig('JADES photutils SED linear.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Developer's Notes:*\n",
    "\n",
    "    Ideally, the secondary axis should know how to convert between units.\n",
    "    As a workaround, I wrote functions and fed them in.\n",
    "\n",
    "    Even then, this only works so long as fluxes are positive.\n",
    "    Clipping all fluxes to positive values doesn't work either.\n",
    "\n",
    "    I would like to automatically scale the y limits to only *some* of the plotted data along the lines of:\n",
    "    https://stackoverflow.com/questions/7386872/make-matplotlib-autoscaling-ignore-some-of-the-plots\n",
    "    But that old solution didn't work.\n",
    "    So for now, I just hard-coded a range that works for this object: y=10-70."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "if 0:  # this didn't work\n",
    "    ax.autoscale(True)\n",
    "    detections = output_fluxes > 0\n",
    "    ax.plot(wavelengths[detections], output_fluxes[detections] * flux_factor, visible=False)\n",
    "    ax.autoscale(False)\n",
    "\n",
    "plt.plot(wavelengths, input_fluxes, 'o-', label='Input fluxes', zorder=10, scaley=False)\n",
    "\n",
    "label = 'Measured PSF-corrected fluxes $\\\\times$ %.1f' % flux_factor\n",
    "plt.errorbar(wavelengths.value, output_fluxes * flux_factor, output_flux_errs * flux_factor,\n",
    "             ms=8, marker='s', mfc=mpl_colors[1], c='k', lw=3, alpha=0.5, ls='none', label=label)\n",
    "\n",
    "label = 'Measured uncorrected fluxes $\\\\times$ %.1f' % flux_factor\n",
    "plt.errorbar(wavelengths.value, output_fluxes * flux_factor / PSF_flux_corrections, output_flux_errs * flux_factor,\n",
    "             ms=8, marker='s', mfc='r', c='k', lw=3, alpha=0.5, ls='none', label=label, zorder=-10)\n",
    "\n",
    "plt.legend()\n",
    "plt.axhline(0, c='k', ls=':')\n",
    "plt.xlim(0, 5)\n",
    "plt.ylim(15, 70)\n",
    "plt.xlabel('Wavelength ($\\\\mu$m)')\n",
    "plt.ylabel('Flux (nJy)')\n",
    "plt.semilogy()\n",
    "ax.yaxis.set_major_formatter(ticker.FormatStrFormatter(\"%g\"))\n",
    "ax.yaxis.set_minor_formatter(ticker.FormatStrFormatter(\"%g\"))\n",
    "\n",
    "# Add AB magnitudes as secondary x-axis at right\n",
    "# (Note this breaks if any fluxes are negative)\n",
    "# https://matplotlib.org/gallery/subplots_axes_and_figures/secondary_axis.html#sphx-glr-gallery-subplots-axes-and-figures-secondary-axis-py\n",
    "\n",
    "def AB2nJy(mAB):\n",
    "    m = mAB * u.ABmag\n",
    "    f = m.to(u.nJy)\n",
    "    return f.value\n",
    "\n",
    "def nJy2AB(F_nJy):\n",
    "    f = F_nJy * u.nJy\n",
    "    m = f.to(u.ABmag)\n",
    "    return m.value\n",
    "\n",
    "# secondary_axis = add_magnitude_axis(ax, flux_units)\n",
    "secax = ax.secondary_yaxis('right', functions=(nJy2AB, AB2nJy))\n",
    "secax.set_ylabel('magnitude (AB)')\n",
    "secax.yaxis.set_major_formatter(ticker.FormatStrFormatter(\"%g\"))\n",
    "secax.yaxis.set_minor_formatter(ticker.FormatStrFormatter(\"%g\"))\n",
    "\n",
    "plt.title('JADES SED PSF-corrected')\n",
    "# plt.savefig('JADES photutils SED.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
