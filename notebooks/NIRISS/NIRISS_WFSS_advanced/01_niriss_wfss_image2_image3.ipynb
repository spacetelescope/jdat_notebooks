{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a935d7c",
   "metadata": {},
   "source": [
    "# Run Image Pipeline and Create Source Catalog\n",
    "\n",
    "In this run, we are starting from the rate files which have already been calibrated with the detector1 pipeline. This will save time as we do not need to edit any of the steps being performed as part of detector1. Therefore, the first calibration that should be done as part of a WFSS run is to run the rate files direct images through the Image2 and Image3 steps of the JWST pipeline. This includes creating a source catalog, which most likely will need to be adjusted from the pipeline default values. **Not having a good source catalog will result in non optimal extraction of sources in the dispersed, WFSS, images.**\n",
    "\n",
    "**Use case**: The default parameters for the pipeline do not extract the expected sources, so custom parameters need to be set to obtain new combined image and source catalog.<br>\n",
    "**Data**: JWST/NIRISS images and spectra from program 2079 observation 004. This should be stored in a single directory `data`, and can be downloaded from the previous notebook, 00_niriss_mast_query_data_setup.ipynb.<br>\n",
    "**Tools**: astropy, crds, glob, jdaviz, json, jwst, matplotlib, numpy, os, pandas, urllib, warnings, zipfile<br>\n",
    "**Cross-instrument**: NIRISS<br>\n",
    "\n",
    "**Content**\n",
    "- [Imports & Data Setup](#imports)\n",
    "- [Default Imaging Pipeline Run](#default)\n",
    "  - [Image2](#default_image2)\n",
    "  - [Image3](#default_image3)\n",
    "  - [Inspecting Default Results](#view_default)\n",
    "- [Custom Imaging Pipeline Run](#custom)\n",
    "  - [Image3](#custom_image3)\n",
    "  - [Inspecting Custom Results](#view_custom)\n",
    "- [Refining the Source Catalog Further](#source_cat)\n",
    "  - [Matching Source IDs Across Catalogs](#match_sources) \n",
    "  - [Manually Editing the Source Catalog](#manual_cat)\n",
    "\n",
    "**Author**: Rachel Plesha (rplesha@stsci.edu), Camilla Pacifici (cpacifici@stsci.edu), JWebbinar notebooks.<br>\n",
    "**First Published**: May 2024 <br>\n",
    "**Last tested**: This notebook was last tested with JWST pipeline version 1.12.5 and the CRDS context jwst_1225.pmap."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fdaf1a1-57e5-4239-b82e-6552261d8d82",
   "metadata": {},
   "source": [
    "<a id='imports'></a>\n",
    "## Imports & Data Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ccd6a3-e781-4d7f-8120-fa142723a6d9",
   "metadata": {},
   "source": [
    "[CRDS Documentation](https://jwst-pipeline.readthedocs.io/en/latest/jwst/user_documentation/reference_files_crds.html#crds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf2ea52-2568-44cf-8074-eec3b5b76cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the CRDS path to your local directory\n",
    "%env CRDS_PATH=crds_cache\n",
    "%env CRDS_SERVER_URL=https://jwst-crds.stsci.edu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028352f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import warnings\n",
    "import urllib\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import astropy.units as u\n",
    "from astropy.io import fits\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy.table import Table\n",
    "\n",
    "from jdaviz import Imviz\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib widget\n",
    "# %matplotlib inline\n",
    "\n",
    "from jwst.pipeline import Image2Pipeline\n",
    "from jwst.pipeline import Image3Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb035a4d-e63c-4125-b083-462e3353e49f",
   "metadata": {},
   "source": [
    "Check what version of the JWST pipeline you are using. To see what the latest version of the pipeline is available or install a previous version, check [GitHub](https://github.com/spacetelescope/jwst#software-vs-dms-build-version-map\"). Also verify what [CRDS version](https://jwst-crds.stsci.edu/) you are using. [CRDS documentation](https://jwst-pipeline.readthedocs.io/en/latest/jwst/user_documentation/reference_files_crds.html) explains how to set a specific context to use in the JWST pipeline. If either of these values are different from the last tested note above there may be differences in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae10a560",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jwst\n",
    "import crds\n",
    "print('JWST Pipeliene Version:', jwst.__version__)\n",
    "print('CRDS Context:', crds.get_context_name('jwst'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb25e11-bc16-44b8-830c-d34f12e2dcf7",
   "metadata": {},
   "source": [
    "The data directory, `data_dir` here should contain all of the association and rate files in a single, flat directory. `default_run_image3` and `custom_run_image3` are directories that we will use later for our calibrated data. They are separated so that we can compare the two outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ecc213-479a-422c-a0f8-8608309b845c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data'\n",
    "default_run_image3 = 'default_image3_calibrated' # where the results of the default image3 run will be saved (inside of data_dir)\n",
    "custom_run_image3 = 'custom_image3_calibrated'# where the results of the custom image3 run will be saved (inside of data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d991e323-8e98-4487-a8ab-1b696f91899b",
   "metadata": {},
   "source": [
    "The association files expect that 1) all of the data are in the same directory and 2) that you are performing the pipeline call also in that directory. Because of that, we need to change into the data directory to run the imaging pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fbaa8a-5062-4a2d-b8a9-f3764086aa91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you have not downloaded the data from notebook 00, run this cell. Otherwise, feel free to skip it.\n",
    "\n",
    "# Download uncalibrated data from Box into the data directory:\n",
    "boxlink = 'https://data.science.stsci.edu/redirect/JWST/jwst-data_analysis_tools/niriss_wfss_advanced/niriss_wfss_advanced_01_input.zip'\n",
    "boxfile = os.path.basename(boxlink)\n",
    "urllib.request.urlretrieve(boxlink, boxfile)\n",
    "\n",
    "zf = zipfile.ZipFile(boxfile, 'r')\n",
    "zf.extractall(path=data_dir)\n",
    "\n",
    "# move the files downloaded from the box file into the top level data directory\n",
    "box_download_dir = os.path.join(data_dir, boxfile.split('.zip')[0])\n",
    "for filename in glob.glob(os.path.join(box_download_dir, '*')):\n",
    "    if '.csv' in filename:\n",
    "        # move to the current directory\n",
    "        os.rename(filename, os.path.basename(filename))\n",
    "    else:\n",
    "        # move to the data directory \n",
    "        os.rename(filename, os.path.join(data_dir, os.path.basename(filename)))\n",
    "\n",
    "# remove unnecessary files now\n",
    "os.remove(boxfile)\n",
    "os.rmdir(box_download_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d348ad9-4344-4a03-a58d-344357eeea28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the csv file we created earlier, find a list of all of the grism observations we will want to calibrate with spec2\n",
    "listrate_file = 'list_ngdeep_rate.csv'\n",
    "rate_df = pd.read_csv(listrate_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ea2cb0-e5d5-4347-8c4c-9126cda54561",
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd() # get the current working directory \n",
    "if cwd != data_dir: # if you are not already in the location of the data, change into it\n",
    "    try:\n",
    "        os.chdir(data_dir)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Not able to change into: {data_dir}.\\nRemaining in: {cwd}\")\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88f9b55-dbde-466c-9647-86e5fff3fdcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for temp_dir in [default_run_image3, custom_run_image3]:\n",
    "    if not os.path.exists(temp_dir):\n",
    "        os.mkdir(temp_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10824c6a-4843-4f31-beb7-05ecc58e8b84",
   "metadata": {},
   "source": [
    "<a id='default'></a>\n",
    "## Default Imaging Pipeline Run\n",
    "To start, run the default image2 and image3 steps of the pipeline on all direct images observed with the WFSS data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac742e8",
   "metadata": {},
   "source": [
    "<a id='default_image2'></a>\n",
    "### Run Default Image2\n",
    "\n",
    "Image2 is run on the direct image rate files. While your program should have valid association files to download from MAST, if for any reason you need to make your own association file, see [Creating Custom ASN Files](#customasn)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82eb2c93",
   "metadata": {},
   "source": [
    "#### Looking in a Level 2 Imaging Association File\n",
    "First, take a look inside the association (ASN) files to better understand everything that is contained in them.\n",
    "\n",
    "For image2 association files, there should be one asn file for each dither position in an observing sequence which is set by the [exposure strategy](https://jwst-docs.stsci.edu/jwst-near-infrared-imager-and-slitless-spectrograph/niriss-observing-strategies/niriss-wfss-recommended-strategies). In this case, that should match the number of direct images (`FILTER=CLEAR`) in `rate_df` because each direct image is at a unique dither position (XOFFSET, YOFFSET) within an observing sequence. For this program and observation, there is one direct image before a grism change with only one dither, another direct image with four dithers between the change in grisms, and a direct image at the end of a sequence with three dithers. This leads to a total of eight images per observing sequence, with five observing sequences in the observation using the blocking filters F115W -> F115W -> F150W -> F150W -> F200W."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6429ae4-cc03-4718-b2c2-12924170fe89",
   "metadata": {},
   "outputs": [],
   "source": [
    "image2_asns = glob.glob('*image2*asn*.json')\n",
    "print(len(image2_asns), 'Image2 ASN files') # there should be 40 asn files for image2\n",
    "\n",
    "# the number of association files should match the number of rate files\n",
    "print(len(rate_df[rate_df['FILTER'] == 'CLEAR']), 'Direct Image rate files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9226e1b9-9553-402b-910d-73f7cffcb784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at one of the association files\n",
    "asn_data = json.load(open(image2_asns[0]))\n",
    "for key, data in asn_data.items():\n",
    "    print(f\"{key} : {data}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c3a7f0-ec0a-403a-9c55-58b2ac6559a7",
   "metadata": {},
   "source": [
    "From this association, we can tell many things about the observation:\n",
    "1. From `asn_type` and `asn_rule`, we can see that this is an image2 association\n",
    "2. From `degraded_status` we can see that there are no exposures to not be included in the calibration.\n",
    "3. From `constraints`, we can see this is not a time series observation (TSO), the observation is part of program 2079, observed with NIRISS with the CLEAR (i.e. imaging for WFSS) and F150W filters.\n",
    "4. From `products` we can see there is only one exposure associated. This is typical for image2 where there is usually only one exposure per dither per observing sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5641931-1042-4494-a527-43e521803f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in particular, take a closer look at the product filenames with the association file:\n",
    "for product in asn_data['products']:\n",
    "    for key, value in product.items():\n",
    "        if key == 'members':\n",
    "            print(f\"{key}:\")\n",
    "            for member in value:\n",
    "                print(f\"    {member['expname']} {member['exptype']}\")\n",
    "        else:\n",
    "            print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2dbaea-228e-4565-928b-2984f4d7fda7",
   "metadata": {},
   "source": [
    "#### Run image2\n",
    "\n",
    "The `rate.fits` products will be calibrated into `cal.fits` files. More information about the steps performed in the Image2 part of the pipeline can be found in the [Image2 pipeline documentation](https://jwst-pipeline.readthedocs.io/en/latest/jwst/pipeline/calwebb_image2.html).\n",
    "\n",
    "In this case, we're saving the outputs to the same directory we are running the pipeline in so that we can then use the output `cal` files to run the Image3 pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff099be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for img2_asn in image2_asns:\n",
    "    # check if the calibrated file already exists\n",
    "    asn_data = json.load(open(img2_asn))\n",
    "    cal_file = f\"{asn_data['products'][0]['name']}_cal.fits\"\n",
    "    if os.path.exists(cal_file):\n",
    "        print(cal_file, 'cal file already exists.')\n",
    "        continue\n",
    "    # if not, calibrated with image2\n",
    "    img2 = Image2Pipeline.call(img2_asn, save_results=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1ae678",
   "metadata": {},
   "source": [
    "<a id='default_image3'></a>\n",
    "### Run Default Image3 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fd5c10",
   "metadata": {},
   "source": [
    "#### Looking in a Level 3 Association File\n",
    "The contents are quite similar to image2, but notice now that there are many more members that are associated together, and they use the individual pointing cal files from image2. Image3 resamples and combines images of the same blocking filter (PUPIL for NIRISS WFSS) from all dither and observing sequences to form a single image, which leads to fewer image3 association files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf6ac3b-333f-451d-8157-f83ccba9352c",
   "metadata": {},
   "outputs": [],
   "source": [
    "image3_asns = glob.glob('*image3*asn*.json')\n",
    "print(len(image3_asns), 'Image3 ASN files') # there should be 3 image3 association files\n",
    "\n",
    "# the number of image3 association files should match the number of unique blocking filters used\n",
    "uniq_filters = np.unique(rate_df[rate_df['FILTER'] == 'CLEAR']['PUPIL'])\n",
    "print(f\"{len(uniq_filters)} unique filters used: {uniq_filters}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add4839e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at one of the association files\n",
    "image3_asn_data = json.load(open(image3_asns[0]))\n",
    "for key, data in image3_asn_data.items():\n",
    "    print(f\"{key} : {data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2831ae47-5b1b-4d92-b02a-8ce1ee359710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in particular, take a closer look at the product filenames with the association file:\n",
    "for product in image3_asn_data['products']:\n",
    "    for key, value in product.items():\n",
    "        if key == 'members':\n",
    "            print(f\"{key}:\")\n",
    "            for member in value:\n",
    "                print(f\"    {member['expname']} {member['exptype']}\")\n",
    "        else:\n",
    "            print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cab171d",
   "metadata": {},
   "source": [
    "#### Run image3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3bd322-7f67-43c4-8dae-dc47779462ee",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "In Image3, the `cal.fits` individual pointing files will be calibrated into a single combined `i2d.fits` image. The Image3 step is also where the final source catalog is created, so we can change some input paramters to obtain a more refined output source catalog. This is done below in the [Custom Imaging Pipeline Run](#custom) section. However, we will first calibrate the data with the default parameters. More information about the steps performed in the Image3 part of the pipeline can be found in the [Image3 pipeline documentation](https://jwst-pipeline.readthedocs.io/en/latest/jwst/pipeline/calwebb_image3.html).\n",
    "\n",
    "**Note: Image3 can take a while to run**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf900af",
   "metadata": {},
   "outputs": [],
   "source": [
    "for img3_asn in image3_asns:\n",
    "    # check if the calibrated file already exists\n",
    "    asn_data = json.load(open(img3_asn))\n",
    "    cal_file = os.path.join(default_run_image3, f\"{asn_data['products'][0]['name']}_i2d.fits\")\n",
    "    if os.path.exists(cal_file):\n",
    "        print(cal_file, 'cal file already exists.')\n",
    "        continue\n",
    "    # if not, calibrated with image3\n",
    "    img3 = Image3Pipeline.call(img3_asn, save_results=True, output_dir=default_run_image3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5b3614-cfc3-42b7-b5ce-e243eb680ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove unnecessary files to save disk space\n",
    "for crf in glob.glob(os.path.join(default_run_image3, '*crf.fits')):\n",
    "    os.remove(crf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f0dbeb-4caf-4d97-8b2c-3255f906e76b",
   "metadata": {},
   "source": [
    "<a id='view_default'></a>\n",
    "### Inspecting Default Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47da18f6-92e3-4fff-8153-222cfc55d353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are all resuts from the Image3 pipeline\n",
    "image3_i2d = np.sort(glob.glob(os.path.join(default_run_image3, '*i2d.fits'))) # combined image over multiple dithers/mosaic\n",
    "image3_segm = np.sort(glob.glob(os.path.join(default_run_image3, '*segm.fits'))) # segmentation map that defines the extent of a source\n",
    "image3_cat = np.sort(glob.glob(os.path.join(default_run_image3, '*cat.ecsv'))) # Source catalog that defines the RA/Dec of a source at a particular pixel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7442c52c-d399-4593-a488-e30e02261383",
   "metadata": {},
   "source": [
    "#### Matplotlib\n",
    "Matplotlib has limitations where ImViz might better suite your needs -- especially if you like to look at things in WCS coordinates. For the notebook purposes, we are highlighting a few key areas using the matplotlib package instead.\n",
    "\n",
    "Using the `i2d` combined image and the source catalog produced by Image3, we can visually inspect if we're happy with where the pipeline found the sources. In the following figures, what has been defined as an extended source by the pipeline is shown in orange-red, and what has been defined as a point source by the pipeline is shown in grey. This definition affects the extraction box in the WFSS images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0945914a-bebc-4a8e-b619-fded2bd42485",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 10))\n",
    "\n",
    "cols = 2\n",
    "rows = int(np.ceil(len(image3_i2d) / cols))\n",
    "\n",
    "for plt_num, img in enumerate(image3_i2d):\n",
    "\n",
    "    # determine where the subplot should be\n",
    "    xpos = (plt_num % 40) % cols\n",
    "    ypos = ((plt_num % 40) // cols) # // to make it an int.\n",
    "\n",
    "    # make the subplot\n",
    "    ax = plt.subplot2grid((rows, cols), (ypos, xpos))\n",
    "\n",
    "    # plot the image\n",
    "    with fits.open(img) as hdu:\n",
    "        ax.imshow(hdu[1].data, vmin=0, vmax=0.3, origin='lower')\n",
    "        ax.set_title(f\"obs{hdu[0].header['OBSERVTN']} {hdu[0].header['PUPIL']}\")\n",
    "\n",
    "    # also plot the associated catalog\n",
    "    cat = Table.read(img.replace('i2d.fits', 'cat.ecsv'))\n",
    "    extended_sources = cat[cat['is_extended'] == 1] # 1 is True; i.e. is extended\n",
    "    point_sources = cat[cat['is_extended'] == 0] # 0 is False; i.e. is a point source\n",
    "    ax.scatter(extended_sources['xcentroid'], extended_sources['ycentroid'], s=20, facecolors='None', edgecolors='orangered', alpha=0.9)\n",
    "    ax.scatter(point_sources['xcentroid'], point_sources['ycentroid'], s=20, facecolors='None', edgecolors='dimgrey', alpha=0.9)\n",
    "\n",
    "# Helps to make the axes not overlap ; you can also set this manually if this doesn't work\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d157e3a8-2f2a-4487-8329-f6fa56713212",
   "metadata": {},
   "source": [
    "The segmentation maps are also a product of the Image3 pipeline, and they are used the help determine the source catalog. Let's take a look at those to ensure we are happy with what it is defining as a source.\n",
    "\n",
    "In the segmentation map, each blue blob should correspond to a physical target. There are cases where sources can be blended, in which case the parameters for making the semgentation map and source catalog should be changed. An example of this can be seen below in the observation 004 F200W filter image where two galaxies at ~(1600, 1300) have been blended into one source. This is discussed in more detail below in [Custom Imaging Pipeline Run](#custom). \n",
    "\n",
    "*Note that because of the [filter offset difference](https://jwst-docs.stsci.edu/jwst-near-infrared-imager-and-slitless-spectrograph/niriss-instrumentation/niriss-gr150-grisms#NIRISSGR150Grisms-Blockingfilters) the field of views for the shown in the cutouts below differs for each filter.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27845f3-65f0-46ce-9c0e-70e64ce65bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will look at this multiple times, so let's define this as a function\n",
    "def plot_image_and_segmentation_map(i2d_images, segm_images, xmin=1250, xmax=1750, ymin=1250, ymax=1750, cat_suffix='cat.ecsv'):\n",
    "        \n",
    "    cols = 2\n",
    "    rows = len(i2d_images)\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 10*(rows/2)))\n",
    "\n",
    "    for plt_num, img in enumerate(np.sort(np.concatenate([segm_images, i2d_images]))):\n",
    "    \n",
    "        # determine where the subplot should be\n",
    "        xpos = (plt_num % 40) % cols\n",
    "        ypos = ((plt_num % 40) // cols) # // to make it an int.\n",
    "\n",
    "        # make the subplot\n",
    "        ax = plt.subplot2grid((rows, cols), (ypos, xpos))\n",
    "    \n",
    "        if 'i2d' in img:\n",
    "            cat = Table.read(img.replace('i2d.fits', cat_suffix))\n",
    "            cmap = 'gist_gray'\n",
    "        else:\n",
    "            cmap = 'tab20c_r'\n",
    "            \n",
    "        # plot the image\n",
    "        with fits.open(img) as hdu:\n",
    "            ax.imshow(hdu[1].data, vmin=0, vmax=0.3, origin='lower', cmap=cmap)\n",
    "            title = f\"obs{hdu[0].header['OBSERVTN']} {hdu[0].header['PUPIL']}\"\n",
    "    \n",
    "        # also plot the associated catalog\n",
    "        extended_sources = cat[cat['is_extended'] == 1] # 1 is True; i.e. is extended\n",
    "        point_sources = cat[cat['is_extended'] == 0] # 0 is False; i.e. is a point source\n",
    "        \n",
    "        for color, sources in zip(['darkred', 'black'], [extended_sources, point_sources]):\n",
    "            # plotting the sources\n",
    "            ax.scatter(sources['xcentroid'], sources['ycentroid'], s=20, facecolors='None', edgecolors=color, alpha=0.9)\n",
    "    \n",
    "            # adding source labels \n",
    "            for i, source_num in enumerate(sources['label']):\n",
    "                ax.annotate(source_num, \n",
    "                            (sources['xcentroid'][i]+0.5, sources['ycentroid'][i]+0.5), \n",
    "                            fontsize=8,\n",
    "                            color=color)\n",
    "        if 'i2d' in img:\n",
    "            ax.set_title(f\"{title} combined image\")\n",
    "        else:\n",
    "            ax.set_title(f\"{title} segmentation map\")\n",
    "        \n",
    "        # zooming in on a smaller region\n",
    "        ax.set_xlim(xmin, xmax)\n",
    "        ax.set_ylim(ymin, ymax)\n",
    "    \n",
    "    # Helps to make the axes not overlap ; you can also set this manually if this doesn't work\n",
    "    plt.tight_layout()\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0599d52e-7a92-4c16-92e7-59ae62cfe8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_fig = plot_image_and_segmentation_map(image3_i2d, image3_segm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1addba0-ae56-4565-b12a-3ded03d9b0bf",
   "metadata": {},
   "source": [
    "#### ImViz\n",
    "\n",
    "Similarly to DS9, ImViz allows you to interactively view these images and the corresponding source catalog as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bec8a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "imviz = Imviz()\n",
    "viewer = imviz.default_viewer\n",
    "\n",
    "# plot each i2d image\n",
    "catalogs = [] # for plotting the catalogs\n",
    "labels = [] # for plotting the catalogs\n",
    "for img in image3_i2d:\n",
    "    print(f'Plotting: {img}')\n",
    "    label = f\"obs{fits.getval(img, 'OBSERVTN')} {fits.getval(img, 'PUPIL')}\"\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter('ignore')\n",
    "        imviz.load_data(img, data_label=label)\n",
    "\n",
    "    # save info to plot the catalogs next\n",
    "    catalogs.append(img.replace('i2d.fits', 'cat.ecsv'))\n",
    "    labels.append(label)\n",
    "\n",
    "# this aligns the image to use the WCS coordinates; \n",
    "#   the images need to be loaded first, but before adding markers\n",
    "linking = imviz.plugins['Orientation']\n",
    "linking.link_type = 'WCS'\n",
    "\n",
    "# also plot the associated catalog\n",
    "#   this needs to be a separate loop due to linking in imviz when using sky coordinates\n",
    "for catname, label in zip(catalogs, labels):\n",
    "    cat = Table.read(catname)\n",
    "    \n",
    "    # format the table into the format imviz expects\n",
    "    sky_coords = Table({'coord': [SkyCoord(ra=cat['sky_centroid'].ra.degree,\n",
    "                                           dec=cat['sky_centroid'].dec.degree,\n",
    "                                           unit=\"deg\")]})\n",
    "\n",
    "    viewer.marker = {'color': 'orange', 'alpha': 1, 'markersize': 20, 'fill': False}\n",
    "    viewer.add_markers(sky_coords, use_skycoord=True, marker_name=f\"{label} catalog\")\n",
    "\n",
    "# This changes the stretch of all of the images\n",
    "plotopt = imviz.plugins['Plot Options']\n",
    "plotopt.select_all(viewers=True, layers=True)\n",
    "plotopt.stretch_preset = '99.5%'\n",
    "    \n",
    "imviz.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea23a1b-4b6f-4ee1-9e2b-ff132dd9127d",
   "metadata": {},
   "source": [
    "<a id='custom'></a>\n",
    "## Custom Imaging Pipeline Run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14216c26-cf89-4f15-b7ec-b5a8ca0071ba",
   "metadata": {},
   "source": [
    "<a id='custom_image3'></a>\n",
    "### Image3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc697e5-92de-4a2a-a9e1-3f81d20fcf27",
   "metadata": {},
   "source": [
    "Try editing a few parameters and compare the outcomes to the default run above, at first for a single file.\n",
    "\n",
    "When we call the image3 pipeline, we can add modifications to a specific step of the pipeline. In this case we're going to edit the `source_catalog` and `tweakreg` steps of the pipeline. An explanation of the different parameters to tweak can be found in the further information below, while the default values are a combination of both the default pipeline values listed in there, and the parameter reference files that are supplied.\n",
    "- [source_catalog Further Information](https://jwst-pipeline.readthedocs.io/en/latest/api/jwst.source_catalog.SourceCatalogStep.html)\n",
    "- [tweakreg Futher Information](https://jwst-pipeline.readthedocs.io/en/latest/api/jwst.tweakreg.tweakreg_step.TweakRegStep.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2f7f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "image3_asns = np.sort(glob.glob('*image3*asn*.json'))\n",
    "test_asn = image3_asns[1]\n",
    "\n",
    "# check if the calibrated file already exists\n",
    "asn_data = json.load(open(test_asn))\n",
    "i2d_file = os.path.join(custom_run_image3, f\"{asn_data['products'][0]['name']}_i2d.fits\")\n",
    "\n",
    "if os.path.exists(i2d_file):\n",
    "    print(i2d_file, 'i2d file already exists.')\n",
    "else:\n",
    "    # call the image3 pipeline in the same way as before, but add a few new modifications\n",
    "    cust_img3 = Image3Pipeline.call(test_asn,\n",
    "                                    steps={\n",
    "                                           'source_catalog': {'kernel_fwhm': 5.0,\n",
    "                                                              'snr_threshold': 10.0,\n",
    "                                                              'npixels': 50,\n",
    "                                                              'deblend': True,\n",
    "                                                              },\n",
    "                                           'tweakreg': {'snr_threshold': 20,\n",
    "                                                        'abs_refcat': 'GAIADR3',\n",
    "                                                        'save_catalogs': True,\n",
    "                                                        'searchrad': 3.0,\n",
    "                                                        'kernel_fwhm': 2.302,\n",
    "                                                        'fitgeometry': 'shift',\n",
    "                                                        },\n",
    "                                           },\n",
    "                                    save_results=True,\n",
    "                                    output_dir=custom_run_image3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403345ea-1f26-4ead-b680-ab6a54f73421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove unnecessary files to save disk space\n",
    "for crf in glob.glob(os.path.join(custom_run_image3, '*crf.fits')):\n",
    "    os.remove(crf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d4cdae-0cad-4385-b93b-6976ecf90898",
   "metadata": {},
   "source": [
    "<a id='view_custom'></a>\n",
    "### Inspecting Custom Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e15c74-65e5-45b2-bf83-4e512cff4c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_i2d = os.path.join(default_run_image3, os.path.basename(i2d_file))\n",
    "compare_i2ds = [i2d_file, default_i2d]\n",
    "compare_segm = [i2d_file.replace('i2d.fits', 'segm.fits'), default_i2d.replace('i2d.fits', 'segm.fits')]\n",
    "\n",
    "compare_fig = plot_image_and_segmentation_map(compare_i2ds, compare_segm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd7891a-22ec-4913-a9fd-b153b66a932e",
   "metadata": {},
   "source": [
    "The cell below shows similar information using Imviz instead to visualize this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724d7a9e-f923-4cc0-8e99-6d21008db42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "imviz = Imviz()\n",
    "viewer = imviz.default_viewer\n",
    "\n",
    "for img, label in zip([i2d_file, os.path.join(default_run_image3, os.path.basename(i2d_file))], ['custom', 'default']):\n",
    "    print(f'Plotting: {img}')\n",
    "    title = f\"{label} obs{fits.getval(img, 'OBSERVTN')} {fits.getval(img, 'PUPIL')}\"\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter('ignore')\n",
    "        imviz.load_data(img, data_label=title)\n",
    "\n",
    "    # this aligns the image to use the WCS coordinates\n",
    "    linking = imviz.plugins['Orientation']\n",
    "    linking.link_type = 'WCS'\n",
    "\n",
    "    # also plot the associated catalog\n",
    "    cat = Table.read(img.replace('i2d.fits', 'cat.ecsv'))\n",
    "    # format the table into the format imviz expects\n",
    "    t_xy = Table({'x': cat['xcentroid'],\n",
    "                  'y': cat['ycentroid']})\n",
    "    viewer.marker = {'color': 'orange', 'alpha': 1, 'markersize': 20, 'fill': False}\n",
    "    viewer.add_markers(t_xy, marker_name=f\"{label} catalog\")\n",
    "\n",
    "# This changes the stretch of all of the images\n",
    "plotopt = imviz.plugins['Plot Options']\n",
    "plotopt.select_all(viewers=True, layers=True)\n",
    "plotopt.stretch_preset = '99.5%'\n",
    "    \n",
    "imviz.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ae7dc1-45ce-41a6-a5a3-c07226efc912",
   "metadata": {},
   "source": [
    "Calibrate the remaining images if you are happy with the above results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4787d1bb-57a7-4056-b93e-c5e7497d14cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "image3_asns = np.sort(glob.glob('*image3*asn*.json'))\n",
    "\n",
    "for img3_asn in image3_asns:\n",
    "    # check if the calibrated file already exists\n",
    "    asn_data = json.load(open(img3_asn))\n",
    "    i2d_file = os.path.join(custom_run_image3, f\"{asn_data['products'][0]['name']}_i2d.fits\")\n",
    "    if os.path.exists(i2d_file):\n",
    "        print(i2d_file, 'cal file already exists.')\n",
    "        continue\n",
    "    # call the image3 pipeline in the same way as before, but add a few new modifications\n",
    "    cust_img3 = Image3Pipeline.call(img3_asn,\n",
    "                                    steps={\n",
    "                                           'source_catalog': {'kernel_fwhm': 5.0,\n",
    "                                                              'snr_threshold': 10.0,\n",
    "                                                              'npixels': 50,\n",
    "                                                              'deblend': True,\n",
    "                                                              },\n",
    "                                           'tweakreg': {'snr_threshold': 20,\n",
    "                                                        'abs_refcat': 'GAIADR3',\n",
    "                                                        'save_catalogs': True,\n",
    "                                                        'searchrad': 3.0,\n",
    "                                                        'kernel_fwhm': 2.302,\n",
    "                                                        'fitgeometry': 'shift',\n",
    "                                                        },\n",
    "                                           },\n",
    "                                    save_results=True,\n",
    "                                    output_dir=custom_run_image3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828566bf-fb5f-4ba5-8ef7-0de09a73f0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove unnecessary files to save disk space\n",
    "for crf in glob.glob(os.path.join(custom_run_image3, '*crf.fits')):\n",
    "    os.remove(crf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8286e568-a553-4434-93ff-74829b79d110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are all resuts from the Image3 pipeline\n",
    "cust_image3_i2d = np.sort(glob.glob(os.path.join(custom_run_image3, '*i2d.fits'))) # combined image over multiple dithers/mosaic\n",
    "cust_image3_segm = np.sort(glob.glob(os.path.join(custom_run_image3, '*segm.fits'))) # segmentation map that defines the extent of a source\n",
    "\n",
    "custom_fig = plot_image_and_segmentation_map(cust_image3_i2d, cust_image3_segm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812a461f-27f5-4ae7-84bd-4c4cafe0c603",
   "metadata": {},
   "source": [
    "<a id='source_cat'></a>\n",
    "## Refining the Source Catalog Further"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191a12fb-0989-46d2-8e62-792cf3b23f4a",
   "metadata": {},
   "source": [
    "In the above cases, we have modified the results using the pipeline directly. It might be the case that perhaps you want to use someone else's custom source catalog, or modify the source catalog even further from what was output by the pipeline. In these cases, we will then need to modify the spec2 ASN files to point to the new source catalog, which will be discussed in the spec2 notebook. Additionally, it can be useful to match all of the source IDs across the different catalogs. In this case, there are three different catalogs created by the pipeline that identify the same RA/Dec or X/Y pixel location as a different source ID, so we will edit those to have the same source ID values across the catalogs. These extra steps aren't always necessary, but could be helpful in analyses of NIRISS WFSS data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eef927a-4301-481c-b730-d80219b9d14e",
   "metadata": {},
   "source": [
    "<a id='match_sources'></a>\n",
    "#### Matching Source IDs Across Catalogs\n",
    "\n",
    "In the above figures, you can see that the same source has multiple source IDs. Here we want to match all of the source IDs across all observations to be sure we are talking about the same source regardless of which filter or observation we look at. To do this, we use the astropy `match_to_catalog_3d` function and rebase the labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca9e9eb-6420-421a-818b-1faab1db788a",
   "metadata": {},
   "source": [
    "The first step is to decide on a base catalog to match all of the other catalogs to. Here we'll use the the observation 004 F115W filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d024dff0-6ffc-408c-ae86-b65f766e73ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_cats = np.sort(glob.glob(os.path.join(custom_run_image3, '*niriss_clear-f????_cat.ecsv'))) # cat filename format from image3 results\n",
    "print(\"All image3 catalogs:\\n\", custom_cats)\n",
    "\n",
    "base_cat = Table.read(custom_cats[0])\n",
    "\n",
    "# save out the base catalog with a new name to be consistent\n",
    "base_cat_name = custom_cats[0].replace('cat.ecsv', 'source-match_cat.ecsv')\n",
    "base_cat.write(base_cat_name, overwrite=True)\n",
    "print(\"\\nBase catalog:\", base_cat_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589f1d52-3915-43c6-93b7-32915139e7d6",
   "metadata": {},
   "source": [
    "Loop through the remaining catalogs to match the IDs based off of sky coordinates matching to within 1 arcsecond."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f6ce9b-d995-489c-8f1b-b6ce76e4b5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sep = 1 * u.arcsec # adjust if necessary\n",
    "\n",
    "base_sky = base_cat['sky_centroid']\n",
    "\n",
    "for to_match_cat in custom_cats[1:]:\n",
    "    # read in the catalog\n",
    "    other_cat = Table.read(to_match_cat)\n",
    "    other_sky = other_cat['sky_centroid']\n",
    "\n",
    "    # find the matching sources between the two catalogs based on sky coordinates\n",
    "    idx, d2d, d3d = base_sky.match_to_catalog_3d(other_sky)\n",
    "    sep_constraint = d2d < max_sep\n",
    "    base_matches = base_cat[sep_constraint]\n",
    "    other_matches = other_cat[idx[sep_constraint]]\n",
    "\n",
    "    # rebase the ID values to be the same\n",
    "    other_matches['label'] = base_matches['label']\n",
    "\n",
    "    # save out the new catalog\n",
    "    match_cat_name = to_match_cat.replace('cat.ecsv', 'source-match_cat.ecsv')\n",
    "    other_matches.write(match_cat_name, overwrite=True)\n",
    "    print('Saved:', match_cat_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f080887a-c1dd-435e-ae8a-72dcfebf9606",
   "metadata": {},
   "source": [
    "Look at the new source label numbers. They should match!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0e4837-f956-4cd2-b4f9-68a60d647605",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cat_fig = plot_image_and_segmentation_map(cust_image3_i2d, cust_image3_segm, cat_suffix='source-match_cat.ecsv',\n",
    "                                              xmin=1500, xmax=2000, ymin=800, ymax=1300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686b13dc-0573-45ec-8828-9be428bf32ea",
   "metadata": {},
   "source": [
    "<a id='manual_cat'></a>\n",
    "#### Manually Editing the Source Catalog\n",
    "\n",
    "Looking ahead to the WFSS extraction, it might be that we only really care about one or two sources at any particular moment. In this case, it's helpful to pair down the source catalog to just that source to make it easier to look at the extracted 1-D spectrum in the WFSS data.\n",
    "\n",
    "- [Source Catalog Column Information](https://jwst-pipeline.readthedocs.io/en/latest/jwst/source_catalog/main.html#output-products)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a379ccea-58a4-4440-b1f5-26c9736e36c6",
   "metadata": {},
   "source": [
    "To start, look at the current custom source catalog for one of the filters to get an idea of what is contained in the catalogs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51fa992-9785-4c96-a4fa-99572e16f63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, look at the current, custom source catalog for the F200W filter\n",
    "cat_name = np.sort(glob.glob(os.path.join(custom_run_image3, '*source-match_cat.ecsv')))[2]\n",
    "cat = Table.read(cat_name)\n",
    "\n",
    "print(cat_name)\n",
    "cat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66930bfc-8647-4e00-8369-936eaff148a9",
   "metadata": {},
   "source": [
    "There may be multiple ways to look for a source, so shown below are three options:\n",
    "1. With a known RA/Dec of an object\n",
    "2. A known x/y location of an object\n",
    "3. With a source ID of an object. Note that we are using the rebased source catalogs here for the IDs.\n",
    "\n",
    "This same concept can be extended to filter by any of the columns contained in the source catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5af10e-90c8-4e08-bff7-b6b798f9bea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with a known RA/Dec\n",
    "desired_ra = 53.15437048946369\n",
    "desired_dec = -27.771689847051736\n",
    "\n",
    "c = SkyCoord(ra=desired_ra*u.degree, dec=desired_dec*u.degree)\n",
    "nearest_id, distance_2d, distance_3d = c.match_to_catalog_sky(cat['sky_centroid']) \n",
    "\n",
    "cat[['label', 'xcentroid', 'ycentroid', 'sky_centroid', 'is_extended', 'isophotal_abmag', 'isophotal_vegamag']][nearest_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bd4079-c774-471d-94da-004a7fd287e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternatively with a known X/Y pixel location in the F200W image (based on what you've defined cat to be)\n",
    "known_x = 1880\n",
    "known_y = 1100\n",
    "\n",
    "nearest_pos = [np.sqrt((x-known_x)**2 + (y-known_y)**2) for x, y in zip(cat['xcentroid'], cat['ycentroid'])]\n",
    "\n",
    "wh_nearest = np.where(np.array(nearest_pos) == min(nearest_pos))[0][0]\n",
    "\n",
    "cat[['label', 'xcentroid', 'ycentroid', 'sky_centroid', 'is_extended', 'isophotal_abmag', 'isophotal_vegamag']][wh_nearest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572fe4a4-3d4d-4364-9672-7b2d23154fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternatively with a known source number\n",
    "# note that this number might be different for you depending on pipeline versions and parameters changed.\n",
    "# source = 109 # if you want to specify the number\n",
    "source = cat['label'][nearest_id] # to match the one chosen in this notebook\n",
    "\n",
    "wh_source = np.where(np.array(cat['label'] == source))[0][0]\n",
    "\n",
    "cat[['label', 'xcentroid', 'ycentroid', 'sky_centroid', 'is_extended', 'isophotal_abmag', 'isophotal_vegamag']][wh_source]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3303d1c5-d484-46d1-9472-e57862660c31",
   "metadata": {},
   "source": [
    "Using any of the three methods above, write out the new catalog.\n",
    "- with RA/Dec: `new_cat = Table(cat[nearest_id])`\n",
    "- with x/y: `new_cat = Table(cat[wh_nearest])`\n",
    "- with source ID: `new_cat = Table(cat[wh_source])`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae96ac3-a587-4672-8edf-8bb327eea6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cat = Table(cat[wh_source]) # turn the row instance into a dataframe again\n",
    "\n",
    "# save the new catalog with a unique name\n",
    "new_cat_name = cat_name.replace('cat.ecsv', f'source{source}_cat.ecsv')\n",
    "new_cat.write(new_cat_name, overwrite=True)\n",
    "print('Saved:', new_cat_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2a8566-eb1c-4df0-b4eb-f24c6edc8e56",
   "metadata": {},
   "source": [
    "Once we have an updated source catalog that we are content with, we can move on to the spec2 step of the pipeline. It likely will be necessary to come back to this step after running spec2. Let's take a quick look at the source that we will be extracting in the following notebook with spec2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443842e0-b30a-4a31-937c-1880eb7f697a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(9, 6))\n",
    "\n",
    "img = cust_image3_i2d[-1]\n",
    "    \n",
    "cat = Table.read(new_cat_name)\n",
    "\n",
    "for ax in [ax1, ax2]:\n",
    "    # plot the image\n",
    "    with fits.open(img) as hdu:\n",
    "        ax.imshow(hdu[1].data, vmin=0, vmax=0.3, origin='lower')\n",
    "        title = f\"obs{hdu[0].header['OBSERVTN']} {hdu[0].header['PUPIL']}\"\n",
    "        \n",
    "    # also plot the associated catalog\n",
    "    extended_sources = cat[cat['is_extended'] == 1] # 1 is True; i.e. is extended\n",
    "    point_sources = cat[cat['is_extended'] == 0] # 0 is False; i.e. is a point source\n",
    "            \n",
    "    for color, sources in zip(['darkred', 'black'], [extended_sources, point_sources]):\n",
    "        # plotting the sources\n",
    "        ax.scatter(sources['xcentroid'], sources['ycentroid'], s=20, facecolors='None', edgecolors=color, alpha=0.9)\n",
    "    \n",
    "        # adding source labels \n",
    "        for i, source_num in enumerate(sources['label']):\n",
    "            ax.annotate(source_num, \n",
    "                        (sources['xcentroid'][i]+0.5, sources['ycentroid'][i]+0.5), \n",
    "                        fontsize=8,\n",
    "                        color=color)\n",
    "\n",
    "fig.suptitle(\"Speicifc Source to Extract with Spec2\")\n",
    "\n",
    "# zooming in on a smaller region\n",
    "ax2.set_xlim(known_x-50, known_x+50)\n",
    "ax2.set_ylim(known_y-50, known_y+50)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73170cc-0e25-44d2-ac6b-0ba56e8122a4",
   "metadata": {},
   "source": [
    "<img style=\"float: right;\" src=\"https://raw.githubusercontent.com/spacetelescope/notebooks/master/assets/stsci_pri_combo_mark_horizonal_white_bkgd.png\" alt=\"Space Telescope Logo\" width=\"200px\"/>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
