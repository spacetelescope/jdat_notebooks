{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "771e1de8",
   "metadata": {},
   "source": [
    "<a id='top'></a>\n",
    "# NIRSpec IFU Pipeline Processing ERO 02732 NGC 7319 AGN\n",
    "<hr style=\"border:3px solid black\">\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "* [1. Introduction](#intro)\n",
    "* [2. Import Library](#imports)\n",
    "* [3. Convenience Functions](#func)\n",
    "* [4. Directory Set-Up](#dir_setup)\n",
    "* [5. Download the data](#data)\n",
    "* [6. Products Found In MAST](#mast_products)\n",
    "  * [6.1 Stage 1 Products Found In MAST](#level1_mast)\n",
    "  * [6.2 Stage 2 Products Found In MAST](#level2_mast)\n",
    "  * [6.3 Stage 3 Products Found In MAST](#level3_mast)\n",
    "* [7. Re-processing the Data](#reprocessing)\n",
    "  * [7.1 Stage 1 Rerun & Products](#level1_rerun)\n",
    "  * [7.2 Stage 2 Rerun & Products](#level2_rerun)\n",
    "  * [7.3 Stage 3 Rerun & Products](#level3_rerun)\n",
    "    * [7.3.1 New Outlier Detection Algorithm](#outlier_detection_new)\n",
    "* [8. Conclusion](#conclusion)\n",
    "* [About This Notebook](#about)\n",
    "\n",
    "\n",
    "\n",
    "## 1. Introduction <a id='intro'></a>\n",
    "<hr style=\"border:1px solid gray\">\n",
    "\n",
    "End-to-end calibration of JWST data is divided into 3 main stages of processing. This notebook explores how to run the JWST calibration pipeline stages 1-3 for NIRSpec IFU spectroscopic data.\n",
    "   <figure>\n",
    "       <img src='./NGC_7319_AGN.png' title=\"Figure 1: NGC 7319 AGN\" alt=\"NGC_7319_AGN\" class=\"bg-primary\" align=\"right\" style=\"width: 400px; height: 350px;\"/>\n",
    "   </figure>\n",
    "\n",
    ">* **`STAGE 1`** ([calwebb_detector1](https://jwst-pipeline.readthedocs.io/en/latest/jwst/pipeline/calwebb_detector1.html#calwebb-detector1)): consists of detector-level corrections, performed on a group-by-group basis, followed by ramp fitting.\n",
    "    * **Input**: Raw exposure (`uncal.fits`) containing original data from all detector readouts (ncols x nrows x ngroups x nintegrations).\n",
    "    * **Output**: Corrected countrate (slope) image (`rate.fits`) \n",
    ">* **`STAGE 2`** ([calwebb_spec2](https://jwst-pipeline.readthedocs.io/en/latest/jwst/pipeline/calwebb_spec2.html#calwebb-spec2)): consists of additional instrument-level and observing mode corrections and calibrations.\n",
    "    * **Input**: A single corrected countrate (slope) image (`rate.fits`) or an ASN file listing multiple inputs.\n",
    "    * **Output**: A fully calibrated unrectified exposure (`cal.fits`). For NIRSpec IFU data, the `cube_build` step returns a 3-D IFU spectroscopic cube (`s3d.fits`). The `extract_1d` step  returns 1-D extracted spectral data products (`x1d.fits`)\n",
    ">* **`STAGE 3`** ([calwebb_spec3](https://jwst-pipeline.readthedocs.io/en/latest/jwst/pipeline/calwebb_spec3.html#calwebb-spec3)): consists of additional corrections (e.g. `outlier_detection`) and routines for combining calibrated data from multiple exposures (e.g. dither/nod pattern) into a single combined 2-D or 3-D spectral product and a combined 1-D spectrum. \n",
    "    * **Input**: An ASN file that lists multiple calibrated exposures (`cal.fits`).\n",
    "    * **Output**: For NIRSpec IFU data, a resampled and combined 3-D IFU cube (`s3d.fits`) and a 1-D extracted spectrum (`x1d.fits`)\n",
    "\n",
    "Here, we will focus on the mechanics of processing \"real\" example data [(NGC 7319 AGN)](#NGC_7319_AGN) from Early Release Science (ERS) Proposal ID 2732, including how to use associations for multi-exposure combination, how to interact and work with data models for each product, and mainly how to process IFU data as an extended source. Our objective is to examine the automated products found in MAST and compare them to products generated with the most up-to-date version of the JWST calibration pipeline.\n",
    "\n",
    "Most processing runs shown here use the default reference files from the Calibration Reference Data System (CRDS). Please note that pipeline software development is a continuous process, so results in some cases may be slightly different if using a subsequent version. There are also a few known issues with some of the pipeline steps in this build that we expect to be fixed in the near future. Until then, at various steps, we provide users with the current processing recommendations when running the pipeline manually."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d60407",
   "metadata": {},
   "source": [
    "## 2. Import Library <a id='imports'></a>\n",
    "<hr style=\"border:1px solid gray\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9cb1f4f-fdc7-420b-a820-57515432e746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Set CRDS environment variables ----------\n",
    "import os\n",
    "import jwst\n",
    "os.environ['CRDS_CONTEXT'] = 'jwst_1210.pmap'\n",
    "os.environ['CRDS_PATH'] = os.environ['HOME']+'/crds_cache'\n",
    "os.environ['CRDS_SERVER_URL'] = 'https://jwst-crds.stsci.edu'\n",
    "print(f'CRDS cache location: {os.environ[\"CRDS_PATH\"]}')\n",
    "\n",
    "print(\"JWST Calibration Pipeline Version={}\".format(jwst.__version__))\n",
    "# print(\"Current Operational CRDS Context = {}\".format(crds.get_default_context()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8a7536-2ec2-45fd-a3e8-ba4694c05838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Library\n",
    "# ---------- General Imports ----------\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import warnings\n",
    "import glob\n",
    "import json\n",
    "import urllib.request\n",
    "import zipfile\n",
    "import fnmatch\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import matplotlib.gridspec as grd\n",
    "from matplotlib import cm\n",
    "from shutil import copy\n",
    "\n",
    "# ---------- Astropy/Astroquery Imports ----------\n",
    "from astropy.io import fits\n",
    "from astropy.wcs import WCS\n",
    "from astropy.visualization import ImageNormalize, ManualInterval\n",
    "from astropy.visualization import LogStretch, LinearStretch, AsinhStretch\n",
    "from astroquery.mast import Observations\n",
    "\n",
    "# ---------- JWST Calibration Pipeline Imports ----------\n",
    "from jwst import datamodels\n",
    "from jwst.pipeline import Detector1Pipeline   # calwebb_detector1\n",
    "from jwst.pipeline import Spec2Pipeline       # calwebb_spec2\n",
    "from jwst.pipeline import Spec3Pipeline       # calwebb_spec3\n",
    "\n",
    "warnings.filterwarnings('ignore')  # Set to 'default' to turn warnings back on\n",
    "\n",
    "# Use this version for non-interactive plots (easier scrolling of the notebook)\n",
    "%matplotlib inline\n",
    "# Use this version (outside of Jupyter Lab) if you want interactive plots\n",
    "# %matplotlib notebook\n",
    "\n",
    "# These gymnastics are needed to make the sizes of the figures\n",
    "# be the same in both the inline and notebook versions\n",
    "%config InlineBackend.print_figure_kwargs = {'bbox_inches': None}\n",
    "mpl.rcParams['savefig.dpi'] = 80\n",
    "mpl.rcParams['figure.dpi'] = 80\n",
    "plt.rcParams.update({'font.size': 18})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140a9682",
   "metadata": {},
   "source": [
    "## 3. Convenience Functions <a id='func'></a>\n",
    "<hr style=\"border:1px solid gray\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9da49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(data_2d, vmin, vmax, xsize=15, ysize=15, title=None,\n",
    "               zoom_in=None, aspect=1, scale='log', units='DN/s', cmap='jet'):\n",
    "    \"\"\"\n",
    "    Function to generate a 2-D, log-scaled image of the data\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data_2d : numpy.ndarray\n",
    "        2-D image to be displayed\n",
    "    vmin : float\n",
    "        Minimum signal value to use for scaling\n",
    "    vmax : float\n",
    "        Maximum signal value to use for scaling\n",
    "    xsize, ysize: int\n",
    "        Figure Size\n",
    "    title : str\n",
    "        String to use for the plot title\n",
    "    zoom_in: list\n",
    "        Zoomed in Region of interest [xstart,xstop,ystart,ystop]\n",
    "    aspect: int\n",
    "        Aspect ratio of the axes\n",
    "    scale : str\n",
    "        Specify scaling of the image. Can be 'log' or 'linear' or 'Asinh'\n",
    "    units : str\n",
    "        Units of the data. Used for the annotation in the color bar.\n",
    "        Defualt is DN/s for countrate images\n",
    "    cmap: str\n",
    "        Color Map for plot\n",
    "    \"\"\"\n",
    "    # ---------- Scaling Information ----------\n",
    "\n",
    "    if scale == 'log':\n",
    "        norm = ImageNormalize(data_2d, interval=ManualInterval(vmin=vmin, vmax=vmax),\n",
    "                              stretch=LogStretch())\n",
    "    elif scale == 'linear':\n",
    "        norm = ImageNormalize(data_2d, interval=ManualInterval(vmin=vmin, vmax=vmax),\n",
    "                              stretch=LinearStretch())\n",
    "    elif scale == 'Asinh':\n",
    "        norm = ImageNormalize(data_2d, interval=ManualInterval(vmin=vmin, vmax=vmax),\n",
    "                              stretch=AsinhStretch())\n",
    "\n",
    "    # ---------- Set Up Figure ----------\n",
    "\n",
    "    fig = plt.figure(figsize=(xsize, ysize))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "    im = ax.imshow(data_2d, origin='lower', norm=norm, aspect=aspect, cmap=cmap)\n",
    "\n",
    "    fig.colorbar(im, label=units)\n",
    "    plt.xlabel('Pixel column')\n",
    "    plt.ylabel('Pixel row')\n",
    "\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "\n",
    "    # Zoom in on a portion of the image?\n",
    "    if zoom_in:\n",
    "        # inset axis\n",
    "        axins = ax.inset_axes([0.5, 0.6, 0.5, 0.3])\n",
    "\n",
    "        axins.imshow(data_2d, origin=\"lower\", norm=norm, aspect=aspect, cmap=cmap)\n",
    "\n",
    "        # subregion of the original image\n",
    "        axins.set_xlim(zoom_in[0], zoom_in[1])\n",
    "        axins.set_ylim(zoom_in[2], zoom_in[3])\n",
    "        axins.set_xticklabels([])\n",
    "        axins.set_yticklabels([])\n",
    "        ax.indicate_inset_zoom(axins, color=\"black\", edgecolor=\"black\", linewidth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d233556",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_ifu_cubeslices(s3d_file_list, wavelength_slices=[], spaxel_locs=[],\n",
    "                        y_scale=None, cmap='jet', vmin_vmax=[[[0, 15e1]]],\n",
    "                        save_figure=False, title=None, title_font=30):\n",
    "    \"\"\"\n",
    "    Function to that takes a 3-D IFU data cube and generates:\n",
    "\n",
    "    > 2-D cube slices based on wavelength (microns)\n",
    "    > Associated 1-D spectrum for a designated spaxel (spatial pixel) in the data cube\n",
    "    > Corresponding 3-D weight image giving the relative weights of the output spaxels\n",
    "\n",
    "    Note: This function can accomidate multiple detectors plotted side-by-side.\n",
    "    The general format would follow [[detector 1 info], [detector 2 info]].\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    s3d_file_list: list of str\n",
    "        3-D IFU data cube fits file list\n",
    "    wavelength_slices: tuple\n",
    "        List of wavelength values (microns) at which to create 2-D slices.\n",
    "    spaxel_locs: tuple\n",
    "        List of spaxel locations in which to plot the\n",
    "        associated 1-D spectrum. (One spaxel location per slice).\n",
    "    y_scale: tuple\n",
    "        Y-axis limits for the associated 1-D spectrum of the spaxel.\n",
    "        Default is to use the ymin and ymax of the data.\n",
    "    cmap: str\n",
    "        Color Map\n",
    "    vmin_vmax: tuple\n",
    "        Minimum & Maximum signal value to use for scaling\n",
    "        (e.g., [[[vmin,vmax],[vmin,vmax]], [[vmin,vmax], [vmin,vmax]]]).\n",
    "    title: str\n",
    "        Figure Title. Default is None.\n",
    "    title_font:int\n",
    "        Title Font Size\n",
    "    save_figure: bool\n",
    "        Save figure?\n",
    "    \"\"\"\n",
    "\n",
    "    # ---------- Set-up Figure ----------\n",
    "\n",
    "    # Plot Slices From the Cube\n",
    "    fig = plt.figure(figsize=(8 * np.array(wavelength_slices).size, 18))\n",
    "    gs = grd.GridSpec(3, np.array(wavelength_slices).size, height_ratios=[1] * 3,\n",
    "                      width_ratios=[1] * np.array(wavelength_slices).size,\n",
    "                      hspace=0.4, wspace=0.7)\n",
    "\n",
    "    total_num_plots = 3 * np.array(wavelength_slices).size\n",
    "\n",
    "    plot_count = 0\n",
    "    # ---------- Open Files ----------\n",
    "\n",
    "    for s3d_file in s3d_file_list:\n",
    "\n",
    "        root = s3d_file[:-9] # Root file name\n",
    "\n",
    "        s3d = fits.open(s3d_file) # 3-D IFU data cube fits file\n",
    "        x1d3 = datamodels.open(root+'_x1d.fits') # 1-D Extracted Spectrum\n",
    "\n",
    "        # ---------- Wavelength & Surface Brightness/Flux Arrays ----------\n",
    "\n",
    "        x1d3wave = x1d3.spec[0].spec_table.WAVELENGTH\n",
    "\n",
    "        # ---------- Data & Header Information ----------\n",
    "\n",
    "        # SCI Extension:\n",
    "        # [Type:ImageHDU  Cards:92   Dimensions:(57, 61, 973)   Format:float32]\n",
    "        cube = s3d[1].data # Science data\n",
    "        wcs = WCS(s3d[1].header) # World Coordinate System (WCS) Transformation keywords\n",
    "        # 3-D weight image giving the relative weights of the output spaxels.\n",
    "        wmap = s3d[4].data\n",
    "        # Axis 3 coordinate increment at reference point\n",
    "        cdelt3 = s3d[1].header['CDELT3']\n",
    "        crval3 = s3d[1].header['CRVAL3'] # third axis value at the reference pixel\n",
    "\n",
    "        # Wavelength range of the grating/filter combination\n",
    "        wavstart = s3d[1].header['WAVSTART']\n",
    "        wavend = s3d[1].header['WAVEND']\n",
    "        s3d.close()\n",
    "\n",
    "        # ---------- Plots ----------\n",
    "        colors = [\"darkred\", \"darkturquoise\", \"blue\"]\n",
    "        cmap_custom = cm.colors.LinearSegmentedColormap.from_list(\"\", colors)\n",
    "        colors = cmap_custom(np.linspace(0, 1, np.array(wavelength_slices).size))\n",
    "\n",
    "        # To Account for if NRS1 & NRS2 are both being plotted Side-by-side\n",
    "        if len(wavelength_slices) != 1:\n",
    "            if 'nrs1' in s3d_file:\n",
    "                wavelengths = wavelength_slices[0]\n",
    "                spaxel_loc = spaxel_locs[0]\n",
    "                vmin_vmax_vals = vmin_vmax[0]\n",
    "\n",
    "                if y_scale:\n",
    "                    y_scales = y_scale[0]\n",
    "\n",
    "            elif 'nrs2' in s3d_file:\n",
    "                wavelengths = wavelength_slices[1]\n",
    "                spaxel_loc = spaxel_locs[1]\n",
    "                vmin_vmax_vals = vmin_vmax[1]\n",
    "                if y_scale:\n",
    "                    y_scales = y_scale[1]\n",
    "\n",
    "        else:\n",
    "            wavelengths = wavelength_slices[0]\n",
    "            spaxel_loc = spaxel_locs[0]\n",
    "            vmin_vmax_vals = vmin_vmax[0]\n",
    "            if y_scale:\n",
    "                y_scales = y_scale[0]\n",
    "\n",
    "        # Loop through each wavelength slices\n",
    "        for i, wave_slice in enumerate(wavelengths):\n",
    "\n",
    "            if float(wavstart) <= wave_slice * 10 ** -6 <= float(wavend):\n",
    "\n",
    "                # ---------- 2-D Cube Slice ----------\n",
    "\n",
    "                # Min & Max Image Values & Scaling\n",
    "                if len(vmin_vmax_vals) != 1:\n",
    "                    vmax_val = vmin_vmax_vals[i][1]\n",
    "                    vmin_val = vmin_vmax_vals[i][0]\n",
    "                else:\n",
    "                    vmax_val = vmin_vmax_vals[0][1]\n",
    "                    vmin_val = vmin_vmax_vals[0][0]\n",
    "\n",
    "                slicewave = wave_slice\n",
    "                # The slice of the cube we want to plot\n",
    "                nslice = int((slicewave - crval3)/cdelt3)\n",
    "                # Setup the subplot space\n",
    "                ax1 = plt.subplot(gs[0+plot_count], projection=wcs,\n",
    "                                  slices=('x', 'y', nslice))\n",
    "\n",
    "                # Mean of the slice looking in the range (nslice-2):(nslice+2)\n",
    "                slice_mean = np.nanmean(cube[(nslice - 2):(nslice + 2), :, :], axis=0)\n",
    "                # Normalize & stretch\n",
    "                slice_norm = ImageNormalize(slice_mean, vmin=vmin_val,\n",
    "                                            vmax=vmax_val, stretch=AsinhStretch())\n",
    "                slice_image = ax1.imshow(slice_mean, norm=slice_norm,\n",
    "                                         origin='lower', aspect='auto', cmap=cmap)\n",
    "\n",
    "                cb_image = fig.colorbar(slice_image, fraction=0.046, pad=0.04)\n",
    "                cb_image.set_label('MJy/sr', labelpad=-1, fontsize=22)\n",
    "                cb_image.ax.tick_params(labelsize=20)\n",
    "                cb_image.ax.yaxis.get_offset_text().set_fontsize(20)\n",
    "\n",
    "                ax1.set_xlabel('RA', fontsize=22)\n",
    "                ax1.set_ylabel('DEC', labelpad=-1, fontsize=22)\n",
    "                # ax1.grid(color='white', ls='solid')\n",
    "                ax1.set_title('Detector {}\\nGrating/Filter: {}/{}\\n{} microns'.format(\n",
    "                                    s3d[0].header['DETECTOR'],\n",
    "                                    s3d[0].header['GRATING'],\n",
    "                                    s3d[0].header['FILTER'],\n",
    "                                    str(slicewave)\n",
    "                                ), fontsize=25)\n",
    "                ax1.tick_params(axis='both', which='major', labelsize=20)\n",
    "                ax1.coords[0].set_ticklabel(rotation=13, ha='right', pad=24)\n",
    "\n",
    "                # ---------- Spaxel 1-D Spectrum ----------\n",
    "\n",
    "                # Zoom in on a Spaxel: Spectrum\n",
    "                loc = [spaxel_loc[i][0], spaxel_loc[i][1]]\n",
    "                x1d3flux_loc = cube[:, loc[1], loc[0]]\n",
    "                ax2 = plt.subplot(gs[int(total_num_plots/3)+plot_count])\n",
    "\n",
    "                # Spaxel Box Highlight\n",
    "                spaxel_rect = plt.Rectangle((loc[0]-.5, loc[1]-.5), 1, 1,\n",
    "                                            fill=False, color='black', linewidth=2)\n",
    "                ax1.add_patch(spaxel_rect)\n",
    "\n",
    "                ax2.plot(x1d3wave, x1d3flux_loc, linewidth=1, color=colors[i])\n",
    "                ax2.grid(linewidth=2)\n",
    "                ax2.set_xlabel('$\\u03BB [\\u03BC$m]', fontsize=22)\n",
    "                ax2.set_ylabel(\"Surface Brightness \\n (MJy/sr)\", fontsize=22)\n",
    "                ax2.set_title('Spaxel at (x, y)='+repr(loc), fontsize=25)\n",
    "                ax2.tick_params(axis='both', which='major', labelsize=20)\n",
    "                ax2.yaxis.get_offset_text().set_fontsize(15)\n",
    "\n",
    "                # Scale Information\n",
    "                if y_scale:\n",
    "                    ymin, ymax = y_scales[i][0], y_scales[i][1]\n",
    "                else:\n",
    "                    ymin, ymax = ax2.set_ylim()\n",
    "\n",
    "                ax2.set_ylim(ymin, ymax)\n",
    "                ax2.xaxis.set_tick_params(labelsize=20)\n",
    "                ax2.yaxis.set_tick_params(labelsize=20)\n",
    "                ax2.set_aspect(0.5/ax2.get_data_ratio())\n",
    "\n",
    "                # ---------- Weight Map ----------\n",
    "\n",
    "                # Corresponding Weight Map (wmap) for Cube Slice\n",
    "                ax3 = plt.subplot(\n",
    "                        gs[int(total_num_plots)-np.array(wavelength_slices).size+plot_count],\n",
    "                        projection=wcs,\n",
    "                        slices=('x', 'y', nslice))\n",
    "\n",
    "                # Mean of the wmap slice looking in the range (nslice-2):(nslice+2)\n",
    "                slice_mean_wmap = np.nanmean(wmap[(nslice-2):(nslice+2), :, :], axis=0)\n",
    "                # Normalize & stretch\n",
    "                slice_norm_wmap = ImageNormalize(slice_mean_wmap,\n",
    "                                                 stretch=AsinhStretch())\n",
    "                slice_wmap = ax3.imshow(slice_mean_wmap, norm=slice_norm_wmap,\n",
    "                                        origin='lower', aspect='auto', cmap=cmap)\n",
    "\n",
    "                cb_wmap = fig.colorbar(slice_wmap, fraction=0.046, pad=0.04)\n",
    "                cb_wmap.set_label('Weight', labelpad=-1, fontsize=22)\n",
    "                cb_wmap.ax.tick_params(labelsize=20)\n",
    "                cb_wmap.ax.yaxis.get_offset_text().set_fontsize(20)\n",
    "\n",
    "                ax3.set_xlabel('RA', fontsize=22)\n",
    "                ax3.set_ylabel('DEC', labelpad=-1, fontsize=22)\n",
    "                # ax3.grid(color='gray', ls='solid')\n",
    "                ax3.set_title(str(slicewave)+' microns: Weight Map', fontsize=25)\n",
    "                ax3.tick_params(axis='both', which='major', labelsize=20)\n",
    "                ax3.coords[0].set_ticklabel(rotation=13, ha='right', pad=24)\n",
    "\n",
    "                plot_count += 1\n",
    "\n",
    "            else:\n",
    "                None\n",
    "\n",
    "    if title:\n",
    "        fig.suptitle(title, fontsize=title_font)\n",
    "        plt.subplots_adjust(top=0.8)\n",
    "\n",
    "    fig.tight_layout(rect=[0, 0, 0.98, 0.98])\n",
    "\n",
    "    if save_figure:\n",
    "        fig.savefig(root+\".png\", dpi=24, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e23e973",
   "metadata": {},
   "source": [
    "## 4. Directory Set-Up <a id='dir_setup'></a>\n",
    "<hr style=\"border:1px solid gray\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70c0dd1-6013-414e-bd71-c7afbb7eba56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To rerun the notebook and all the pipeline steps set runflag=True.\n",
    "runflag = True\n",
    "\n",
    "# To run with pre-computed data, set `runflag=False` and specify the local directory.\n",
    "output_dir = './nirspec_ifu_02732_rerun/'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d17cc0",
   "metadata": {},
   "source": [
    "## 5. Download the Data <a id='data'></a>\n",
    "\n",
    "<hr style=\"border:1px solid gray\">\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "<b>Tip:</b> To download the data from MAST, you must input your MAST authorization token. Get your MAST Token Here: https://auth.mast.stsci.edu/token. Additionally, be sure to follow [astroquery installation procedures](https://astroquery.readthedocs.io/en/latest/index.html#) to properly run this cell. \n",
    "    \n",
    "</div> \n",
    "\n",
    "| Target: NGC 7319 AGN |       |   |   |   |\n",
    "|:-----------:|:-------:|---|---|---|\n",
    "| Proposal ID | 02732 |   |   |   |\n",
    "| [GRATING/FILTER](https://jwst-docs.stsci.edu/jwst-near-infrared-spectrograph/nirspec-observing-modes/nirspec-ifu-spectroscopy)   | PRISM/CLEAR | λ: 0.6–5.3 μm (a low resolution, R ~ 100) |   |   |\n",
    "|   DURATION  | 160.478 [s] | Total duration of one exposure |   |   |   |\n",
    "|   READPATT  | NRSIRS2RAPID | Readout Pattern |   |   |   |\n",
    "|   PATTTYPE  | CYCLING | Primary dither pattern type |   |   |\n",
    "|   PATTSIZE  | LARGE | Primary dither pattern size (1.0\" extent) |   |   |\n",
    "|   NUMDTHPT  | 8 | Total number of points in pattern |   |   | \n",
    "|   SRCTYAPT  | UNKNOWN | Source Type selected in APT |   |   | \n",
    "\n",
    "> **Note:** The presence of a physical gap between detectors affects high-resolution IFU observations because the spectra are long enough to span both NIRSpec detectors. When using the grating-filter combination G140H/F070LP (or PRISM/CLEAR) the resulting spectra do not have any gaps because the spectra do not extend beyond NRS1. [More Info ...](https://jwst-docs.stsci.edu/jwst-near-infrared-spectrograph/nirspec-operations/nirspec-ifu-operations/nirspec-ifu-wavelength-ranges-and-gaps#NIRSpecIFUWavelengthRangesandGaps-Wavelengthgaps)\n",
    "\n",
    "The cell below downloads the raw uncalibrated data along with the stage 2 and stage 3 products that are available in MAST. MAST products will get saved to a folder called `mast_products` within the designated output directory defined earlier in this notebook. These files have already been pre-downloaded and stored in a provided demo directory. To get the most up-to-date products set `runflag = True` and rerun this notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb9acfe-cdab-495e-a255-219da4140c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a directory for the downloaded data from MAST.\n",
    "mast_products_dir = output_dir+'mast_products/'\n",
    "if not os.path.exists(mast_products_dir):\n",
    "    os.makedirs(mast_products_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d53288-38c6-4b90-8492-745a249580d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processed MAST products for comparison:\n",
    "# RATE (stage 1) & CAL (stage 2&3) & S3D (stage 2&3) & X1D (stage2&3)\n",
    "\n",
    "if runflag:\n",
    "    # ---------- Products from MAST ----------\n",
    "\n",
    "    # Box link to the pre-proccessed data from MAST.\n",
    "    # We are downloading data from this Box link containing the products in MAST\n",
    "    # as they were at the time this notebook was created.\n",
    "    # Occasionally, products in MAST undergo re-processing.\n",
    "    # To ensure the notebook's reproducibility and maintain interpretability\n",
    "    # of comments throughout, we employ this approach.\n",
    "\n",
    "    boxlink_mast = \"https://stsci.box.com/shared/static/kzqnv9op5u34h1dz39x9j4bzly14nwqm.zip\"\n",
    "    boxfile_mast = os.path.join(mast_products_dir, '2732_mast_products.zip')\n",
    "    urllib.request.urlretrieve(boxlink_mast, boxfile_mast)\n",
    "\n",
    "    # Extract the files from the zip file.\n",
    "    with zipfile.ZipFile(boxfile_mast, 'r') as zip_ref:\n",
    "        zip_ref.extractall(mast_products_dir)\n",
    "    print(\"MAST products extracted successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd37df0-b49e-4c97-bc07-d5971d3725bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Download data from MAST\n",
    "\n",
    "# Setup your account\n",
    "\n",
    "# NOTE:\n",
    "# The data in this notebook is public and does not require a token.\n",
    "# For other data sets, uncomment the following line and enter your\n",
    "# token at the prompt.\n",
    "\n",
    "# Observations.login(token=None)\n",
    "\n",
    "sessioninfo = Observations.session_info()\n",
    "\n",
    "# Define the general search criteria\n",
    "obs = Observations.query_criteria(\n",
    "        obs_collection='JWST',\n",
    "        instrument_name=['NIRSPEC/IFU'],\n",
    "        proposal_id='02732')\n",
    "\n",
    "# Print the Observations returned from the general search criteria\n",
    "products = Observations.get_product_list(obs)\n",
    "# print(products)\n",
    "\n",
    "# Filter the list of observations\n",
    "# In this case we look for UNCAL products and\n",
    "# ASN files to manually run pipeline stage 1-3\n",
    "filtered = Observations.filter_products(products,\n",
    "                                        productSubGroupDescription=[\"UNCAL\", \"ASN\"],\n",
    "                                        mrp_only=False)\n",
    "\n",
    "# Only download data for the G235H/F170LP configuration in this dataset.\n",
    "subset_extensions = ['*nrs1_uncal.fits', '*_spec3_00001_asn.json']\n",
    "\n",
    "# Print the filtered products\n",
    "number = len(filtered)\n",
    "for k in range(number):\n",
    "    if any(fnmatch.fnmatch(filtered['productFilename'][k], pattern)\n",
    "           for pattern in subset_extensions):\n",
    "        print(filtered['productFilename'][k])\n",
    "\n",
    "# Download the filtered products\n",
    "# This creates a mastDownload directory,\n",
    "# unless you set flat=True and set a download_dir.\n",
    "for i in range(len(filtered)):\n",
    "    if runflag:\n",
    "        # Override any cached files and download the most up-to-date ones.\n",
    "        if any(fnmatch.fnmatch(filtered['productFilename'][i], pattern)\n",
    "               for pattern in subset_extensions):\n",
    "            Observations.download_products(filtered[i], mrp_only=False, cache=False,\n",
    "                                           flat=True, download_dir=mast_products_dir)\n",
    "    else:\n",
    "        # Find any cached files first before downloading new ones.\n",
    "        if any(fnmatch.fnmatch(filtered['productFilename'][i], pattern)\n",
    "               for pattern in subset_extensions):\n",
    "            Observations.download_products(filtered[i], mrp_only=False, cache=True,\n",
    "                                           flat=True, download_dir=mast_products_dir)\n",
    "print(\"Raw data and ASN files from MAST downloaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dee6a2f",
   "metadata": {},
   "source": [
    "## 6. Products Found In MAST <a id='mast_products'></a>\n",
    "<hr style=\"border:1px solid gray\">\n",
    "\n",
    "> In [APT](https://jwst-docs.stsci.edu/jwst-astronomers-proposal-tool-overview), the observer has three options for source type (`SRCTYAPT` keyword): `POINT`, `EXTENDED`, or `UNKNOWN`. In stage 2, the `srctype` step will first check if the `SRCTYAPT` keyword is present and populated. If `SRCTYAPT` is not present or is set to `UNKNOWN`, the step determines a suitable value based on the observing mode, command line input, and other characteristics of the exposure. If the exposure is identified as a background exposure (`BKGDTARG = True`), the exposures default to a source type of `EXTENDED`. Exposures that are part of a nodded pattern (identified by keyword `PATTYPE`), which are assumed to only be used with point-like targets, default to a source type of `POINT`. [More Info ...](https://jwst-pipeline.readthedocs.io/en/latest/jwst/srctype/description.html#single-source-observations)\n",
    "\n",
    "For dithered NIRSpec IFU data like ours, which do not meet any of the above conditions, will default to source type `EXTENDED`. <mark> Therefore, the products found in MAST for target NGC 7319 AGN (PID 02732) have been processed as an `EXTENDED` source </mark>. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f59a62",
   "metadata": {},
   "source": [
    "### 6.1 Stage 1 Products Found In MAST  <a id='level1_mast'></a>\n",
    "<hr style=\"border:1px solid gray\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24dcd56",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Stage 1 slope products -- level 2a images\n",
    "\n",
    "# Plot 4th (out of 8) dither position (spectra fall only on NRS1)\n",
    "# for GRATING/FILTER PRISM/CLEAR combination\n",
    "for rate_file in sorted(glob.glob(mast_products_dir+'*00004_nrs1_rate.fits')):\n",
    "\n",
    "    ratefile_open = datamodels.open(rate_file)\n",
    "    # Get the pixel data (the SCI extension of the fits file)\n",
    "    ratefile_sci = ratefile_open.data\n",
    "    ratefile_dq = ratefile_open.dq  # Data quality map data (DQ extension)\n",
    "\n",
    "    # Print the version and CRDS pmap used to create these rate.fits files\n",
    "    # ratefile_open.serach(key='context')\n",
    "    print(\"Products found in MAST used JWST calibration pipeline version: {} and {}\"\n",
    "          .format(ratefile_open.meta.calibration_software_version,\n",
    "                  ratefile_open.meta.ref_file.crds.context_used))\n",
    "\n",
    "    # Plot the slope image and small section of the\n",
    "    # countrate image & corresponding section of the DQ map.\n",
    "    detector = ratefile_open.meta.instrument.detector\n",
    "    dither_pos = ratefile_open.meta.dither.position_number\n",
    "    grating = ratefile_open.meta.instrument.grating\n",
    "    filter_ = ratefile_open.meta.instrument.filter\n",
    "\n",
    "    title_sci = ('Countrate Image\\n'\n",
    "                 'Detector: {}\\n'\n",
    "                 '8-Cycle Dither Position Index: {}\\n'\n",
    "                 'GRATING/FILTER: {}/{}'\n",
    "                 .format(detector, dither_pos, grating, filter_))\n",
    "\n",
    "    title_dq = ('Data Quality Map \\n'\n",
    "                'Detector: {} \\n'\n",
    "                '8-Cycle Dither Position Index: {} \\n'\n",
    "                'GRATING/FILTER: {}/{}'\n",
    "                .format(detector, dither_pos, grating, filter_))\n",
    "\n",
    "    # Plot the slope image and zoom in on a small section of the\n",
    "    # countrate image & corresponding section of the DQ map.\n",
    "    show_image(ratefile_sci, 0, 10, units='DN/s',\n",
    "               zoom_in=[500, 550, 1250, 1300], title=title_sci)\n",
    "    show_image(ratefile_dq, 0, 10, units='Bit Value', scale='linear',\n",
    "               zoom_in=[500, 550, 1250, 1300], title=title_dq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217a5889",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "    \n",
    "<b>Warning:</b> Please be aware that in the countrate (slope) images found in MAST, many pixels are flagged as Do Not Use (more clearly seen in the corresponding DQ map) and therefore appear white with a value of NaN. This excessive flagging is due to an outdated mask reference file that would mark unreliable slope, bad fit, and telegraph pixels as Do Not Use. Despite the large number of NaNs in the countrate image, the extracted spectra are not significantly affected by them when combining multiple dithered exposures because the number of flagged pixels is still a relatively small fraction. However, due to the high number of flags in the MAST products, it is difficult to see specific details in the slope images, like correlated read noise, which manifests as low-level vertical banding/striping and a \"picture frame\" with the [$IRS^{2}$](https://jwst-docs.stsci.edu/jwst-near-infrared-spectrograph/nirspec-instrumentation/nirspec-detectors/nirspec-detector-readout-modes-and-patterns/nirspec-irs2-detector-readout-mode) readout mode. As of context jwst_1084.pmap, the pipeline now considers unreliable slope, bad fit, and telegraph pixels good for further processing in Full frame data. [Therefore, the reprocessed data below offers improved visibility of the correlated read noise.](#level1_rerun)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511d3a5f",
   "metadata": {},
   "source": [
    "### 6.2 Stage 2 Products Found In MAST  <a id='level2_mast'></a>\n",
    "<hr style=\"border:1px solid gray\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8221ff0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 2 Products\n",
    "# Calibrated 3-D data cube for PRISM/CLEAR (only falls on NRS1)\n",
    "\n",
    "# Plotting the 4th (out of 8) dither position\n",
    "stage2_s3d_file = sorted(glob.glob(mast_products_dir+'*00004_nrs1_s3d.fits'))\n",
    "\n",
    "# Print the version and CRDS pmap used to create these S3D files\n",
    "# stage2_s3d_file_open.serach(key='context')\n",
    "stage2_s3d_file_open = datamodels.open(stage2_s3d_file[0])\n",
    "print(\"Products found in MAST used JWST calibration pipeline version: {} and {}\"\n",
    "      .format(stage2_s3d_file_open.meta.calibration_software_version,\n",
    "              stage2_s3d_file_open.meta.ref_file.crds.context_used))\n",
    "\n",
    "title_stage2_mast = ('NGC 7319 AGN \\n Level 2 IFU Product:'\n",
    "                     '3-D Cube Slices vs. Corresponding 3-D Weighted Map')\n",
    "\n",
    "# Characteristics of the plot\n",
    "\n",
    "# Wavelength slices (microns) to take from the 3-D data cube\n",
    "nrs1_wavelengths = [1.4, 3.3, 4.5]\n",
    "\n",
    "# Spaxel locations for associated 1-D spectrum (one spaxel plotted per slice)\n",
    "nrs1_spaxel_locs = [[30, 29], [28, 39], [14, 25]]\n",
    "\n",
    "# Plot using the convience function defined above\n",
    "show_ifu_cubeslices(stage2_s3d_file, wavelength_slices=[nrs1_wavelengths],\n",
    "                    spaxel_locs=[nrs1_spaxel_locs], title=title_stage2_mast)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f5cf27",
   "metadata": {},
   "source": [
    "### 6.3 Stage 3 Products Found In MAST  <a id='level3_mast'></a>\n",
    "\n",
    "<hr style=\"border:1px solid gray\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f187aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 3 Products\n",
    "# Combined Calibrated 3-D data cube for PRISM/CLEAR (only falls on NRS1)\n",
    "\n",
    "stage3_s3d_file = sorted(glob.glob(mast_products_dir+'*nirspec_prism-clear_s3d.fits'))\n",
    "\n",
    "# Print the version and CRDS pmap used to create these S3D files\n",
    "# stage3_s3d_file_open.serach(key='context')\n",
    "stage3_s3d_file_open = datamodels.open(stage2_s3d_file[0])\n",
    "print(\"Products found in MAST used JWST calibration pipeline version: {} and {}\"\n",
    "      .format(stage3_s3d_file_open.meta.calibration_software_version,\n",
    "              stage3_s3d_file_open.meta.ref_file.crds.context_used))\n",
    "\n",
    "title_stage3_mast = ('NGC 7319 AGN \\n Level 3 IFU Product:'\n",
    "                     '3-D Cube Slices vs. Corresponding 3-D Weighted Map')\n",
    "\n",
    "# Characteristics of the plot\n",
    "\n",
    "# Wavelength slices (microns) to take from the 3-D data cube\n",
    "nrs1_wavelengths = [1.4, 3.3, 4.5]\n",
    "\n",
    "# Spaxel locations for associated 1-D spectrum (one spaxel plotted per slice)\n",
    "nrs1_spaxel_locs = [[30, 29], [28, 39], [14, 25]]\n",
    "\n",
    "# Plot using the convience function defined above\n",
    "show_ifu_cubeslices(stage3_s3d_file, wavelength_slices=[nrs1_wavelengths],\n",
    "                    spaxel_locs=[nrs1_spaxel_locs], title=title_stage3_mast)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d3f605-0014-4eac-9c73-a9a9f547deb2",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "    \n",
    "<b>Warning:</b> Please note that in the final product (stage 3) downloaded from MAST, a significant portion of the data got rejected, returning a value of zero in the weight maps. This over-rejection of data is due to the outdated `outlier_detection` step that MAST automatically enables during stage 3 of the pipeline. A new outlier detection algorithm has been developed specifically for IFU data that overcomes some of these limitations (as of DMS build B9.3rc1/CAL_VER 1.11.0). Due to the limitations of the previous outlier detection algorithm, the user recommendation is to skip the `outlier_detection` step if using an older version of the pipleine or manually rerun stage 3 of the pipleine with outlier detection on with the most up-to-date pipeline version (detailed in the next section of this notebook).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3575d780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 3 Products -- Combined Extracted 1-D Spectrum\n",
    "\n",
    "x1d3_mast_list = glob.glob(mast_products_dir + '*nirspec_prism-clear_x1d.fits')\n",
    "x1d3_mast = datamodels.open(x1d3_mast_list[0])\n",
    "\n",
    "# Print the version and CRDS pmap used to create these X1D files\n",
    "# x1d3_mast.serach(key='context')\n",
    "print(\"Products found in MAST used JWST calibration pipeline version: {} and {}\"\n",
    "      .format(x1d3_mast.meta.calibration_software_version,\n",
    "              x1d3_mast.meta.ref_file.crds.context_used))\n",
    "\n",
    "# Wavelength & Surface Brightness Arrays\n",
    "x1d3wave_mast = x1d3_mast.spec[0].spec_table.WAVELENGTH\n",
    "x1d3flux_mast = x1d3_mast.spec[0].spec_table.SURF_BRIGHT\n",
    "\n",
    "# Plot the Extracted 1-D Spectrum\n",
    "fig = plt.figure(figsize=(15, 9))\n",
    "\n",
    "plt.plot(x1d3wave_mast, x1d3flux_mast, linewidth=2)\n",
    "\n",
    "# Where wavelength slice was taken above\n",
    "plt.vlines(1.4, 0., 400., 'black', 'dotted', label='1.4 microns')\n",
    "plt.vlines(3.3, 0., 400., 'red', 'dotted', label='3.3 microns')\n",
    "plt.vlines(4.5, 0., 400., 'green', 'dotted', label='4.5 microns')\n",
    "\n",
    "plt.xlabel(r'$\\lambda [\\mu$m]', fontsize=15)\n",
    "plt.ylabel('Surface Brightness (MJy/sr)', fontsize=15)\n",
    "plt.title((\"NGC 7319 AGN \\n Level 3 IFU Product in MAST:\"\n",
    "           \"Extracted 1-D Spectrum\"), fontsize=20)\n",
    "plt.ylim(0, 50)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced813b1",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<b>Note:</b> When the source type is extended, the default extraction aperture for the `extract_1d` step covers the entire cube.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b899f0",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Warning:</b> Most of the large negative and positive flux spikes extending beyond the plot range are likely due to bad/hot pixels that are not flagged in the current DQ masks. The mask reference file gets directly pulled from CRDS. The products found in MAST use a specific CRDS context (.pmap) when processing data. However, the CRDS is constantly updating the operational .pmap.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8e38b5",
   "metadata": {},
   "source": [
    "### 7. Re-processing the Data <a id='reprocessing'></a>\n",
    "<hr style=\"border:1px solid gray\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7211260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory for rerun of stage 1\n",
    "# to avoid overwriting MAST products.\n",
    "output_dir_rerun = output_dir+'rerun/'\n",
    "if not os.path.exists(output_dir_rerun):\n",
    "    os.makedirs(output_dir_rerun)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126569cf",
   "metadata": {},
   "source": [
    "### 7.1 Stage 1 Rerun & Products  <a id='level1_rerun'></a>\n",
    "<hr style=\"border:1px solid gray\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6b19a3-fddb-411b-9864-2799f527b937",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Stage 1 Processing\n",
    "\n",
    "if runflag:\n",
    "\n",
    "    for uncal_file in sorted(glob.glob(mast_products_dir+'*nrs1_uncal.fits')):\n",
    "\n",
    "        print(\"Applying Stage 1 Corrections & Calibrations to: \"\n",
    "              + os.path.basename(uncal_file))\n",
    "\n",
    "        result = Detector1Pipeline.call(uncal_file,\n",
    "                                        save_results=True,\n",
    "                                        output_dir=output_dir_rerun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f5160e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Stage 1 slope products -- level 2a images\n",
    "\n",
    "# Plot 4th (out of 8) dither position (NRS1 & NRS2)\n",
    "# for GRATING/FILTER G140H/F100LP combination.\n",
    "for rate_file in sorted(glob.glob(output_dir_rerun+'*00004_nrs?_rate.fits')):\n",
    "\n",
    "    ratefile_open = datamodels.open(rate_file)\n",
    "    # Get the pixel data (the SCI extension of the fits file)\n",
    "    ratefile_sci = ratefile_open.data\n",
    "    ratefile_dq = ratefile_open.dq # The Data Quality Map Data\n",
    "\n",
    "    detector = ratefile_open.meta.instrument.detector\n",
    "    dither_pos = ratefile_open.meta.dither.position_number\n",
    "    grating = ratefile_open.meta.instrument.grating\n",
    "    filter_ = ratefile_open.meta.instrument.filter\n",
    "\n",
    "    title_sci = ('Countrate Image\\n'\n",
    "                 'Detector: {}\\n'\n",
    "                 '8-Cycle Dither Position Index: {}\\n'\n",
    "                 'GRATING/FILTER: {}/{}'\n",
    "                 .format(detector, dither_pos, grating, filter_))\n",
    "\n",
    "    title_dq = ('Data Quality Map \\n'\n",
    "                'Detector: {} \\n'\n",
    "                '8-Cycle Dither Position Index: {} \\n'\n",
    "                'GRATING/FILTER: {}/{}'\n",
    "                .format(detector, dither_pos, grating, filter_))\n",
    "\n",
    "    # Plot the slope image and zoom in on a small section of the\n",
    "    # countrate image & corresponding section of the DQ map.\n",
    "    show_image(ratefile_sci, 0, 10, units='DN/s',\n",
    "               zoom_in=[500, 550, 1250, 1300], title=title_sci)\n",
    "    show_image(ratefile_dq, 0, 10, units='Bit Value', scale='linear',\n",
    "               zoom_in=[500, 550, 1250, 1300], title=title_dq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84c9f5b",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<b>Note:</b> Compared to the [countrate (slope) products found in MAST](#level1_mast), fewer pixels are flagged as Do Not Use when using the most up-to-date pmap in CRDS (at the time jwst_1106.pmap). With the latest pmap, one can observe low-level vertical banding in the central regions of the detector, and the \"picture frame\" towards the edge of both detectors, where there is less correlated read noise a lot easier. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32018775",
   "metadata": {},
   "source": [
    "### 7.2 Stage 2 Rerun & Products  <a id='level2_rerun'></a>\n",
    "<hr style=\"border:1px solid gray\">\n",
    "\n",
    "During stage 2 of the pipeline, the countrate (slope) image products from stage 1, which have units of DN/s, are converted to units of surface brightness (MJy/sr) for both extended and point sources (as of DMS build 9.3/CAL_VER 1.10.2). For extended targets, like the NGC 7319 AGN, the `extract_1d` step is controlled by a different set of parameters in the EXTRACT1D reference file: \n",
    "\n",
    "> For an extended source, rectangular aperture photometry is used, with the entire image being extracted, and no background subtraction, regardless of what was specified in the reference file or step arguments. [More Info ...](https://jwst-pipeline.readthedocs.io/en/latest/jwst/extract_1d/description.html)\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "    \n",
    "<b>Warning:</b> Note there has been a bug in the `cube_build` step that caused the point source flux to not be conserved when using different spatial sampling. A fix has been implemented as of release DMS build 9.3/CAL_VER 1.10.2. In order to enable the correct functionality, the units of the cal.fits files and cubes will now be in surface brightness, and only the 1-D extracted spectra will be in units of Jy.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba980d6f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Stage 2 Processing\n",
    "\n",
    "if runflag:\n",
    "\n",
    "    # Process each rate file separately\n",
    "    for rate_file in sorted(glob.glob(output_dir_rerun+'*nrs1*rate.fits')):\n",
    "\n",
    "        print(\"Applying Stage 2 Calibrations & Corrections to: \"\n",
    "              + os.path.basename(rate_file))\n",
    "\n",
    "        result = Spec2Pipeline.call(rate_file,\n",
    "                                    save_results=True,\n",
    "                                    output_dir=output_dir_rerun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66fe4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 2 Products -- Calibrated 3-D data cube for PRISM/CLEAR (only falls on NRS1)\n",
    "\n",
    "# Plotting the 4th (out of 8) dither position\n",
    "stage2_s3d_file = sorted(glob.glob(output_dir_rerun+'*00004_nrs1_s3d.fits'))\n",
    "\n",
    "title_stage2_rerun = ('NGC 7319 AGN \\n Level 2 IFU Product:'\n",
    "                      '3-D Cube Slices vs. Corresponding 3-D Weighted Map')\n",
    "\n",
    "\n",
    "# Characteristics of the plot\n",
    "\n",
    "# Wavelength slices (microns) to take from the 3-D data cube\n",
    "nrs1_wavelengths = [1.4, 3.3, 4.5]\n",
    "# Spaxel locations for associated 1-D spectrum (one spaxel plotted per slice)\n",
    "nrs1_spaxel_locs = [[30, 29], [28, 39], [14, 25]]\n",
    "\n",
    "\n",
    "# Plot using the convience function defined above\n",
    "show_ifu_cubeslices(stage2_s3d_file, wavelength_slices=[nrs1_wavelengths],\n",
    "                    spaxel_locs=[nrs1_spaxel_locs], title=title_stage2_rerun)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e369b29b",
   "metadata": {},
   "source": [
    "### 7.3 Stage 3 Rerun & Products  <a id='level3_rerun'></a>\n",
    "<hr style=\"border:1px solid gray\">\n",
    "\n",
    "***Level 3 ASN File***\n",
    "\n",
    "> Observations that use a nod-type/dither patterns, their exposures are related. [Association files (ASN)](https://jwst-pipeline.readthedocs.io/en/stable/jwst/associations/overview.html) describe how multiple exposures are related to one another and how they depend on one another. Processing an ASN file permits exposures to be calibrated, archived, retrieved, and reprocessed as a set rather than individual objects. IFU exposures taken with a dither pattern are not used for pixel-to-pixel background subtraction by the calibration pipeline (unlike exposures taken with a nod pattern).\n",
    "\n",
    "Therefore, all calibration files (`cal.fits`) in our spec3 ASN file should be labeled as science exposures (`exptype: science`).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05e9415",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Copy ASN file from MAST into the stage 1 rerun directory\n",
    "\n",
    "# ASN file found in MAST\n",
    "asnfile_mast = glob.glob(mast_products_dir+'*_spec3_00001_asn.json')[0]\n",
    "\n",
    "# New ASN file path\n",
    "asnfile_rerun = output_dir_rerun+os.path.basename(asnfile_mast)\n",
    "if not os.path.exists(asnfile_rerun):\n",
    "    copy(asnfile_mast, asnfile_rerun)\n",
    "\n",
    "# Check the ASN file contents\n",
    "with open(asnfile_rerun, 'r') as f_obj:\n",
    "    asnfile_rerun_data = json.load(f_obj)\n",
    "\n",
    "asnfile_rerun_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3f966d",
   "metadata": {},
   "source": [
    "#### 7.3.1 New Outlier Detection Algorithm<a id='outlier_detection_new'></a>\n",
    "<hr style=\"border:1px solid gray\">\n",
    "\n",
    "The new outlier detection algorithm for IFU data (as of DMS build B9.3rc1/CAL_VER 1.11.0) implements the basic outlier detection algorithm -- searches for pixels that are consistent outliers in the calibrated images created by the `calwebb_spec2` pipeline. The algorithm generally operates as follows:\n",
    "\n",
    "> * Identifies outlier pixels by comparing them with their neighboring pixels in the spatial direction across a set of input files within an association.\n",
    "> * For NIRSpec data, it calculates differences between pixels located above and below each science pixel.\n",
    "> * The pixel differences for every input model in the association are computed and stored in a stack of pixel differences.\n",
    "> * For each pixel, the algorithm determines the minimum difference across this stack and then performs normalization. This normalization process employs a local median derived from the difference array, with the size of the median determined by the kernel size.\n",
    "> * A pixel is flagged as an outlier if this normalized minimum difference is greater than the input threshold percentage. \n",
    "> * Pixels that are found to be outliers are flaged in in the DQ array.\n",
    "> * [More Info ...](https://jwst-pipeline.readthedocs.io/en/latest/jwst/outlier_detection/outlier_detection_ifu.html#outlier-detection-ifu)\n",
    "\n",
    "**[The outlier_detection step for IFU data has the following optional arguments that control the behavior of the processing](https://github.com/spacetelescope/jwst/blob/master/docs/jwst/outlier_detection/arguments.rst):**\n",
    "\n",
    "* `kernel_size` (string, default='7 7'): The size of the kernel to use to normalize the pixel differences. The kernel size must only contain odd values.\n",
    "* `threshold_percent` (float, default=99.8): The threshold (in percent) of the normalized minimum pixel difference used to identify bad pixels. Pixels with a normalized minimum pixel difference above this percentage are flagged as a outlier.\n",
    "* `save_intermediate_results` (boolean, default=False): Specifies whether or not to save any intermediate products created during step processing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177fa11a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Rerun stage 3 with outlier detection on\n",
    "if runflag:\n",
    "\n",
    "    result = Spec3Pipeline.call(asnfile_rerun,\n",
    "                                save_results=True,\n",
    "                                output_dir=output_dir_rerun,\n",
    "                                steps={\"outlier_detection\": {\"skip\": False,\n",
    "                                                             \"save_results\": True,\n",
    "                                                             \"kernel_size\": '3 3'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c7188b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 3 Products -- Combined Calibrated 3-D data cube for PRISM/CLEAR\n",
    "\n",
    "stage3_s3d_file = sorted(glob.glob(output_dir_rerun+'*nirspec_prism-clear_s3d.fits'))\n",
    "\n",
    "title_stage3_rerun = ('NGC 7319 AGN \\n Level 3 IFU Product:'\n",
    "                      '3-D Cube Slices vs. Corresponding 3-D Weighted Map')\n",
    "\n",
    "# Characteristics of the plot\n",
    "\n",
    "# Wavelength slices (microns) to take from the 3-D data cube\n",
    "nrs1_wavelengths = [1.4, 3.3, 4.5]\n",
    "\n",
    "# Spaxel locations for associated 1-D spectrum (one spaxel plotted per slice)\n",
    "nrs1_spaxel_locs = [[30, 29], [28, 39], [14, 25]]\n",
    "\n",
    "# Plot using the convience function defined above\n",
    "show_ifu_cubeslices(stage3_s3d_file, wavelength_slices=[nrs1_wavelengths],\n",
    "                    spaxel_locs=[nrs1_spaxel_locs], title=title_stage3_rerun)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322f8a59",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<b>Note:</b> In comparison to the [weight maps for the 3-D data cube products found in MAST](#level3_mast), the implementation of the new outlier detection algorithm leads to a notable decrease data rejection.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee63edd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 3 Products -- Combined Extracted 1-D Spectrum\n",
    "\n",
    "x1d3_rerun_list = glob.glob(output_dir_rerun+'*nirspec_prism-clear_x1d.fits')\n",
    "x1d3_rerun = datamodels.open(x1d3_rerun_list[0])\n",
    "\n",
    "# Wavelength & Surface Brightness Arrays\n",
    "x1d3wave_rerun = x1d3_rerun.spec[0].spec_table.WAVELENGTH\n",
    "x1d3flux_rerun = x1d3_rerun.spec[0].spec_table.SURF_BRIGHT\n",
    "\n",
    "# Plot the Extracted 1-D Spectrum\n",
    "fig = plt.figure(figsize=(15, 9))\n",
    "\n",
    "plt.plot(x1d3wave_rerun, x1d3flux_rerun, linewidth=2)\n",
    "\n",
    "# Where wavelength slice was taken above\n",
    "plt.vlines(1.4, 0., 400., 'black', 'dotted', label='1.4 microns')\n",
    "plt.vlines(3.3, 0., 400., 'red', 'dotted', label='3.3 microns')\n",
    "plt.vlines(4.5, 0., 400., 'green', 'dotted', label='4.5 microns')\n",
    "\n",
    "plt.xlabel(r'$\\lambda [\\mu$m]', fontsize=15)\n",
    "plt.ylabel('Surface Brightness (MJy/sr)', fontsize=15)\n",
    "plt.title((\"NGC 7319 AGN \\n Level 3 IFU Product in MAST:\"\n",
    "           \"Extracted 1-D Spectrum\"), fontsize=20)\n",
    "plt.ylim(0, 55)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645a1387",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<b>Note:</b> With the integration of the new outlier detection algorithm, a significant change is evident when comparing to the [1-D extracted spectrum found in MAST](#level3_mast). Previously prominent positive/negative spikes in the data have now been successfully identified and flagged as outliers.  \n",
    "</div>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6eb616-c8cf-46a1-b2f8-a5a642824171",
   "metadata": {},
   "source": [
    "## Conclusion <a id='conclusion'></a>\n",
    "<hr style=\"border:1px solid gray\">  \n",
    "\n",
    "In conclusion, this notebook walks users through processing real data (NGC 7319 AGN) from ERS Proposal ID 2732 and comparing automated products in MAST with those generated using the latest version of the JWST calibration pipeline and latest CRDS context. For optimal results, users are strongly encouraged to reprocess their own data using the most recent pipeline version and CRDS context, taking advantage of bug fixes and algorithm improvements (i.e., the new IFU outlier detection algorithm). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ed417a-849b-4777-9cea-2a39ea18b34a",
   "metadata": {},
   "source": [
    "## About This Notebook <a id='about'></a>\n",
    "<hr style=\"border:1px solid gray\">  \n",
    "\n",
    "**Authors**: Kayli Glidic (kglidic@stsci.edu),  Leonardo Ubeda (lubeda@stsci.edu)\n",
    "\n",
    "**Update On**: 2023-08-11 (Data links updated 2024-03-05)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
