{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "298b8519-c695-4562-a96c-96208063c1c3",
   "metadata": {},
   "source": [
    "# MIRI MRS IFU Spectroscopy Part 2: \n",
    "# Defining and Extracting a Background Spectrum\n",
    "\n",
    "Aug 2023\n",
    "\n",
    "**Use case:** Reduce MRS Data With User Defined Master Background Step. This is particularly relevant if you did not obtain a Dedicated Background with your observations. While the pipeline will subtract a sky background derived from an annulus, the underlying background may be prohibitively complicated and the user may wish to measure their own background from elsewhere in the cube.<br>\n",
    "**Data:** Publicly available science data for SN 1987A (Program 1232). For this notebook, we will follow the science workflow outlined by [Jones et al. 2023](https://ui.adsabs.harvard.edu/abs/2023arXiv230706692J/abstract).<br>\n",
    "**Tools:** jwst, jdaviz, matplotlib, astropy.<br>\n",
    "**Cross-intrument:** NIRSpec, MIRI.<br>\n",
    "**Documentation:** This notebook is part of a STScI's larger [post-pipeline Data Analysis Tools Ecosystem](https://jwst-docs.stsci.edu/jwst-post-pipeline-data-analysis) and can be [downloaded](https://github.com/spacetelescope/dat_pyinthesky/tree/main/jdat_notebooks/MRS_Mstar_analysis) directly from the [JDAT Notebook Github directory](https://github.com/spacetelescope/jdat_notebooks).<br>\n",
    "\n",
    "### Introduction: Spectral extraction in the JWST calibration pipeline\n",
    "\n",
    "The JWST calibration pipeline performs spectrac extraction for all spectroscopic data using basic default assumptions that are tuned to produce accurately calibrated spectra for the majority of science cases. This default method is a simple fixed-width boxcar extraction, where the spectrum is summed over a number of pixels along the cross-dispersion axis, over the valid wavelength range. An aperture correction is applied at each pixel along the spectrum to account for flux lost from the finite-width aperture. \n",
    "\n",
    "The ``extract_1d`` step uses the following inputs for its algorithm:\n",
    "- the spectral extraction reference file: this is a json-formatted file, available as a reference file from the [JWST CRDS system](https://jwst-crds.stsci.edu)\n",
    "- the bounding box: the ``assign_wcs`` step attaches a bounding box definition to the data, which defines the region over which a valid calibration is available. We will demonstrate below how to visualize this region. \n",
    "\n",
    "However the ``extract_1d`` step has the capability to perform more complex spectral extractions, requiring some manual editing of parameters and re-running of the pipeline step. \n",
    "\n",
    "\n",
    "### Aims\n",
    "\n",
    "This notebook will demonstrate how to re-run the spectral extraction step with different settings to illustrate the capabilities of the JWST calibration pipeline. \n",
    "\n",
    "\n",
    "### Assumptions\n",
    "\n",
    "We will demonstrate the spectral extraction methods on resampled, calibrated spectral images. The basic demo and two examples run on Level 3 data, in which the nod exposures have been combined into a single spectral image. Two examples will use the Level 2b data - one of the nodded exposures. \n",
    "\n",
    "\n",
    "### Test data\n",
    "\n",
    "The data used in this notebook is an observation of the Type Ia supernova SN2021aefx, observed by Jha et al in PID 2072 (Obs 1). These data were taken with zero exclusive access period, and published in [Kwok et al 2023](https://ui.adsabs.harvard.edu/abs/2023ApJ...944L...3K/abstract). You can retrieve the data from [this Box folder](https://stsci.box.com/s/i2xi18jziu1iawpkom0z2r94kvf9n9kb), and we recommend you place the files in the ``data/`` folder of this repository, or change the directory settings in the notebook prior to running. \n",
    "\n",
    "You can of course use your own data instead of the demo data. \n",
    "\n",
    "\n",
    "### JWST pipeline version and CRDS context\n",
    "\n",
    "This notebook was written using the calibration pipeline version 1.10.2. We set the CRDS context explicitly to 1089 to match the current latest version in MAST. If you use different pipeline versions or CRDS context, please read the relevant release notes ([here for pipeline](https://github.com/spacetelescope/jwst), [here for CRDS](https://jwst-crds.stsci.edu)) for possibly relevant changes.\n",
    "\n",
    "### Contents\n",
    "\n",
    "1. [The Level 3 data products](#l3data)\n",
    "2. [The spectral extraction reference file](#x1dref)\n",
    "3. [Example 1: Changing the aperture width](#ex1)\n",
    "4. [Example 2: Changing the aperture location](#ex2)\n",
    "5. [Example 3: Extraction with background subtraction](#ex3)\n",
    "6. [Example 4: Tapered column extraction](#ex4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58c7be6",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8c9d77",
   "metadata": {},
   "source": [
    "- `astropy.io` fits for accessing FITS files\n",
    "- `os` for managing system paths\n",
    "- `matplotlib` for plotting data\n",
    "- `urllib` for downloading data\n",
    "- `tarfile` for unpacking data\n",
    "- `numpy` for basic array manipulation\n",
    "- `jwst` for running JWST pipeline and handling data products\n",
    "- `json` for working with json files\n",
    "- `crds` for working with JWST reference files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1f42bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set CRDS variables first\n",
    "import os\n",
    "\n",
    "os.environ['CRDS_CONTEXT'] = 'jwst_1089.pmap'\n",
    "os.environ['CRDS_PATH'] = os.environ['HOME']+'/crds_cache'\n",
    "os.environ['CRDS_SERVER_URL'] = 'https://jwst-crds.stsci.edu'\n",
    "print(f'CRDS cache location: {os.environ[\"CRDS_PATH\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21efc012",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys,os, pdb\n",
    "# Basic system utilities for interacting with files\n",
    "import glob\n",
    "import time\n",
    "import shutil\n",
    "import warnings\n",
    "import zipfile\n",
    "import urllib.request\n",
    "import requests\n",
    "\n",
    "# Astropy utilities for opening FITS and ASCII files\n",
    "from astropy.io import fits\n",
    "from astropy.io import ascii\n",
    "from astropy.utils.data import download_file\n",
    "from regions import Regions\n",
    "from astropy import units as u\n",
    "\n",
    "from astroquery.mast import Observations\n",
    "\n",
    "# Astropy utilities for making plots\n",
    "from astropy.visualization import (LinearStretch, LogStretch, ImageNormalize, ZScaleInterval)\n",
    "\n",
    "# Numpy for doing calculations\n",
    "import numpy as np\n",
    "\n",
    "# Matplotlib for making plots\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "\n",
    "# Import the base JWST package\n",
    "import jwst\n",
    "\n",
    "# JWST pipelines (encompassing many steps)\n",
    "from jwst.pipeline import Detector1Pipeline\n",
    "from jwst.pipeline import Spec2Pipeline\n",
    "from jwst.pipeline import Spec3Pipeline\n",
    "\n",
    "# JWST pipeline utilities\n",
    "from jwst import datamodels # JWST datamodels\n",
    "from jwst.associations import asn_from_list as afl # Tools for creating association files\n",
    "from jwst.associations.lib.rules_level2_base import DMSLevel2bBase # Definition of a Lvl2 association file\n",
    "from jwst.associations.lib.rules_level3_base import DMS_Level3_Base # Definition of a Lvl3 association file\n",
    "from jwst.datamodels import SpecModel, MultiSpecModel, IFUCubeModel\n",
    "\n",
    "\n",
    "from stcal import dqflags # Utilities for working with the data quality (DQ) arrays\n",
    "\n",
    "import shutil\n",
    "\n",
    "# Import packages for multiprocessing.  These won't be used on the online demo, but can be\n",
    "# very useful for local data processing unless/until they get integrated natively into\n",
    "# the cube building code.  These need to be imported before anything else.\n",
    "\n",
    "import multiprocessing\n",
    "#multiprocessing.set_start_method('fork')\n",
    "from multiprocessing import Pool\n",
    "import os\n",
    "\n",
    "# Set the maximum number of processes to spawn based on available cores\n",
    "usage = 'all' # Either 'none' (single thread), 'quarter', 'half', or 'all' available cores\n",
    "\n",
    "from specutils import Spectrum1D\n",
    "from matplotlib.pyplot import cm\n",
    "\n",
    "from jdaviz import Cubeviz\n",
    "\n",
    "# Display the video\n",
    "from IPython.display import HTML, YouTubeVideo\n",
    "\n",
    "#shutil.copytree('/astro/armin/data/mshahbandeh/aefx/input_dir/', '/astro/armin/data/mshahbandeh/aefx/input_dir_sc/')\n",
    "#shutil.copytree('/astro/armin/data/mshahbandeh/aefx/input_dir/', '/astro/armin/data/mshahbandeh/aefx/input_dir_bkg/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37350f4d-4dbc-445d-b743-f26e7898e73e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set parameters to be changed here.\n",
    "# It should not be necessary to edit cells below this in general unless modifying pipeline processing steps.\n",
    "\n",
    "import sys,os, pdb\n",
    "\n",
    "# CRDS context (if overriding)\n",
    "#%env CRDS_CONTEXT jwst_0771.pmap\n",
    "\n",
    "# Point to where the uncalibrated FITS files are from the science observation\n",
    "input_dir = './mastDownload/1232/uncal/'\n",
    "\n",
    "# Point to where you want the output science results to go\n",
    "output_dir = './output/87A/'\n",
    "\n",
    "# Point to where the uncalibrated FITS files are from the background observation\n",
    "# If no background observation, leave this blank\n",
    "input_bgdir = ' '\n",
    "\n",
    "# Point to where the output background observations should go\n",
    "# If no background observation, leave this blank\n",
    "output_bgdir = ' '\n",
    "\n",
    "# Whether or not to run a given pipeline stage\n",
    "# Science and background are processed independently through det1+spec2, and jointly in spec3\n",
    "\n",
    "# Science processing\n",
    "dodet1=True\n",
    "dospec2=True\n",
    "dospec3=True\n",
    "\n",
    "# Background processing\n",
    "dodet1bg=True\n",
    "dospec2bg=True\n",
    "\n",
    "# If there is no background folder, ensure we don't try to process it\n",
    "if (input_bgdir == ''):\n",
    "    dodet1bg=False\n",
    "    dospec2bg=False"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a1c5254b-6e38-4b43-82c5-44fa67a4f4b0",
   "metadata": {},
   "source": [
    "## Point to where the uncalibrated FITS files are from the science observation\n",
    "input_dir = '/Users/ofox/data/1860/mast/01860/obsnum03/'\n",
    "#\n",
    "## Point to where you want the output science results to go\n",
    "output_dir = '/Users/ofox/data/1860/output/05ip_3/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c10e734",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Output subdirectories to keep science data products organized\n",
    "## Note that the pipeline might complain about this as it is intended to work with everything in a single\n",
    "## directory, but it nonetheless works fine for the examples given here.\n",
    "det1_dir = os.path.join(output_dir, 'stage1/') # Detector1 pipeline outputs will go here\n",
    "#spec2_dir = os.path.join(output_dir, 'stage2/') # Spec2 pipeline outputs will go here\n",
    "spec2_dir = os.path.join(output_dir, 'stage2/') # Spec2 pipeline outputs will go here\n",
    "spec2_bgdir = ' '\n",
    "#spec3_dir = os.path.join(output_dir, 'stage3/') # Spec3 pipeline outputs will go here\n",
    "spec3_dir = os.path.join(output_dir, 'stage3/') # Spec3 pipeline outputs will go here\n",
    "\n",
    "# We need to check that the desired output directories exist, and if not create them\n",
    "if not os.path.exists(det1_dir):\n",
    "    os.makedirs(det1_dir)\n",
    "if not os.path.exists(spec2_dir):\n",
    "    os.makedirs(spec2_dir)\n",
    "if not os.path.exists(spec3_dir):\n",
    "    os.makedirs(spec3_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5341f5-08f7-409b-a764-c3afc160faa2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Output subdirectories to keep background data products organized\n",
    "det1_bgdir = os.path.join(output_bgdir, 'stage1/') # Detector1 pipeline outputs will go here\n",
    "spec2_bgdir = os.path.join(output_bgdir, 'stage2/') # Spec2 pipeline outputs will go here\n",
    "\n",
    "# We need to check that the desired output directories exist, and if not create them\n",
    "if (output_bgdir != ''):\n",
    "    if not os.path.exists(det1_bgdir):\n",
    "        os.makedirs(det1_bgdir)\n",
    "    if not os.path.exists(spec2_bgdir):\n",
    "        os.makedirs(spec2_bgdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86205cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkKey(dict, key):\n",
    "      \n",
    "    if key in dict.keys():\n",
    "        print(\"Present, \", end=\" \")\n",
    "        print(\"value =\", dict[key])\n",
    "        return(True)\n",
    "    else:\n",
    "        print(\"Not present\")\n",
    "        return(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7def969a",
   "metadata": {},
   "source": [
    "# 2. Use Cubeviz to make mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4eef1a",
   "metadata": {},
   "source": [
    "#### This step show how to interactively define a region to be used for extracting a background. If you skip this step, you can continue to run the notebook further in Step 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7aa348f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Video showing how to define an annulus background around SN 1987A using the cells below\n",
    "\n",
    "HTML('<iframe width=\"700\" height=\"500\" src=\"https://data.science.stsci.edu/redirect/JWST/jwst-data_analysis_tools/MRS_1987A/region_mask1.mov\" frameborder=\"0\" allowfullscreen></iframe>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89d0586",
   "metadata": {},
   "outputs": [],
   "source": [
    "cubefile = \"/astro/armin/data/ofox/1232/output/87A/stage3/Level3_ch1-2-3-4-shortmediumlong_s3d.fits\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7224f0b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from jdaviz import Cubeviz\n",
    "cubeviz = Cubeviz()\n",
    "cubeviz.load_data(cubefile, data_label='SN1987A')\n",
    "cubeviz.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9dc7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the collapsed cube, ideally from Cubeviz, but otherwise download from pre-defined files.\n",
    "\n",
    "collapse_cube = cubeviz.app.get_data_from_viewer(\"uncert-viewer\") # AGN Center Model Cube\n",
    "if checkKey(collapse_cube,\"collapsed\") is True:\n",
    "    collapse_cube = cubeviz.app.get_data_from_viewer(\"uncert-viewer\",\"collapsed\") # AGN Center Model Cube\n",
    "    collapse_cube.write(spec3_dir+\"collapsed_cube.fits\",overwrite='True')\n",
    "else:\n",
    "    print(\"No Collapsed Cube in Cubeviz.\")\n",
    "    if os.path.isfile(spec3_dir+'/'+\"collapsed_cube.fits\"):\n",
    "        print('File exists. Deleting '+spec3_dir+'/'+\"collapsed_cube.fits\")\n",
    "        os.remove(spec3_dir+'/'+\"collapsed_cube.fits\")\n",
    "    print(\"Downloading to \"+spec3_dir)\n",
    "    url = 'https://data.science.stsci.edu/redirect/JWST/jwst-data_analysis_tools/MRS_1987A/collapsed_cube.fits'\n",
    "    urllib.request.urlretrieve(url, './collapsed_cube.fits')\n",
    "    shutil.move(\"collapsed_cube.fits\",spec3_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b145607c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the ellipse region, ideally from Cubeviz, but otherwise download from pre-defined files.\n",
    "\n",
    "regions = cubeviz.get_interactive_regions()\n",
    "if checkKey(regions,\"Subset 1\") is True:\n",
    "    regions['Subset 1'].write('my_elipse.reg', overwrite=True)\n",
    "else:\n",
    "    print(\"No Background Region From Cubeviz.\")\n",
    "    if os.path.isfile(\"./my_elipse.reg\"):\n",
    "        print('File exists. Deleting ./my_elipse.reg')\n",
    "        os.remove(\"./my_elipse.reg\")\n",
    "    print(\"Downloading...\")\n",
    "    fname = \"./my_elipse.reg\"\n",
    "    url = 'https://data.science.stsci.edu/redirect/JWST/jwst-data_analysis_tools/MRS_1987A/my_elipse.txt'\n",
    "    urllib.request.urlretrieve(url, fname)\n",
    "    #fn = x = download_file(url, cache=False)\n",
    "    #reg = Regions.read(fn, format='ds9')[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24590618",
   "metadata": {},
   "source": [
    "# 3. Apply the mask to the weights extension of the data cube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabb87c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data cube as a JWST data model\n",
    "spec_model_cube = IFUCubeModel()\n",
    "spec_model_cube.read(cubefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7334184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the source and aperture type being used in the header of the file (this can be Extended or Point). \n",
    "# For SN 1987A, we have an EXTENDED source\n",
    "\n",
    "spec_model_cube.find_fits_keyword('SRCTYPE')\n",
    "spec_model_cube.find_fits_keyword('SRCTYAPT')\n",
    "\n",
    "print(spec_model_cube.meta.target.source_type)\n",
    "print(spec_model_cube.meta.target.source_type_apt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730eb1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If necessary, you can change your cube header as necessary. We don't need to change anything in this case.\n",
    "# But you might want to if you have a point source, yet want to extract a user specified background spectrum.\n",
    "# The pipeline extracts EXTENDED and POINT sources differently.\n",
    "\n",
    "spec_model_cube.meta.target.source_type = 'EXTENDED'\n",
    "spec_model_cube.meta.target.source_type_apt = 'EXTENDED'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21adcb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in previously extracted region\n",
    "\n",
    "reg = Regions.read('./my_elipse.reg', format='ds9')[0]\n",
    "print(reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce2d007",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a weight map using the region mask\n",
    "\n",
    "tmp_wgts = spec_model_cube.weightmap[:]\n",
    "mask = reg.to_mask('exact')\n",
    "x1 = int(reg.center.x-reg.width/2.)\n",
    "x2 = x1+mask.shape[1]\n",
    "y1 = int(reg.center.y-reg.height/2.)\n",
    "y2 = y1+mask.shape[0]\n",
    "\n",
    "### Note above, the region shape is slightly different than the mask shape that gets generated. \n",
    "### This hack gets all the arrays to be the same size.\n",
    "\n",
    "# Start by setting all pixels to 1.\n",
    "mask2d = tmp_wgts[13,:,:]\n",
    "mask2d[mask2d>0] = 1.\n",
    "\n",
    "# Because we want an inverse array, we can't just use the mask, we have to subtract the mask (which is 1's) from the original mask2d above (make sense?) \n",
    "mask2d[y1:y2,x1:x2] = mask2d[y1:y2,x1:x2]-mask\n",
    "\n",
    "# Take into account weird rounding errors\n",
    "mask2d[mask2d<0.1] = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51239ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the 2D Mask\n",
    "\n",
    "from astropy.nddata import CCDData\n",
    "from astropy.visualization import simple_norm\n",
    "ccd = mask2d\n",
    "norm = simple_norm(ccd, 'sqrt', min_cut=0, max_cut=0.5)   \n",
    "color = 'rgbmkrgbmk'\n",
    "\n",
    "xceni = [36, 44]\n",
    "yceni = [66, 58]\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot()\n",
    "counter = 0\n",
    "plt.title(\"Masked Data\")\n",
    "plt.imshow(ccd, norm=norm, origin=\"lower\")     \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d800d33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 3D weightmap from the 2D map. Mask all NAN values, too.\n",
    "\n",
    "mask3d = np.broadcast_to(mask2d, spec_model_cube.weightmap.shape)\n",
    "mask3d.flags.writeable = True\n",
    "mask3d[np.isnan(spec_model_cube.data)] = 0\n",
    "#mask_sci_cube = np.ma.masked_array(spec_model_cube.weightmap, mask=mask3d.astype(bool))\n",
    "tmp_wgt_cube = np.swapaxes(mask3d,0,1)\n",
    "tmp_wgt_cube = np.swapaxes(tmp_wgt_cube,1,2)\n",
    "plotcube = Spectrum1D(tmp_wgt_cube*u.dimensionless_unscaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b9a1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the 3D Cube in Cubeviz\n",
    "\n",
    "cubeviz2 = Cubeviz()\n",
    "cubeviz2.load_data(plotcube, data_label='SN1987A MASK')\n",
    "cubeviz2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03177ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the weightmap in the original cube as the new 3D Mask \n",
    "# This will tell the pipeline which spaxels to use for extraction\n",
    "\n",
    "spec_model_cube.weightmap = mask3d\n",
    "spec_model_cube.save(spec3_dir+'87A_skycube.fits',overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b381d59",
   "metadata": {},
   "source": [
    "# 4. Extract Background Spectrum using Extract1dStep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17914f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set 1D extraction parameters\n",
    "\n",
    "def runex(filename, outdir, outputfile):\n",
    "    ex1d = jwst.extract_1d.Extract1dStep()\n",
    "    ex1d.output_dir = outdir\n",
    "    ex1d.save_results = True\n",
    "    ex1d.subtract_background = False\n",
    "    ex1d.output_file = outputfile\n",
    "    ex1d(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c46fc4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# We will extract a 1D spectrum from the cube created above with a weightmap defined by the region mask\n",
    "# This extraction will create an average of all the spaxels in each frame that are not masked\n",
    "# We will use this to be our master background to subtract from the entire cube\n",
    "\n",
    "cubefile_p1  = spec3_dir+'87A_skycube.fits'\n",
    "outputfile = spec3_dir+'87A_bg'\n",
    "runex(cubefile_p1,spec3_dir,outputfile=outputfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f50b83",
   "metadata": {},
   "source": [
    "### A single background spectrum is necessary in this workflow. But in some workflows, you may wish to work with more than one background region. This is further illustrated in Notebook 3 of this series on SN 1987A."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36656ad",
   "metadata": {},
   "source": [
    "# 4. Rerun Stage 3 With Master Background Turned On"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c7b505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that will call the spec3 pipeline with our desired set of parameters\n",
    "# This is designed to run on an association file\n",
    "def runspec3(filename):\n",
    "    \n",
    "    crds_config = Spec3Pipeline.get_config_from_reference(filename)\n",
    "    spec3 = Spec3Pipeline.from_config_section(crds_config)\n",
    "    spec3.output_dir = spec3_dir\n",
    "    spec3.save_results = True\n",
    "    spec3.cube_build.output_file = '87A_bg_sub' # Custom output name\n",
    "    spec3.cube_build.output_type = 'multi' # 'band', 'channel', or 'multi' type cube output\n",
    "    spec3.outlier_detection.threshold_percent = 98.5 # optimized threshold number\n",
    "    spec3.master_background.user_background=spec3_dir+'87A_bg_extract1dstep.fits' # Master Background Extracted Above\n",
    "    spec3.master_background.force_subtract=True\n",
    "    \n",
    "    spec3(filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f450bfca",
   "metadata": {},
   "source": [
    "### Developer Note: Right now, this association file can only be created manually. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc38c7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the association file used for the background subtraction.\n",
    "# Download the background subtract json file.\n",
    "\n",
    "asnfile_bg_sub = 'spec2_l3asn_bg_sub.json'\n",
    "if os.path.isfile(asnfile_bg_sub):\n",
    "    print('File exists. Deleting '+asnfile_bg_sub)\n",
    "    os.remove(asnfile_bg_sub)\n",
    "print(\"Downloading \"+asnfile_bg_sub)\n",
    "url = 'https://data.science.stsci.edu/redirect/JWST/jwst-data_analysis_tools/MRS_1987A/spec2_l3asn_bg_sub.json'\n",
    "urllib.request.urlretrieve(url, asnfile_bg_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5d3a36",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "spec3 = 1.\n",
    "if dospec3:\n",
    "    runspec3(asnfile_bg_sub)\n",
    "else:\n",
    "    print('Skipping Spec3 processing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad227282",
   "metadata": {},
   "outputs": [],
   "source": [
    "datacube = spec3_dir+'87A_bg_sub_ch1-2-3-4-shortmediumlong_s3d.fits'\n",
    "datacube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad317338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Background Subtracted Cube\n",
    "# Note, this is not a perfect subtraction. As we will see in the next notebook, we oversubtract the background.\n",
    "# This is likely caused by poorly chose spaxels. A more careful selection of background regions should result in a flatter background post-subtraction.\n",
    "\n",
    "cubeviz3 = Cubeviz()\n",
    "cubeviz3.load_data(datacube, data_label='SN1987A MASK')\n",
    "cubeviz3.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
