{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-cell"
    ]
   },
   "source": [
    "# NIRSpec IFU Optimal Point Source Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook illustrates various extraction methods for a point source in JWST NIRSpec IFU data, utilizing the [Q3D](https://q3d.github.io/) (PID 1335) observation of quasar SDSS J165202.64+172852.3. The extraction techniques include subset extraction with Cubeviz, simple sum over spaxels, cylindrical aperture, conical aperture photometry, and optimal point source extraction using a WebbPSF model PSF. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use case:** optimal spectral extraction; method by [Horne (1986)](https://ui.adsabs.harvard.edu/abs/1986PASP...98..609H/abstract).\n",
    "\n",
    "**Data:** JWST NIRSpec IFU data; point sources.\n",
    "\n",
    "**Tools:**  jwst, webbpsf, matplotlib, scipy, custom functions.\n",
    "\n",
    "**Cross-intrument:** any spectrograph. \n",
    "\n",
    "**Documentation:** This notebook is part of a STScI's larger [post-pipeline Data Analysis Tools Ecosystem](https://jwst-docs.stsci.edu/jwst-post-pipeline-data-analysis)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "1. [Imports](#imports)\n",
    "2. [Read in NIRSpec IFU Cube](#read)\n",
    "3. [Visualize Science Data with Cubeviz](#visualize)\n",
    "4. [Export Source and Good Data Regions from Cubeviz](#source)\n",
    "5. [Extract Subset Spectrum and Background from Cubeviz Spectrum Viewer](#viewer)\n",
    "6. [Extract Spectrum by Sum over Spaxels](#sum)\n",
    "7. [Extract Spectrum in Constant Radius Circular Aperture (Cylinder)](#cylinder)\n",
    "8. [Extract Spectrum in Linearly Expanding Circular Aperture (Cone)](#cone)\n",
    "9. [Plot and Compare Non-optimal Spectral Extractions](#plot)\n",
    "10. [WebbPSF Model for Optimal Extraction](#webbpsf)\n",
    "11. [Align Model PSF Cube with Science Data](#align)\n",
    "12. [Optimal Extraction Using WebbPSF Model](#optimal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports <a id=\"imports\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* _numpy_ for array math\n",
    "* _scipy_ for ndimage shift\n",
    "* _specutils_ for Spectrum1D data model\n",
    "* _jdaviz_ : for data visualization\n",
    "* _photutils_ to define circular apertures\n",
    "* _astropy.io_ for reading and writing FITS cubes and images\n",
    "* _astropy.wcs, units, coordinates_ for defining and reading WCS\n",
    "* _astropy.stats_ for sigma_clipping\n",
    "* _astropy.utils_ for downloading files from URLs\n",
    "* _matplotlib_ for plotting spectra and images\n",
    "* _os_ for file management\n",
    "* _astroquery.mast_ to download the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "from specutils import Spectrum1D\n",
    "import jdaviz\n",
    "from jdaviz import Cubeviz, Specviz\n",
    "print(\"jdaviz Version={}\".format(jdaviz.__version__))\n",
    "from photutils.aperture import CircularAperture, aperture_photometry \n",
    "from astropy.io import fits\n",
    "from astropy import wcs\n",
    "from astropy import units as u\n",
    "import os\n",
    "from astroquery.mast import Observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Read in NIRSpec IFU Cube <a id=\"read\"/>\n",
    "\n",
    "The NIRSpec IFU observation of quasar SDSS J1652+1728 (redshift z=1.9) was taken using the G235H grating with F170LP filter, covering 1.66-3.17 microns at a spectral resolution of R~2700. The IFU spaxels are 0.1\" on a side. \n",
    "The level-3 pipeline_processed datacube (s3d.fits, which combines all dithered exposures) is retrieved from MAST \n",
    "in the next notebook cell  below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the data file\n",
    "uri = \"mast:jwst/product/jw01335-o008_t007_nirspec_g235h-f170lp_s3d.fits\"\n",
    "result = Observations.download_file(\n",
    "    uri, base_url=\"https://mast.stsci.edu/api/v0.1/Download/file\"\n",
    ")\n",
    "if result[0] == \"ERROR\":\n",
    "    raise RuntimeError(\"Error retrieving file: \" + result[1])\n",
    "\n",
    "# Construct the local filepath\n",
    "filename = os.path.join(os.path.abspath(\".\"), uri.rsplit(\"/\", 1)[-1])\n",
    "\n",
    "# Optionally Replace MAST data with custom reprocessed data in the current directory\n",
    "# filename=\"./jw01335-o008_t007_nirspec_g235h-f170lp_s3d.fits\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open and inspect the file and WCS\n",
    "with fits.open(filename, memmap=False) as hdulist:\n",
    "    sci = hdulist[\"SCI\"].data\n",
    "    err = hdulist[\"ERR\"].data\n",
    "    w = wcs.WCS(hdulist[1].header)\n",
    "    hdr = hdulist[1].header\n",
    "    print(w)\n",
    "\n",
    "# Window the wavelength range to focus on Hbeta-[OIII]\n",
    "spec1d = Spectrum1D.read(filename)\n",
    "slice_range = range(500, 1100, 1)\n",
    "wavelength = np.array(spec1d.spectral_axis.value)[slice_range[0]: slice_range[-1] + 1]\n",
    "\n",
    "# List of cube slices for aperture photometry\n",
    "sci_data = []\n",
    "sci_var = []\n",
    "for idx in slice_range:\n",
    "    sci_data.append(sci[idx, :, :])\n",
    "    sci_var.append(err[idx, :, :])\n",
    "\n",
    "data = np.nan_to_num(np.array(sci_data))\n",
    "var = np.array(sci_var)\n",
    "print(\"\\nTrimmed data shape:\", data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cubeviz = Cubeviz()\n",
    "cubeviz.load_data(filename)\n",
    "cubeviz.show()\n",
    "\n",
    "# Set spectrum display limits\n",
    "cubeviz.specviz.x_limits(1.65 * u.um, 2.4 * u.um)\n",
    "cubeviz.specviz.y_limits(0.0, 5.0e3)\n",
    "\n",
    "# Select slice to visualize\n",
    "cubeviz.select_slice(714)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualize Science Data with Cubeviz <a id=\"visualize\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"sdssj1652_nirspec_ifu_cubeviz.png\" alt=\"Cubeviz, an astronomy data analysis viewer, showing two image panels with a central bright object and a spectral graph panel displaying numerous peaks across various wavelengths\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UI Instructions:\n",
    "* Scrub through the cube to a line-free region using the spectrum-viewer slice tool.\n",
    "* In the flux-viewer, select one circular subset region centered on the quasar, and a square region to delimit the good area for spectral and background extraction\n",
    "* Note that the regions are pixelated and don't include fractional pixels\n",
    "* The default collapse method is \"Sum\" in the spectrum viewer (see Plot Options:Line). \"Median\" may also be useful for visualization but will not give an accurate measurement of the total flux.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Export Source and Good Data Regions from Cubeviz <a id=\"source\"/>\n",
    "Export the region defined by the user in Cubeviz as astropy PixelRegions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    print(\"\\nSource Region\")\n",
    "    region1 = cubeviz.get_interactive_regions()['Subset 1']\n",
    "    print(region1)\n",
    "    center_xy = [region1.center.x, region1.center.y]\n",
    "    r_pix = region1.radius\n",
    "    region1_exists = True\n",
    "except Exception:\n",
    "    print(\"There is no Subset 1 selected in the cube viewer.\")\n",
    "    center_xy = [17.1, 20.0]\n",
    "    r_pix = 5.92\n",
    "    print(\"Using default pixel center and radius:\")\n",
    "    print(\"Center pixel:\", center_xy)\n",
    "    print(\"Radius (pixels):\", r_pix)\n",
    "    region1_exists = False\n",
    "    \n",
    "print(\"\\nGood Data Region\")\n",
    "try:\n",
    "    region2 = cubeviz_data.get_selection_definition(\n",
    "        \"Subset 2\", format=\"astropy-regions\"\n",
    "    )\n",
    "    print(region2)\n",
    "    region2_exists = True\n",
    "    data_xrange = [\n",
    "        round(region2.center.x - region2.width / 2),\n",
    "        round(region2.center.x + region2.width / 2),\n",
    "    ]\n",
    "    data_yrange = [\n",
    "        round(region2.center.y - region2.height / 2),\n",
    "        round(region2.center.y + region2.height / 2),\n",
    "    ]\n",
    "    print(\"Good data (xmin,xmax), (ymin,ymax):\", data_xrange, data_yrange)\n",
    "    good_data = np.nan_to_num(\n",
    "        data[:, data_yrange[0]: data_yrange[1], data_xrange[0]: data_xrange[1]]\n",
    "    )\n",
    "    good_var = var[:, data_yrange[0]: data_yrange[1], data_xrange[0]: data_xrange[1]]\n",
    "\n",
    "except Exception:\n",
    "    print(\"There is no Subset 2 selected in the cube viewer.\")\n",
    "    region1_exists = False\n",
    "    data_xrange = [7, 36]\n",
    "    data_yrange = [6, 33]\n",
    "    good_data = np.nan_to_num(\n",
    "        data[:, data_yrange[0]: data_yrange[1], data_xrange[0]: data_xrange[1]]\n",
    "    )\n",
    "    good_var = var[:, data_yrange[0]: data_yrange[1], data_xrange[0]: data_xrange[1]]\n",
    "    print(\"Using default good data (xmin,xmax), (ymin,ymax):\", data_xrange, data_yrange)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Extract Subset Spectrum and Background from Cubeviz Spectrum Viewer <a id=\"viewer\"/>\n",
    "Retrieve the collapsed spectrum (Subset1) of the user-defined region from the Spectrum Viewer as a Spectrum1D object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsets = cubeviz.specviz.get_spectra()\n",
    "print(subsets.keys())\n",
    "\n",
    "print(\"\\nSource\")\n",
    "try:\n",
    "    spectrum_subset1 = cubeviz.get_data(cubeviz.data_labels[0].label,\n",
    "                                        spatial_subset=\"Subset 1\", function=\"mean\")\n",
    "    print(spectrum_subset1)\n",
    "except Exception:\n",
    "    print(\"There is no Subset 1 selected in the spectrum viewer.\")\n",
    "\n",
    "print(\"\\nBackground\")\n",
    "try:\n",
    "    spectrum_subset2 = spectrum_subset2 = subsets[\n",
    "        [i for i in subsets.keys() if \"Subset 2\" in i][0]\n",
    "    ]\n",
    "    print(spectrum_subset2)\n",
    "except Exception:\n",
    "    print(\"There is no Subset 2 selected in the spectrum viewer.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-cell"
    ]
   },
   "source": [
    "*Developer Note:* The units of the Cubeviz \"Sum\" collapse method (and all other spectra below) need to be multiplied by the pixel area in sr to yield flux units (MJy) instead of surface brightness units (MJy/sr)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Extract Spectrum by Sum Over Spaxels <a id=\"sum\"/>\n",
    "\n",
    "Perform a simple numpy sum over all spaxels in the cube as a rudimentary extraction method. Also sum over wavelength to collapse the cube."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum over wavelength\n",
    "# Clip data for display purposes\n",
    "clip_level = 4e4\n",
    "data_clipped = np.clip(good_data, 0, clip_level)\n",
    "cube_sum = np.sum(data_clipped, axis=0)\n",
    "\n",
    "# Extraction via sum over spaxels\n",
    "fnu_sum = np.sum(good_data, axis=(1, 2))\n",
    "fnu_sum_clipped = np.clip(fnu_sum, 0, clip_level)\n",
    "flux_spaxsum = np.array(fnu_sum) * u.MJy / u.sr\n",
    "spec1d_spaxsum = Spectrum1D(spectral_axis=wavelength * u.um, flux=flux_spaxsum)\n",
    "\n",
    "# Plots\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "ax1.plot(wavelength, fnu_sum)\n",
    "ax1.set_title(\"Spaxel sums\")\n",
    "ax1.set_xlabel(\"Wavelength (um)\")\n",
    "ax1.set_ylabel(\"Flux (MJy/sr)\")\n",
    "ax1.set_ylim(0, 5e3)\n",
    "ax2.imshow(cube_sum, norm=LogNorm(vmin=100, vmax=clip_level), origin=\"lower\")\n",
    "ax2.set_title(\"Slice sums\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Extract Spectrum in Constant Radius Circular Aperture (Cylinder) <a id=\"cylinder\" />\n",
    "This method is appropriate for an extended source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CircularAperture uses xy pixels\n",
    "aperture = CircularAperture(center_xy, r=r_pix)\n",
    "print(aperture)\n",
    "\n",
    "cylinder_sum = []\n",
    "for slice2d in data:\n",
    "    phot_table = aperture_photometry(slice2d, aperture)\n",
    "    cylinder_sum.append(phot_table[\"aperture_sum\"][0])\n",
    "\n",
    "flux_cylinder = np.array(cylinder_sum) * u.MJy / u.sr\n",
    "spec1d_cylinder = Spectrum1D(spectral_axis=wavelength * u.um, flux=flux_cylinder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-cell"
    ]
   },
   "source": [
    "*Developer Note:*  Is there a way to retrieve the coordinates (RA, Dec) of the Subset1 region, for use in a SkyCircularAperture?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Extract Spectrum in Linearly Expanding Circular Aperture (Cone) <a id = \"cone\" />\n",
    "This method is appropriate for a point source PSF with width proportional to wavelength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference wavelength for expanding aperture\n",
    "lambda0 = wavelength[0]\n",
    "print(\"Reference wavelength:\", lambda0)\n",
    "\n",
    "cone_sum = []\n",
    "idx = -1\n",
    "for (slice2d, wave) in zip(data, wavelength):\n",
    "    idx = idx + 1\n",
    "    r_cone = r_pix * wave / lambda0\n",
    "\n",
    "    aperture_cone = CircularAperture(center_xy, r=r_cone)\n",
    "    phot_table = aperture_photometry(\n",
    "        slice2d, aperture_cone, wcs=w.celestial, method=\"exact\"\n",
    "    )\n",
    "    cone_sum.append(phot_table[\"aperture_sum\"][0])\n",
    "\n",
    "flux_cone = np.array(cone_sum) * u.MJy / u.sr\n",
    "spec1d_cone = Spectrum1D(spectral_axis=wavelength * u.um, flux=flux_cone)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Plot and Compare Non-optimal Spectral Extractions <a id = \"plot\" />\n",
    "Compare spectra extracted in cylinder, cone, Cubeviz subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax1) = plt.subplots(1, 1, figsize=(15, 5))\n",
    "\n",
    "# ax1.plot(wavelength, flux_spaxsum.value, label=\"All spaxels\", c='k')\n",
    "ax1.plot(wavelength, flux_cylinder.value, label=\"Cylinder\", c=\"b\")\n",
    "ax1.plot(wavelength, flux_cone.value, label=\"Cone\", c=\"darkorange\", alpha=0.5)\n",
    "try:\n",
    "    ax1.plot(\n",
    "        wavelength,\n",
    "        spectrum_subset1.flux.value[slice_range[0]: slice_range[-1] + 1],\n",
    "        c=\"r\",\n",
    "        label=\"Subset1\",\n",
    "        alpha=0.4,\n",
    "    )\n",
    "except Exception:\n",
    "    print(\"There is no Cubeviz Subset1 spectrum to plot.\")\n",
    "\n",
    "ax1.set_title(\"Non-optimal spectral extractions\")\n",
    "ax1.set_xlabel(\"Observed Wavelength (microns)\")\n",
    "ax1.set_ylabel(\"Flux Density\")\n",
    "ax1.set_ylim(0, 5.0e3)\n",
    "ax1.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The non-optimal cylindrical, conical, and CubeViz subset spectral extractions are quite similar. \n",
    "The conical extraction captures more flux at long wavelengths.\n",
    "Red-shifted Broad H-beta and narrow [O III] lines  are visible in the quasar spectra. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. WebbPSF  Model PSF for Optimal Extraction <a id=\"webbpsf\" />\n",
    "Generate PSF model cube using WebbPSF for NIRSpec IFU, or read in precomputed PSF model cube."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WebbPSF installation instructions can be found in [ReadTheDocs](https://webbpsf.readthedocs.io/en/latest/).\n",
    "\n",
    "Caution! The WebbPSF model takes about 10 hr to run.  Uncomment the following cell to do so. Otherwise, read in the precomputed WebbPSF model, which covers the full wavelength range of the present NIRSpec G235H dataset. For other filter/grating combinations, uncomment and run the cell below using the wavelengths from the science data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #WebbPSF imports\n",
    "# %pylab inline\n",
    "# import webbpsf\n",
    "#\n",
    "# #WebbPSF commands used to create PSF model cube\n",
    "# ns = webbpsf.NIRSpec()\n",
    "# ns.image_mask = \"IFU\"  # Sets to 3x3 arcsec square mask\n",
    "\n",
    "# wavelengths = wavelength*1.0E-6\n",
    "# psfcube = ns.calc_datacube(wavelengths, fov_pixels=30, oversample=4,  add_distortion=True)\n",
    "# psfcube.writeto(\"Webbpsf_ifucube.fits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "BoxPath = \"https://data.science.stsci.edu/redirect/JWST/jwst-data_analysis_tools/IFU_optimal_extraction/\"\n",
    "psf_filename = BoxPath + \"Webbpsf_ifucube.fits\"\n",
    "\n",
    "# Open WebbPSF data cube\n",
    "with fits.open(psf_filename, memmap=False) as hdulist:\n",
    "    psf_model = hdulist[\"DET_SAMP\"].data\n",
    "    psf_hdr = hdulist[\"DET_SAMP\"].header\n",
    "    hdulist.info()\n",
    "\n",
    "# Pad PSF model cube with zeros to match the present dataset\n",
    "# (Different padding may be needed for your particular dataset)\n",
    "print(sci.shape, psf_model.shape)\n",
    "psf_model_padded = np.pad(psf_model, ((0, 0), (4, 5), (6, 7)), \"constant\")\n",
    "\n",
    "# Sum over wavelength\n",
    "psf_model_sum = np.sum(psf_model_padded[slice_range[0]: slice_range[-1] + 1], axis=0)\n",
    "\n",
    "# Sum over spaxels\n",
    "psf_model_fnusum = np.sum(\n",
    "    psf_model_padded[slice_range[0]: slice_range[-1] + 1], axis=(1, 2)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-cell"
    ]
   },
   "source": [
    "*Developer Note:*  The file Webbpsf_ifucube.fits is large (946.3 MB) and takes some time to load from Box.\n",
    "It might behoove the user to download it to a local directory and retrieve it from there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Align Model PSF Cube with Science Data <a id=\"align\"/>\n",
    "Flip, smooth, and shift the model PSF cube to align with the simulated data. Trim the simulated data.  \n",
    "\n",
    "Important Note 1: this PSF will likely be rotated with respect to your dataset, depending on telescope roll angle.  You can either rotate it to match your data or reprocess your data using the ifualign keyword to align the WCS with the instrumental coordinate frame.\n",
    "\n",
    "Important Note 2: this PSF will likely be shifted with respect to your dataset. It would be beneficial to automatically find the (x,y) offset between the data and simulated PSF peaks.  Currently the shift is determined empirically by eye."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Flip model PSF left-right to match data.\n",
    "psf_model_fliplr = psf_model_padded[:, ::-1, :]\n",
    "\n",
    "# Empirically (chi-by-eye) determined shift\n",
    "shiftx = 1.5  # 2\n",
    "shifty = 1.5  # 1.5\n",
    "\n",
    "# Shift model PSF using linear interpolation\n",
    "psf_model_aligned = scipy.ndimage.shift(\n",
    "    psf_model_fliplr,\n",
    "    (0.0, shiftx, shifty),\n",
    "    order=1,\n",
    "    mode=\"constant\",\n",
    "    cval=0.0,\n",
    "    prefilter=True,\n",
    ")\n",
    "\n",
    "good_psf_model = psf_model_aligned[\n",
    "    slice_range[0]: slice_range[-1] + 1,\n",
    "    data_yrange[0]: data_yrange[1],\n",
    "    data_xrange[0]: data_xrange[1],\n",
    "]\n",
    "\n",
    "# Sum over wavelength\n",
    "psf_model_sum = np.sum(good_psf_model, axis=0)\n",
    "\n",
    "# Scale factor for PSF subtraction\n",
    "psf_sum_max = np.amax(psf_model_sum)\n",
    "scalefactor = np.amax(cube_sum) / psf_sum_max\n",
    "\n",
    "# Plots\n",
    "f, ([ax1, ax2], [ax3, ax4]) = plt.subplots(2, 2, figsize=(10, 10))\n",
    "\n",
    "ax1.set_title(\"PSF slice sum\")\n",
    "ax1.imshow(psf_model_sum, norm=LogNorm(), origin=\"lower\")\n",
    "\n",
    "ax2.set_title(\"Science Data slice sum\")\n",
    "ax2.imshow(cube_sum, norm=LogNorm(), origin=\"lower\")\n",
    "\n",
    "ax3.set_title(\"Data / PSF Ratio\")\n",
    "ax3.imshow(cube_sum / psf_model_sum, norm=LogNorm(vmin=1, vmax=1e6), origin=\"lower\")\n",
    "\n",
    "im4 = ax4.imshow(\n",
    "    np.log10(np.absolute(cube_sum - 0.75 * scalefactor * psf_model_sum)), origin=\"lower\"\n",
    ")\n",
    "plt.colorbar(im4)\n",
    "ax4.set_title(\"log abs(Data - PSF)\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Figure top row_: Comparison of shifted WebbPSF PSF (left) to science data (right).  The NIRSpec IFU PSF is signficantly different from the WebbPSF simulation for the telescope. This is partly due to the IFU optics and perhaps partly due to the cube building algorithm. There is also some real extended emission from the QSO host and surrounding galaies.\n",
    "\n",
    "_Figure bottom row_:  Differences between the model PSF and the observed PSF will result in a sub-optimal extraction, not quite attaining the maximum SNR, but still better than a sum over all spaxels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Optimal Extraction using WebbPSF Model <a id=\"optimal\" />\n",
    "Optimal extraction ([Horne 1986, PASP, 98, 609](https://ui.adsabs.harvard.edu/abs/1986PASP...98..609H/abstract)) weights the flux contributions to a spectrum by their signal-to-noise ratio (SNR). Dividing the simulated data by the model PSF gives an estimate of the total flux density spectrum in each spaxel. A weighted average of these estimates over all spaxels yields the optimally extracted spectrum over the cube. In the faint source limit, where the noise is background-dominated, optimal extraction inside a 3-sigma radius can increase the effective exposure time by a factor of 1.69 (Horne et al. 1986). In the bright source limit, where the noise is dominated by the Poisson statistics of the source, optimal extraction is formally identical to a straight sum over spaxels for a perfect PSF model. \n",
    "\n",
    "We use the precomputed WebbPSF PSF model for optimal extraction here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Window PSF model (and replace NaNs)\n",
    "good_profile = np.nan_to_num(good_psf_model)\n",
    "var_clean = np.nan_to_num(good_var, nan=1e12, posinf=1e12, neginf=1e12)\n",
    "zerovar = np.where(var_clean == 0)\n",
    "var_clean[zerovar] = 1e12\n",
    "var_clean_sum = np.sum(var_clean, axis=(0))\n",
    "snr_clean = np.nan_to_num(good_data / var_clean)\n",
    "\n",
    "# Divide data by PSF model\n",
    "data_norm = np.nan_to_num(good_data / good_profile, posinf=0, neginf=0)\n",
    "data_norm_sum = np.sum(data_norm, axis=0)\n",
    "\n",
    "# Mask out bad data\n",
    "# data_norm_clipped = sigma_clip(data_norm, sigma=3.0, maxiters=5, axis=(1, 2))\n",
    "data_norm_clipped = data_norm\n",
    "data_norm_clipped_sum = np.sum(data_norm_clipped, axis=0)\n",
    "snr_thresh = 1.0\n",
    "badvoxel = np.where((data_norm_clipped == 0) | (snr_clean < snr_thresh))\n",
    "data_clean = 1.0 * good_data\n",
    "data_clean[badvoxel] = 0.0\n",
    "data_clean_sum = np.sum(data_clean, axis=0)\n",
    "\n",
    "# Optimal extraction, using model profile weight and variance cube from the simulated data\n",
    "optimal_weight = np.nan_to_num(\n",
    "    good_profile**2 / var_clean, posinf=0, neginf=0\n",
    ")  # Replace nans and infs with 0\n",
    "optimal_weight_sum = np.sum(optimal_weight, axis=(0))\n",
    "optimal_weight_norm = np.sum(optimal_weight, axis=(1, 2))\n",
    "spectrum_optimal = (\n",
    "    np.sum(good_profile * data_clean / var_clean, axis=(1, 2)) / optimal_weight_norm\n",
    ")\n",
    "\n",
    "# Plots\n",
    "f, (ax1) = plt.subplots(1, 1, figsize=(12, 6))\n",
    "ax1.set_title(\"Optimal Extraction Comparison\")\n",
    "ax1.set_xlabel(\"Observed Wavelength (microns)\")\n",
    "ax1.set_ylabel(\"Flux Density\")\n",
    "ax1.set_ylim(0, 5000)\n",
    "ax1.plot(wavelength, cone_sum, label=\"Conical Extraction\", alpha=0.5)\n",
    "ax1.plot(wavelength, spectrum_optimal, label=\"Optimal\")\n",
    "ax1.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specviz = Specviz()\n",
    "\n",
    "flux_opt = spectrum_optimal * u.MJy / u.sr\n",
    "spec1d_opt = Spectrum1D(spectral_axis=wavelength * u.um, flux=flux_opt)\n",
    "\n",
    "# specviz.load_data(spec1d_spaxsum, data_label=\"collapse spec\")\n",
    "specviz.load_data(spec1d_opt, data_label=\"optimal spec\")\n",
    "specviz.load_data(spec1d_cone, data_label=\"cone spec\")\n",
    "specviz.show()\n",
    "\n",
    "# set spectrum display limits\n",
    "# specviz.x_limits()\n",
    "specviz.y_limits(0.0, clip_level / 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimally extracted spectrum is less noisy than the aperture extraction and incorporates fewer bad pixels and cosmic ray events. The OIII line profile is different because extended emission is downweighted with respect to the unresolved quasar nucleus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: right;\" src=\"https://raw.githubusercontent.com/spacetelescope/notebooks/master/assets/stsci_pri_combo_mark_horizonal_white_bkgd.png\" alt=\"Space Telescope Logo\" width=\"200px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook created by Patrick Ogle and James Davies. Last update: December 2023."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
