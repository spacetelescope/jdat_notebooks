{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PSF Photometry\n",
    "\n",
    "\n",
    "**Use case:** PSF photometry, creating a PSF, derive Color-Magnitude Diagram.<br>\n",
    "**Data:** NIRCam simulated images obtained using [MIRAGE](https://jwst-docs.stsci.edu/jwst-other-tools/mirage-data-simulator) and run through the [JWST pipeline](https://jwst-pipeline.readthedocs.io/en/latest/) of the Large Magellanic Cloud (LMC) Astrometric Calibration Field. Simulations is obtained using a 4-pt subpixel dither for three couples of wide filters: F070W, F115W, and F200W for the SW channel, and F277W, F356W, and F444W for the LW channel. We simulated only 1 NIRCam SW detector (i.e., \"NRCB1\"). For this example, we use Level-2 images (.cal, calibrated but not rectified) for two SW filters (i.e., F115W and F200W) and derive the photometry in each one of them. The images for the other filters are also available and can be used to test the notebook and/or different filters combination.<br>\n",
    "**Tools:**  photutils.<br>\n",
    "**Cross-intrument:** NIRSpec, NIRISS, MIRI.<br>\n",
    "**Documentation:** This notebook is part of a STScI's larger [post-pipeline Data Analysis Tools Ecosystem](https://jwst-docs.stsci.edu/jwst-post-pipeline-data-analysis).<br>\n",
    "\n",
    "\n",
    "PSF Photometry can be obtained using:\n",
    "\n",
    "* single model obtained from WebbPSF\n",
    "* grid of PSF models from WebbPSF\n",
    "* single effective PSF (ePSF)\n",
    "\n",
    "### Work in Progress:\n",
    "\n",
    "* create a grid of ePSF and perform reduction using the ePSF grid\n",
    "* use the ePSF grid to perturbate the WebbPSF model\n",
    "\n",
    "The notebook shows:\n",
    "\n",
    "* how to obtain the PSF model from WebbPSF (or build an ePSF)\n",
    "* how to perform PSF photometry on the image\n",
    "* how to cross-match the catalogs of the different images\n",
    "* how to derive and apply photometric zeropoint\n",
    "\n",
    "Final plots show:\n",
    "\n",
    "* Instrumental Color-Magnitude Diagrams for the 4 images\n",
    "* Instrumental Color-Magnitude Diagrams and errors\n",
    "* Magnitudes Zeropoints \n",
    "* Calibrated Color-Magnitude Diagram (compared with Input Color-Magnitude Diagram)\n",
    "* Comparison between input and output photometry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note on pysynphot**: Data files for pysynphot are distributed separately by Calibration Reference Data System. They are expected to follow a certain directory structure under the root directory, identified by the PYSYN_CDBS environment variable that must be set prior to using this package. In the example below, the root directory is arbitrarily named /my/local/dir/trds/. \\\n",
    "export PYSYN_CDBS=/my/local/dir/trds/ \\\n",
    "See documentation [here](https://pysynphot.readthedocs.io/en/latest/#installation-and-setup) for the configuration and download of the data files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import glob as glob\n",
    "\n",
    "import jwst\n",
    "from jwst.datamodels import ImageModel\n",
    "\n",
    "import tarfile\n",
    "\n",
    "import urllib.request\n",
    "\n",
    "from astropy import wcs\n",
    "from astropy import units as u\n",
    "from astropy.io import fits\n",
    "from astropy.visualization import (ZScaleInterval, SqrtStretch, ImageNormalize)\n",
    "from astropy.visualization import simple_norm\n",
    "from astropy.nddata import Cutout2D, NDData\n",
    "from astropy.stats import gaussian_sigma_to_fwhm\n",
    "from astropy.table import Table, QTable\n",
    "from astropy.modeling.fitting import LevMarLSQFitter\n",
    "from astropy.wcs.utils import pixel_to_skycoord\n",
    "from astropy.coordinates import SkyCoord, match_coordinates_sky\n",
    "from astropy.stats import sigma_clipped_stats\n",
    "\n",
    "from photutils import CircularAperture, EPSFBuilder, find_peaks, CircularAnnulus\n",
    "from photutils.detection import DAOStarFinder, IRAFStarFinder\n",
    "from photutils.psf import DAOGroup, IntegratedGaussianPRF, extract_stars, IterativelySubtractedPSFPhotometry\n",
    "from photutils.background import MMMBackground, MADStdBackgroundRMS\n",
    "from photutils.centroids import centroid_2dg\n",
    "from photutils import aperture_photometry\n",
    "\n",
    "from ipywidgets import interact\n",
    "\n",
    "import webbpsf\n",
    "from webbpsf.utils import to_griddedpsfmodel\n",
    "\n",
    "import pysynphot  # PYSIN_CDBS must be defined in the user's environment (see note above)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Plotting Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import style, pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "plt.rcParams['image.cmap'] = 'viridis'\n",
    "plt.rcParams['image.origin'] = 'lower'\n",
    "plt.rcParams['axes.titlesize'] = plt.rcParams['axes.labelsize'] = 30\n",
    "plt.rcParams['xtick.labelsize'] = plt.rcParams['ytick.labelsize'] = 30\n",
    "\n",
    "font1 = {'family': 'helvetica', 'color': 'black', 'weight': 'normal', 'size': '12'}\n",
    "font2 = {'family': 'helvetica', 'color': 'black', 'weight': 'normal', 'size': '20'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Load the images and create some useful dictionaries\n",
    "\n",
    "We load all the images and we create a dictionary that contains all of them, divided by detectors and filters. This is useful to check which detectors and filters are available and to decide if we want to perform the photometry on all of them or only on a subset (for example, only on the SW filters). \n",
    "\n",
    "We also create a dictionary with some useful parameters for the analysis. The dictionary contains the photometric zeropoints (from [MIRAGE](https://jwst-docs.stsci.edu/jwst-other-tools/mirage-data-simulator) configuration files) and the NIRCam point spread function (PSF) FWHM, from the [NIRCam Point Spread Function](https://jwst-docs.stsci.edu/near-infrared-camera/nircam-predicted-performance/nircam-point-spread-functions) JDox page. The FWHM are calculated from the analysis of the expected NIRCam PSFs simulated with [WebbPSF](https://www.stsci.edu/jwst/science-planning/proposal-planning-toolbox/psf-simulation-tool). \n",
    "\n",
    "**Note**: this dictionary will be updated once the values for zeropoints and FWHM will be available for each detectors after commissioning. \n",
    "\n",
    "Hence, we have two dictionaries:\n",
    "\n",
    "* dictionary for the single Level-2 calibrated images\n",
    "* dictionary with some other useful parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_images = {'NRCA1': {}, 'NRCA2': {}, 'NRCA3': {}, 'NRCA4': {}, 'NRCA5': {},\n",
    "               'NRCB1': {}, 'NRCB2': {}, 'NRCB3': {}, 'NRCB4': {}, 'NRCB5': {}}\n",
    "\n",
    "dict_filter_short = {}\n",
    "dict_filter_long = {}\n",
    "\n",
    "ff_short = []\n",
    "det_short = []\n",
    "det_long = []\n",
    "ff_long = []\n",
    "detlist_short = []\n",
    "detlist_long = []\n",
    "filtlist_short = []\n",
    "filtlist_long = []\n",
    "\n",
    "if not glob.glob('./*cal*fits'):\n",
    "\n",
    "    print(\"Downloading images\")\n",
    "\n",
    "    boxlink_images_lev2 = 'https://data.science.stsci.edu/redirect/JWST/jwst-data_analysis_tools/stellar_photometry/images_level2.tar.gz'\n",
    "    boxfile_images_lev2 = './images_level2.tar.gz'\n",
    "    urllib.request.urlretrieve(boxlink_images_lev2, boxfile_images_lev2)\n",
    "\n",
    "    tar = tarfile.open(boxfile_images_lev2, 'r')\n",
    "    tar.extractall()\n",
    "\n",
    "    images_dir = './'\n",
    "    images = sorted(glob.glob(os.path.join(images_dir, \"*cal.fits\")))\n",
    "\n",
    "else:\n",
    "\n",
    "    images_dir = './'\n",
    "    images = sorted(glob.glob(os.path.join(images_dir, \"*cal.fits\")))\n",
    "\n",
    "for image in images:\n",
    "\n",
    "    im = fits.open(image)\n",
    "    f = im[0].header['FILTER']\n",
    "    d = im[0].header['DETECTOR']\n",
    "\n",
    "    if d == 'NRCBLONG':\n",
    "        d = 'NRCB5'\n",
    "    elif d == 'NRCALONG':\n",
    "        d = 'NRCA5'\n",
    "    else:\n",
    "        d = d\n",
    "\n",
    "    wv = np.float(f[1:3])\n",
    "\n",
    "    if wv > 24:         \n",
    "        ff_long.append(f)\n",
    "        det_long.append(d)\n",
    "\n",
    "    else:\n",
    "        ff_short.append(f)\n",
    "        det_short.append(d)   \n",
    "\n",
    "    detlist_short = sorted(list(dict.fromkeys(det_short)))\n",
    "    detlist_long = sorted(list(dict.fromkeys(det_long)))\n",
    "\n",
    "    unique_list_filters_short = []\n",
    "    unique_list_filters_long = []\n",
    "\n",
    "    for x in ff_short:\n",
    "\n",
    "        if x not in unique_list_filters_short:\n",
    "\n",
    "            dict_filter_short.setdefault(x, {})\n",
    "\n",
    "    for x in ff_long:\n",
    "        if x not in unique_list_filters_long:\n",
    "            dict_filter_long.setdefault(x, {})   \n",
    "\n",
    "    for d_s in detlist_short:\n",
    "        dict_images[d_s] = dict_filter_short\n",
    "\n",
    "    for d_l in detlist_long:\n",
    "        dict_images[d_l] = dict_filter_long\n",
    "\n",
    "    filtlist_short = sorted(list(dict.fromkeys(dict_filter_short)))\n",
    "    filtlist_long = sorted(list(dict.fromkeys(dict_filter_long)))\n",
    "\n",
    "    if len(dict_images[d][f]) == 0:\n",
    "        dict_images[d][f] = {'images': [image]}\n",
    "    else:\n",
    "        dict_images[d][f]['images'].append(image)\n",
    "\n",
    "print(\"Available Detectors for SW channel:\", detlist_short)\n",
    "print(\"Available Detectors for LW channel:\", detlist_long)\n",
    "print(\"Available SW Filters:\", filtlist_short)\n",
    "print(\"Available LW Filters:\", filtlist_long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = ['F070W', 'F090W', 'F115W', 'F140M', 'F150W2', 'F150W', 'F162M', 'F164N', 'F182M',\n",
    "           'F187N', 'F200W', 'F210M', 'F212N', 'F250M', 'F277W', 'F300M', 'F322W2', 'F323N',\n",
    "           'F335M', 'F356W', 'F360M', 'F405N', 'F410M', 'F430M', 'F444W', 'F460M', 'F466N', 'F470N', 'F480M']\n",
    "\n",
    "psf_fwhm = [0.987, 1.103, 1.298, 1.553, 1.628, 1.770, 1.801, 1.494, 1.990, 2.060, 2.141, 2.304, 2.341, 1.340,\n",
    "            1.444, 1.585, 1.547, 1.711, 1.760, 1.830, 1.901, 2.165, 2.179, 2.300, 2.302, 2.459, 2.507, 2.535, 2.574]\n",
    "\n",
    "zp_modA = [25.7977, 25.9686, 25.8419, 24.8878, 27.0048, 25.6536, 24.6957, 22.3073, 24.8258, 22.1775, 25.3677, 24.3296,\n",
    "           22.1036, 22.7850, 23.5964, 24.8239, 23.6452, 25.3648, 20.8604, 23.5873, 24.3778, 23.4778, 20.5588,\n",
    "           23.2749, 22.3584, 23.9731, 21.9502, 20.0428, 19.8869, 21.9002]\n",
    "\n",
    "zp_modB = [25.7568, 25.9771, 25.8041, 24.8738, 26.9821, 25.6279, 24.6767, 22.2903, 24.8042, 22.1499, 25.3391, 24.2909,\n",
    "           22.0574, 22.7596, 23.5011, 24.6792, 23.5769, 25.3455, 20.8631, 23.4885, 24.3883, 23.4555, 20.7007,\n",
    "           23.2763, 22.4677, 24.1562, 22.0422, 20.1430, 20.0173, 22.4086]\n",
    "\n",
    "dict_utils = {filters[i]: {'psf fwhm': psf_fwhm[i], 'VegaMAG zp modA': zp_modA[i],\n",
    "                           'VegaMAG zp modB': zp_modB[i]} for i in range(len(filters))}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select the detectors and/or filters for the analysis\n",
    "\n",
    "If we are interested only in some filters (and/or some detectors) in the analysis, as in this example, we can select the Level-2 calibrated images from the dictionary for those filters (detectors) and analyze only those images.\n",
    "\n",
    "In this particular example, we analyze images for filters **F115W** and **F200W** for the detector **NRCB1**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dets_short = ['NRCB1']  # detector of interest in this example\n",
    "filts_short = ['F115W', 'F200W']  # filters of interest in this example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display the images\n",
    "\n",
    "To check that our images do not present artifacts and can be used in the analysis, we display them using an interactive cursor that allows to shuffle through the different images for each filter.\n",
    "\n",
    "### Note for developers: \n",
    "\n",
    "this is only a sketch of what I would like to show (I am not very familiar with ipywidgets). Would it be possible to show both filters at the same time, in a 2 window panel as in the static plot below? Or even better, have a widget control that allows to select the filters available and then use interact to cycle through the images? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell for display images using ipywidgets\n",
    "\n",
    "def browse_images(images):\n",
    "    n = len(images)\n",
    "\n",
    "    def view_image(image):\n",
    "        det = 'NRCB1'\n",
    "        filt = 'F115W'\n",
    "        im = fits.open(dict_images[det][filt]['images'][image])\n",
    "\n",
    "        data_sb = im[1].data\n",
    "        norm = simple_norm(data_sb, 'sqrt', percent=99.)   \n",
    "        plt.figure(figsize=(10, 10))\n",
    "\n",
    "        plt.title(filt)\n",
    "        plt.imshow(data_sb, norm=norm, cmap='Greys')        \n",
    "        plt.show()\n",
    "\n",
    "    interact(view_image, image=(0, n - 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "browse_images(dict_images['NRCB1']['F115W']['images'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note for developers: \n",
    "\n",
    "Cell below should be removed once we finalize the interactive one above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 14))\n",
    "\n",
    "for det in dets_short:\n",
    "    for i, filt in enumerate(filts_short):\n",
    "\n",
    "        image = fits.open(dict_images[det][filt]['images'][0])\n",
    "        data_sb = image[1].data\n",
    "\n",
    "        ax = plt.subplot(1, len(filts_short), i + 1)\n",
    "\n",
    "        plt.xlabel(\"X [px]\", fontdict=font2)\n",
    "        plt.ylabel(\"Y [px]\", fontdict=font2)\n",
    "        plt.title(filt, fontdict=font2)\n",
    "        norm = simple_norm(data_sb, 'sqrt', percent=99.)\n",
    "\n",
    "        ax.imshow(data_sb, norm=norm, cmap='Greys')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the PSF models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Create the PSF model using WebbPSF\n",
    "\n",
    "We create a dictionary that contains the PSF created using WebbPSF for the detectors and filters selected above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_psfs_webbpsf = {}\n",
    "\n",
    "for det in dets_short:\n",
    "    dict_psfs_webbpsf.setdefault(det, {})\n",
    "    for j, filt in enumerate(filts_short):\n",
    "        dict_psfs_webbpsf[det].setdefault(filt, {})\n",
    "\n",
    "        dict_psfs_webbpsf[det][filt]['psf model grid'] = None\n",
    "        dict_psfs_webbpsf[det][filt]['psf model single'] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below allows to create a single PSF or a grid of PSFs and allows to save the PSF as a fits file. The model PSF are stored by default in the psf dictionary. For the grid of PSFs, users can select the number of PSFs to be created. The PSF can be created detector sampled or oversampled (the oversample can be changed inside the function).\n",
    "\n",
    "**Note**: The default source spectrum is, if `pysynphot` is installed, a G2V star spectrum from Castelli & Kurucz (2004). Without `pysynphot`, the default is a simple flat spectrum such that the same number of photons are detected at each wavelength."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_psf_model(fov=11, create_grid=False, num=9, save_psf=False, detsampled=False):\n",
    "\n",
    "    nrc = webbpsf.NIRCam()\n",
    "\n",
    "    nrc.detector = det \n",
    "    nrc.filter = filt\n",
    "\n",
    "    src = webbpsf.specFromSpectralType('G5V', catalog='phoenix')\n",
    "    if detsampled:\n",
    "        print(\"Creating a detector sampled PSF\")\n",
    "        aa = 'detector sampled'\n",
    "        fov = 21\n",
    "    else:\n",
    "        print(\"Creating a oversampled PSF\")\n",
    "        aa = 'oversampled'\n",
    "        fov = fov\n",
    "\n",
    "    print(\"Using a {field}\".format(field=fov), \"px fov\")\n",
    "\n",
    "    if create_grid:\n",
    "        print(\"\")\n",
    "        print(\"Creating a grid of PSF for filter {filt} and detector {det}\".format(filt=filt, det=det))\n",
    "        print(\"\")\n",
    "        num = num\n",
    "\n",
    "        if save_psf:\n",
    "\n",
    "            outname = \"./PSF_%s_samp4_G5V_fov%d_npsfs%d.fits\" % (filt, fov, num)\n",
    "            nrc.psf_grid(num_psfs=num, oversample=4, source=src, all_detectors=False, fov_pixels=fov,\n",
    "                         save=True, outfile=outname, use_detsampled_psf=detsampled)\n",
    "        else:\n",
    "            grid_psf = nrc.psf_grid(num_psfs=num, oversample=4, source=src, all_detectors=False,\n",
    "                                    fov_pixels=fov, use_detsampled_psf=detsampled)\n",
    "            dict_psfs_webbpsf[det][filt]['psf model grid'] = grid_psf\n",
    "    else:\n",
    "        print(\"\")\n",
    "        print(\"Creating a single PSF for filter {filt} and detector {det}\".format(filt=filt, det=det))\n",
    "        print(\"\")\n",
    "        num = 1\n",
    "        if save_psf:\n",
    "            outname = \"./PSF_%s_samp4_G5V_fov%d_npsfs%d.fits\" % (filt, fov, num)\n",
    "            nrc.psf_grid(num_psfs=num, oversample=4, source=src, all_detectors=False, fov_pixels=fov,\n",
    "                         save=True, outfile=outname, use_detsampled_psf=detsampled)\n",
    "        else:\n",
    "            single_psf = nrc.psf_grid(num_psfs=num, oversample=4, source=src, all_detectors=False,\n",
    "                                      fov_pixels=fov, use_detsampled_psf=detsampled)\n",
    "            dict_psfs_webbpsf[det][filt]['psf model single'] = single_psf\n",
    "\n",
    "    return        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single PSF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for det in dets_short:\n",
    "    for filt in filts_short:\n",
    "        create_psf_model(fov=11, num=25, create_grid=False, save_psf=False, detsampled=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display the single PSF models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 14))\n",
    "\n",
    "for det in dets_short:\n",
    "    for i, filt in enumerate(filts_short):\n",
    "        ax = plt.subplot(1, 2, i + 1)\n",
    "\n",
    "        norm_epsf = simple_norm(dict_psfs_webbpsf[det][filt]['psf model single'].data[0], 'log', percent=99.)\n",
    "        ax.set_title(filt, fontsize=40)\n",
    "        ax.imshow(dict_psfs_webbpsf[det][filt]['psf model single'].data[0], norm=norm_epsf)\n",
    "        ax.set_xlabel('X [px]', fontsize=30)\n",
    "        ax.set_ylabel('Y [px]', fontsize=30)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PSF grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for det in dets_short:\n",
    "    for filt in filts_short:\n",
    "        create_psf_model(fov=11, num=25, create_grid=True, save_psf=False, detsampled=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display the PSFs grid\n",
    "\n",
    "We show for 1 filter (**F115W**) the grid of PSFs and the difference from the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "webbpsf.gridded_library.display_psf_grid(dict_psfs_webbpsf[dets_short[0]][filts_short[0]]['psf model grid'],\n",
    "                                         zoom_in=False, figsize=(14, 14))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Create the PSF model building an Effective PSF (ePSF)\n",
    "\n",
    "More information on the PhotUtils Effective PSF can be found [here](https://photutils.readthedocs.io/en/stable/epsf.html).\n",
    "\n",
    "* Select the stars from the images we want to use for building the PSF. We use the [DAOStarFinder](https://photutils.readthedocs.io/en/stable/api/photutils.detection.DAOStarFinder.html) function to find bright stars in the images (setting a high detection threshold). [DAOStarFinder](https://photutils.readthedocs.io/en/stable/api/photutils.detection.DAOStarFinder.html#photutils.detection.DAOStarFinder) detects stars in an image using the DAOFIND ([Stetson 1987](https://ui.adsabs.harvard.edu/abs/1987PASP...99..191S/abstract)) algorithm. DAOFIND searches images for local density maxima that have a peak amplitude greater than `threshold` (approximately; threshold is applied to a convolved image) and have a size and shape similar to the defined 2D Gaussian kernel. \\\n",
    " **Note**: The threshold and the maximum distance to the closest neighbour depend on the user science case (i.e.; number of stars in the field of view, crowding, number of bright sources, minimum number of stars required to build the ePSF, etc.) and must be modified accordingly. \n",
    "* Build the effective PSF (excluding objects for which the bounding box exceed the detector edge) using [EPSBuilder](https://photutils.readthedocs.io/en/stable/api/photutils.psf.EPSFBuilder.html#photutils.psf.EPSFBuilder) function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a dictionary that contains the effective PSF for the detectors and filters selected above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_psfs_epsf = {}\n",
    "\n",
    "for det in dets_short:\n",
    "    dict_psfs_epsf.setdefault(det, {})\n",
    "    for j, filt in enumerate(filts_short):\n",
    "        dict_psfs_epsf[det].setdefault(filt, {})\n",
    "\n",
    "        dict_psfs_epsf[det][filt]['table psf stars'] = {}\n",
    "        dict_psfs_epsf[det][filt]['epsf single'] = {}\n",
    "        dict_psfs_epsf[det][filt]['epsf grid'] = {}\n",
    "\n",
    "        for i in np.arange(0, len(dict_images[det][filt]['images']), 1):\n",
    "\n",
    "            dict_psfs_epsf[det][filt]['table psf stars'][i + 1] = None\n",
    "            dict_psfs_epsf[det][filt]['epsf single'][i + 1] = None\n",
    "            dict_psfs_epsf[det][filt]['epsf grid'][i + 1] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the unit of the Level-2 and Level-3 Images from the pipeline is MJy/sr (hence a surface brightness). The actual unit of the image can be checked from the header keyword **BUNIT**. The scalar conversion constant is copied to the header keyword **PHOTMJSR**, which gives the conversion from DN/s to megaJy/steradian. For our analysis we revert back to DN/s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_stars_epsf(det='NRCA1', filt='F070W', dist_sel=False):\n",
    "\n",
    "    bkgrms = MADStdBackgroundRMS()\n",
    "    mmm_bkg = MMMBackground()\n",
    "\n",
    "    image = fits.open(dict_images[det][filt]['images'][i])\n",
    "    data_sb = image[1].data\n",
    "    imh = image[1].header\n",
    "\n",
    "    print(\"Finding PSF stars on image {number} of filter {f}, detector {d}\".format(number=i + 1, f=filt, d=det))\n",
    "\n",
    "    data = data_sb / imh['PHOTMJSR']\n",
    "    print(\"Conversion factor from {units} to DN/s for filter {f}:\".format(units=imh['BUNIT'], f=filt), imh['PHOTMJSR'])\n",
    "\n",
    "    sigma_psf = dict_utils[filt]['psf fwhm']\n",
    "\n",
    "    print(\"FWHM for the filter {f}:\".format(f=filt), sigma_psf, \"px\")\n",
    "\n",
    "    std = bkgrms(data)\n",
    "    bkg = mmm_bkg(data)\n",
    "    daofind = DAOStarFinder(threshold=th[j] * std + bkg, fwhm=sigma_psf, roundhi=1.0, roundlo=-1.0,\n",
    "                            sharplo=0.30, sharphi=1.40)\n",
    "\n",
    "    psf_stars = daofind(data)\n",
    "    dict_psfs_epsf[det][filt]['table psf stars'][i + 1] = psf_stars\n",
    "    \n",
    "    if dist_sel:\n",
    "\n",
    "        print(\"\")\n",
    "        print(\"Calculating closest neigbhour distance\")\n",
    "\n",
    "        d = []\n",
    "\n",
    "        daofind_tot = DAOStarFinder(threshold=10 * std + bkg, fwhm=sigma_psf, roundhi=1.0, roundlo=-1.0,\n",
    "                                    sharplo=0.30, sharphi=1.40)\n",
    "\n",
    "        stars_tot = daofind_tot(data)\n",
    "\n",
    "        x_tot = stars_tot['xcentroid']\n",
    "        y_tot = stars_tot['ycentroid']\n",
    "\n",
    "        for xx, yy in zip(psf_stars['xcentroid'], psf_stars['ycentroid']):\n",
    "\n",
    "            sep = []\n",
    "            dist = np.sqrt((x_tot - xx)**2 + (y_tot - yy)**2)\n",
    "            sep = np.sort(dist)[1:2][0]\n",
    "            d.append(sep)\n",
    "\n",
    "        psf_stars['min distance'] = d\n",
    "        mask_dist = (psf_stars['min distance'] > min_sep[j])\n",
    "\n",
    "        psf_stars = psf_stars[mask_dist]\n",
    "\n",
    "        dict_psfs_epsf[det][filt]['table psf stars'][i + 1] = psf_stars\n",
    "\n",
    "        print(\"Minimum distance required:\", min_sep[j], \"px\")\n",
    "        print(\"\")\n",
    "        print(\"Number of isolated sources found in the image used to build ePSF for {f}:\".format(f=filt), len(psf_stars))\n",
    "        print(\"-----------------------------------------------------\")\n",
    "        print(\"\")\n",
    "    else:\n",
    "        print(\"\")\n",
    "        print(\"Number of sources used to build ePSF for {f}:\".format(f=filt), len(psf_stars))\n",
    "        print(\"--------------------------------------------\")\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.perf_counter()\n",
    "\n",
    "th = [700, 500]  # threshold level for the two filters (length must match number of filters analyzed)\n",
    "min_sep = [10, 10]  # minimum separation acceptable for ePSF stars from closest neighbour\n",
    "\n",
    "for det in dets_short:\n",
    "    for j, filt in enumerate(filts_short):\n",
    "        for i in np.arange(0, len(dict_images[det][filt]['images']), 1):\n",
    "\n",
    "            find_stars_epsf(det=det, filt=filt, dist_sel=False)\n",
    "\n",
    "toc = time.perf_counter()\n",
    "\n",
    "print(\"Elapsed Time for finding stars:\", toc - tic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II. Build Effective PSF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_epsf(det='NRCA1', filt='F070W'):\n",
    "    \n",
    "    mmm_bkg = MMMBackground()\n",
    "    \n",
    "    image = fits.open(dict_images[det][filt]['images'][i])\n",
    "    data_sb = image[1].data\n",
    "    imh = image[1].header\n",
    "\n",
    "    data = data_sb / imh['PHOTMJSR']\n",
    "\n",
    "    hsize = (sizes[j] - 1) / 2\n",
    "\n",
    "    x = dict_psfs_epsf[det][filt]['table psf stars'][i + 1]['xcentroid']\n",
    "    y = dict_psfs_epsf[det][filt]['table psf stars'][i + 1]['ycentroid']\n",
    "    mask = ((x > hsize) & (x < (data.shape[1] - 1 - hsize)) & (y > hsize) & (y < (data.shape[0] - 1 - hsize)))\n",
    "\n",
    "    stars_tbl = Table()\n",
    "    stars_tbl['x'] = x[mask]\n",
    "    stars_tbl['y'] = y[mask]\n",
    "\n",
    "    bkg = mmm_bkg(data)\n",
    "\n",
    "    data_bkgsub = data.copy()\n",
    "\n",
    "    data_bkgsub -= bkg\n",
    "\n",
    "    nddata = NDData(data=data_bkgsub)\n",
    "    stars = extract_stars(nddata, stars_tbl, size=sizes[j])\n",
    "\n",
    "    print(\"Creating ePSF for image {number} of filter {f}, detector {d}\".format(number=i + 1, f=filt, d=det))\n",
    "\n",
    "    epsf_builder = EPSFBuilder(oversampling=oversample, maxiters=3, progress_bar=False)\n",
    "\n",
    "    epsf, fitted_stars = epsf_builder(stars)\n",
    "    dict_psfs_epsf[det][filt]['epsf single'][i + 1] = epsf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: here we limit the maximum number of iterations to 3 (to limit it’s run time), but in practice one should use about 10 or more iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.perf_counter()\n",
    "\n",
    "sizes = [11, 11]  # size of the cutout (extract region) for each PSF star - must match number of filters analyzed\n",
    "oversample = 4\n",
    "\n",
    "for det in dets_short:\n",
    "    for j, filt in enumerate(filts_short):\n",
    "        for i in np.arange(0, len(dict_images[det][filt]['images']), 1):\n",
    "            build_epsf(det=det, filt=filt)\n",
    "\n",
    "toc = time.perf_counter()\n",
    "\n",
    "print(\"Time to build the Effective PSF:\", toc - tic)                  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display the ePSFs \n",
    "\n",
    "We display only 1 ePSF for each filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 14))\n",
    "\n",
    "for det in dets_short:\n",
    "    for i, filt in enumerate(filts_short):\n",
    "        ax = plt.subplot(1, 2, i + 1)\n",
    "\n",
    "        norm_epsf = simple_norm(dict_psfs_epsf[det][filt]['epsf single'][i + 1].data, 'log', percent=99.)\n",
    "        plt.title(filt, fontsize=30)\n",
    "        ax.imshow(dict_psfs_epsf[det][filt]['epsf single'][i + 1].data, norm=norm_epsf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work in Progress - Build a grid of effective PSF\n",
    "\n",
    "Two functions:\n",
    "* count PSF stars in the grid \n",
    "* create a gridded ePSF\n",
    "\n",
    "The purpose of the first function is to count how many good PSF stars are in each sub-region defined by the grid number N. The function should start from the number provided by the user and iterate until the minimum grid size 2x2. Depending on the number of PSF stars that the users want in each cell of the grid, they can choose the appropriate grid size or modify the threshold values for the stars detection, selected when creating the single ePSF (in the **Finding stars** cell above).\n",
    "\n",
    "The second function creates a grid of PSFs with EPSFBuilder. The function will return a a GriddedEPSFModel object containing a 3D array of N  ×  n  ×  n. The 3D array represents the N number of 2D n  ×  n ePSFs created. It should include a grid_xypos key which will state the position of the PSF on the detector for each of the PSFs. The order of the tuples in grid_xypos refers to the number the PSF is in the 3D array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I. Counting PSF stars in each region of the grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_PSFstars_grid(grid_points=5, size=15, min_numpsf=40):\n",
    "\n",
    "    num_grid_calc = np.arange(2, grid_points + 1, 1)\n",
    "    num_grid_calc = num_grid_calc[::-1]\n",
    "\n",
    "    for num in num_grid_calc:\n",
    "        print(\"Calculating the number of PSF stars in a %d x %d grid:\" % (num, num))\n",
    "        print(\"\")\n",
    "\n",
    "        image = fits.open(dict_images[det][filt]['images'][i])\n",
    "        data_sb = image[1].data\n",
    "\n",
    "        points = np.int16((data_sb.shape[0] / num) / 2)\n",
    "        x_center = np.arange(points, 2 * points * (num), 2 * points)\n",
    "        y_center = np.arange(points, 2 * points * (num), 2 * points)\n",
    "\n",
    "        centers = np.array(np.meshgrid(x_center, y_center)).T.reshape(-1, 2)\n",
    "\n",
    "        for n, val in enumerate(centers):\n",
    "\n",
    "            x = dict_psfs_epsf[det][filt]['table psf stars'][i + 1]['xcentroid']\n",
    "            y = dict_psfs_epsf[det][filt]['table psf stars'][i + 1]['ycentroid']\n",
    "            flux = dict_psfs_epsf[det][filt]['table psf stars'][i + 1]['flux']\n",
    "\n",
    "            half_size = (size - 1) / 2\n",
    "\n",
    "            lim1 = val[0] - points + half_size\n",
    "            lim2 = val[0] + points - half_size\n",
    "            lim3 = val[1] - points + half_size\n",
    "            lim4 = val[1] + points - half_size\n",
    "\n",
    "            test = (x > lim1) & (x < lim2) & (y > lim3) & (y < lim4)\n",
    "\n",
    "            # if np.count_nonzero(test) < min_numpsf:\n",
    "            # raise ValueError(\"Not enough PSF stars in all the cells (> %d): Decrease your grid size or the minimum number of PSF stars in each cell or change parameters in the finder\" %(min_numpsf))\n",
    "            if np.count_nonzero(test) < min_numpsf:\n",
    "                print(\"Center Coordinates of grid cell %d are (%d, %d) --- Not enough PSF stars in the cell (number of PSF stars < %d)\" % (i + 1, val[0], val[1], min_numpsf))\n",
    "\n",
    "            else:\n",
    "                print(\"Center Coordinate of grid cell %d are (%d, %d) --- Number of PSF stars:\" % (n + 1, val[0], val[1]), np.count_nonzero(test))                \n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for det in dets_short:\n",
    "    for j, filt in enumerate(filts_short):\n",
    "        for i in np.arange(0, len(dict_images[det][filt]['images']), 1):\n",
    "\n",
    "            print(\"Analyzing image {number} of filter {f}, detector {d} \".format(number=i + 1, f=filt, d=det))\n",
    "            print(\"\")\n",
    "\n",
    "            count_PSFstars_grid(grid_points=5, size=15, min_numpsf=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO - Create a grid of ePSF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here goes the function that creates a grid of ePSF that can be saved in the epsf dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO - Use the ePSF grid to perturbate the WebbPSF model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here goes the function that create a grid of PSF models obtained perturbating the WebbPSF PSF models using the ePSF grid created above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform PSF photometry\n",
    "\n",
    "We perform the PSF photometry on the images, saving by default the output catalogs and the residual images in the dictionary created below. It is also possible to save the output catalogs (pickles pandas object) and residual images (fits files) in the current directory using the parameters `save_output` and `save_residuals`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_phot = {}\n",
    "\n",
    "for det in dets_short:\n",
    "    dict_phot.setdefault(det, {})\n",
    "    for j, filt in enumerate(filts_short):\n",
    "        dict_phot[det].setdefault(filt, {})\n",
    "\n",
    "        dict_phot[det][filt]['residual images'] = {}\n",
    "        dict_phot[det][filt]['output photometry tables'] = {}\n",
    "\n",
    "        for i in np.arange(0, len(dict_images[det][filt]['images']), 1):\n",
    "\n",
    "            dict_phot[det][filt]['residual images'][i + 1] = None\n",
    "            dict_phot[det][filt]['output photometry tables'][i + 1] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: since performing the PSF photometry on the images takes some time (for the 8 images in this example ~ 4 hours), to speed up the notebook, we use a high threshold in the finding algorithm (threshold ~ 2000) and we will use in the analyis below the catalogs obtained with a sigma threshold = 10 from a previous reduction run. To perform a meaningful data reduction, the user should modify the threshold accordingly. \n",
    "\n",
    "Here we use as PSF model the grid of WebbPSF PSFs, but the users can change the model and use the others available (i.e., single WebbPSF PSF, single ePSF) modifying the `psf` parameter in the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def psf_phot(det='NRCA1', filt='F070W', th=2000, psf='grid_webbpsf', save_residuals=False, save_output=False):\n",
    "\n",
    "    bkgrms = MADStdBackgroundRMS()\n",
    "    mmm_bkg = MMMBackground()\n",
    "    fitter = LevMarLSQFitter()\n",
    "\n",
    "    im = fits.open(dict_images[det][filt]['images'][i])\n",
    "    imh = im[1].header\n",
    "    data_sb = im[1].data\n",
    "\n",
    "    d = im[0].header['DETECTOR']\n",
    "    prim_dith_pos = im[0].header['PATT_NUM']\n",
    "    prim_dith_num = im[0].header['NUMDTHPT']\n",
    "    subpx_dith_pos = im[0].header['SUBPXNUM']\n",
    "    subpx_dith_num = im[0].header['SUBPXPNS']\n",
    "\n",
    "    data = data_sb / imh['PHOTMJSR']\n",
    "\n",
    "    print(\"Conversion factor from {units} to DN/s for filter {f}:\".format(units=imh['BUNIT'], f=filt), imh['PHOTMJSR'])\n",
    "    print(\"Applying conversion to the data\")\n",
    "            \n",
    "    sigma_psf = dict_utils[filt]['psf fwhm']\n",
    "    print(\"FWHM for the filter {f}:\".format(f=filt), sigma_psf)\n",
    "    \n",
    "    std = bkgrms(data)\n",
    "    bkg = mmm_bkg(data)\n",
    "    \n",
    "    daofind = DAOStarFinder(threshold=th * std + bkg, fwhm=sigma_psf, roundhi=1.0, roundlo=-1.0,\n",
    "                            sharplo=0.30, sharphi=1.40)\n",
    "    \n",
    "    daogroup = DAOGroup(5.0 * sigma_psf)\n",
    "    \n",
    "    # grid PSF\n",
    "\n",
    "    if psf == 'grid_webbpsf':\n",
    "        print(\"Using as PSF model WebbPSF PSFs grid\")\n",
    "        psf_model = dict_psfs_webbpsf[det][filt]['psf model grid'].copy()\n",
    "\n",
    "    # single psf:\n",
    "\n",
    "    if psf == 'single_webbpsf':\n",
    "        print(\"Using as PSF model WebbPSF single PSF\")\n",
    "        psf_model = dict_psfs_webbpsf[det][filt]['psf model single'].copy()\n",
    "\n",
    "    # epsf:\n",
    "\n",
    "    if psf == 'single_epsf':\n",
    "        print(\"Using as PSF model single ePSF\")\n",
    "        psf_model = dict_psfs_epsf[det][filt]['epsf single'][i + 1].copy()\n",
    "\n",
    "    print(\"Performing the photometry on image {number} of filter {f}, detector {d}\".format(number=i + 1, f=filt, d=det))\n",
    "            \n",
    "    tic = time.perf_counter()\n",
    "    \n",
    "    phot = IterativelySubtractedPSFPhotometry(finder=daofind, group_maker=daogroup,\n",
    "                                              bkg_estimator=mmm_bkg, psf_model=psf_model,\n",
    "                                              fitter=LevMarLSQFitter(),\n",
    "                                              niters=2, fitshape=(11, 11), aperture_radius=ap_radius[j])\n",
    "    result = phot(data)\n",
    "    \n",
    "    toc = time.perf_counter()\n",
    "    \n",
    "    print(\"Time needed to perform photometry on image {number}:\".format(number=i + 1), \"%.2f\" % ((toc - tic) / 3600), \"hours\")\n",
    "    print(\"Number of sources detected in image {number} for filter {f}:\".format(number=i + 1, f=filt), len(result))\n",
    "        \n",
    "    residual_image = phot.get_residual_image()\n",
    "                            \n",
    "    dict_phot[det][filt]['residual images'][i + 1] = residual_image\n",
    "    dict_phot[det][filt]['output photometry tables'][i + 1] = result\n",
    "\n",
    "    # save the residual images as fits file:\n",
    "\n",
    "    if save_residuals:\n",
    "        hdu = fits.PrimaryHDU(residual_image)\n",
    "        hdul = fits.HDUList([hdu])\n",
    "        residual_outname = 'residual_%s_%s_webbPSF_gridPSF_%dof%d_%dof%d.fits' % (d, filt, prim_dith_pos, prim_dith_num, subpx_dith_pos, subpx_dith_num)\n",
    "\n",
    "        dir_output_phot = './'\n",
    "\n",
    "        hdul.writeto(os.path.join(dir_output_phot, residual_outname))\n",
    "\n",
    "        outname = 'phot_%s_%s_webbPSF_gridPSF_level2_%dof%d_%dof%d.pkl' % (d, filt, prim_dith_pos, prim_dith_num, subpx_dith_pos, subpx_dith_num)\n",
    "\n",
    "    # save the output photometry Tables\n",
    "\n",
    "    if save_output:\n",
    "        tab = result.to_pandas()\n",
    "        tab.to_pickle(os.path.join(dir_output_phot, outname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic_tot = time.perf_counter()\n",
    "\n",
    "ap_radius = [3.0, 3.5]  # must match the number of filters analyzed\n",
    "\n",
    "if glob.glob('./*residual*.fits'):\n",
    "    print(\"Deleting Residual images from directory\")\n",
    "    files = glob.glob('./residual*.fits')\n",
    "    for file in files:\n",
    "        os.remove(file)\n",
    "\n",
    "for det in dets_short:\n",
    "    for j, filt in enumerate(filts_short):\n",
    "        for i in np.arange(0, len(dict_images[det][filt]['images']), 1):\n",
    "            \n",
    "            psf_phot(det=det, filt=filt, th=2000, psf='grid_webbpsf', save_residuals=True, save_output=False) \n",
    "\n",
    "toc_tot = time.perf_counter()\n",
    "print(\"Time elapsed to perform the photometry of the {number} images:\".format(number=(len(filts_short) * len(dict_images[det][filt]['images']))), \"%.2f\" % ((toc_tot - tic_tot) / 3600), \"hours\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Photometry Table\n",
    "\n",
    "\n",
    "### Note for developer: \n",
    "\n",
    "It would be really useful, if PhotUtils can provide some diagnostics to identify the quality of the photometry in the final catalog for each source (similarly to all the other PSF photometry programs available)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_phot['NRCB1']['F115W']['output photometry tables'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display subtracted image\n",
    "\n",
    "As an example, we show the comparison between one science image and the residual image after the data reduction for both filters. Note that the residual image is obtained from the photometry run in the cell above with a very high detection threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 14))\n",
    "\n",
    "for det in dets_short:\n",
    "    for i, filt in enumerate(filts_short):\n",
    "\n",
    "        image = fits.open(dict_images[det][filt]['images'][0])\n",
    "        data_sb = image[1].data\n",
    "\n",
    "        ax = plt.subplot(2, len(filts_short), i + 1)\n",
    "\n",
    "        plt.xlabel(\"X [px]\", fontdict=font2)\n",
    "        plt.ylabel(\"Y [px]\", fontdict=font2)\n",
    "        plt.title(filt, fontdict=font2)\n",
    "        norm = simple_norm(data_sb, 'sqrt', percent=99.)\n",
    "\n",
    "        ax.imshow(data_sb, norm=norm, cmap='Greys')\n",
    "\n",
    "for det in dets_short:\n",
    "    for i, filt in enumerate(filts_short):\n",
    "\n",
    "        res = dict_phot[det][filt]['residual images'][1]\n",
    "\n",
    "        ax = plt.subplot(2, len(filts_short), i + 3)\n",
    "\n",
    "        plt.xlabel(\"X [px]\", fontdict=font2)\n",
    "        plt.ylabel(\"Y [px]\", fontdict=font2)\n",
    "        norm = simple_norm(data_sb, 'sqrt', percent=99.)\n",
    "\n",
    "        ax.imshow(res, norm=norm, cmap='Greys')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part II - Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: here we use the reduction obtained using a grid of WebbPSF PSFs as PSF models. The users can perform the data analysis using different PSF models (single PSF model, PSF grid, etc.) and compare the results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Tables with PSF Photometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not glob.glob('./*phot*gridPSF*.pkl'):\n",
    "\n",
    "    print(\"Downloading Photometry Output\")\n",
    "\n",
    "    boxlink_cat_f115w = 'https://data.science.stsci.edu/redirect/JWST/jwst-data_analysis_tools/stellar_photometry/phot_cat_F115W.tar.gz'\n",
    "    boxfile_cat_f115w = './phot_cat_F115W.tar.gz'\n",
    "    urllib.request.urlretrieve(boxlink_cat_f115w, boxfile_cat_f115w)\n",
    "\n",
    "    tar = tarfile.open(boxfile_cat_f115w, 'r')\n",
    "    tar.extractall()\n",
    "\n",
    "    boxlink_cat_f200w = 'https://data.science.stsci.edu/redirect/JWST/jwst-data_analysis_tools/stellar_photometry/phot_cat_F200W.tar.gz'\n",
    "    boxfile_cat_f200w = './phot_cat_F200W.tar.gz'\n",
    "    urllib.request.urlretrieve(boxlink_cat_f200w, boxfile_cat_f200w)\n",
    "\n",
    "    tar = tarfile.open(boxfile_cat_f200w, 'r')\n",
    "    tar.extractall()\n",
    "\n",
    "    cat_dir = './'\n",
    "    phots_pkl_f115w = sorted(glob.glob(os.path.join(cat_dir, '*F115W*gridPSF*.pkl')))\n",
    "    phots_pkl_f200w = sorted(glob.glob(os.path.join(cat_dir, '*F200W*gridPSF*.pkl')))                       \n",
    "\n",
    "else:\n",
    "\n",
    "    cat_dir = './'\n",
    "    phots_pkl_f115w = sorted(glob.glob(os.path.join(cat_dir, '*F115W*gridPSF*.pkl')))\n",
    "    phots_pkl_f200w = sorted(glob.glob(os.path.join(cat_dir, '*F200W*gridPSF*.pkl')))                      \n",
    "\n",
    "results_f115w = []\n",
    "results_f200w = []\n",
    "\n",
    "for phot_pkl_f115w, phot_pkl_f200w in zip(phots_pkl_f115w, phots_pkl_f200w):\n",
    "\n",
    "    ph_f115w = pd.read_pickle(phot_pkl_f115w)\n",
    "    ph_f200w = pd.read_pickle(phot_pkl_f200w)\n",
    "\n",
    "    result_f115w = QTable.from_pandas(ph_f115w)\n",
    "    result_f200w = QTable.from_pandas(ph_f200w)\n",
    "\n",
    "    results_f115w.append(result_f115w)\n",
    "    results_f200w.append(result_f200w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform the images to DataModel\n",
    "\n",
    "In order to assign the WCS coordinate and hence cross-match the images, we need to transform the images to DataModel. The coordinates are assigned during the step [assign_wcs](https://jwst-pipeline.readthedocs.io/en/stable/jwst/assign_wcs/main.html?#using-the-wcs-interactively) step in the JWST pipeline and allow us to cross-match the different catalogs obtained for each filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_f115w = []\n",
    "images_f200w = []\n",
    "\n",
    "for i in np.arange(0, len(dict_images['NRCB1']['F115W']['images']), 1):\n",
    "\n",
    "    image_f115w = ImageModel(dict_images['NRCB1']['F115W']['images'][i])\n",
    "    images_f115w.append(image_f115w)\n",
    "        \n",
    "for i in np.arange(0, len(dict_images['NRCB1']['F200W']['images']), 1):\n",
    "\n",
    "    image_f200w = ImageModel(dict_images['NRCB1']['F200W']['images'][i])\n",
    "    images_f200w.append(image_f200w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-match the catalogs from the two filters for the 4 images\n",
    "\n",
    "We cross-match the catalogs to obtain the single color-magnitude diagrams.\n",
    "\n",
    "Stars from the two filters are associated if the distance between the matches is < 0.5 px. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_clean_f115w = []\n",
    "results_clean_f200w = []\n",
    "\n",
    "for i in np.arange(0, len(images_f115w), 1):\n",
    "\n",
    "    mask_f115w = ((results_f115w[i]['x_fit'] > 0) & (results_f115w[i]['x_fit'] < 2048) &\n",
    "                  (results_f115w[i]['y_fit'] > 0) & (results_f115w[i]['y_fit'] < 2048) &\n",
    "                  (results_f115w[i]['flux_fit'] > 0))\n",
    "\n",
    "    result_clean_f115w = results_f115w[i][mask_f115w]\n",
    "\n",
    "    ra_f115w, dec_f115w = images_f115w[i].meta.wcs(result_clean_f115w['x_fit'], result_clean_f115w['y_fit'])\n",
    "    radec_f115w = SkyCoord(ra_f115w, dec_f115w, unit='deg')\n",
    "    result_clean_f115w['radec'] = radec_f115w\n",
    "    results_clean_f115w.append(result_clean_f115w)\n",
    "\n",
    "    mask_f200w = ((results_f200w[i]['x_fit'] > 0) & (results_f200w[i]['x_fit'] < 2048) &\n",
    "                  (results_f200w[i]['y_fit'] > 0) & (results_f200w[i]['y_fit'] < 2048) &\n",
    "                  (results_f200w[i]['flux_fit'] > 0))\n",
    "\n",
    "    result_clean_f200w = results_f200w[i][mask_f200w]\n",
    "\n",
    "    ra_f200w, dec_f200w = images_f200w[i].meta.wcs(result_clean_f200w['x_fit'], result_clean_f200w['y_fit'])\n",
    "    radec_f200w = SkyCoord(ra_f200w, dec_f200w, unit='deg')\n",
    "\n",
    "    result_clean_f200w['radec'] = radec_f200w\n",
    "    results_clean_f200w.append(result_clean_f200w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sep = 0.015 * u.arcsec\n",
    "\n",
    "matches_phot_single = []\n",
    "filt1 = 'F115W'\n",
    "filt2 = 'F200W'\n",
    "\n",
    "for res1, res2 in zip(results_clean_f115w, results_clean_f200w):\n",
    "\n",
    "    idx, d2d, _ = match_coordinates_sky(res1['radec'], res2['radec'])\n",
    "\n",
    "    sep_constraint = d2d < max_sep\n",
    "\n",
    "    match_phot_single = Table()\n",
    "\n",
    "    x_0_f115w = res1['x_0'][sep_constraint]\n",
    "    y_0_f115w = res1['y_0'][sep_constraint]\n",
    "    x_fit_f115w = res1['x_fit'][sep_constraint]\n",
    "    y_fit_f115w = res1['y_fit'][sep_constraint]\n",
    "    radec_f115w = res1['radec'][sep_constraint]\n",
    "    mag_f115w = (-2.5 * np.log10(res1['flux_fit']))[sep_constraint]\n",
    "    emag_f115w = (1.086 * (res1['flux_unc'] / res1['flux_fit']))[sep_constraint]\n",
    "\n",
    "    x_0_f200w = res2['x_0'][idx[sep_constraint]]\n",
    "    y_0_f200w = res2['y_0'][idx[sep_constraint]]\n",
    "    x_fit_f200w = res2['x_fit'][idx[sep_constraint]]\n",
    "    y_fit_f200w = res2['y_fit'][idx[sep_constraint]]\n",
    "    radec_f200w = res2['radec'][idx][sep_constraint]\n",
    "    mag_f200w = (-2.5 * np.log10(res2['flux_fit']))[idx[sep_constraint]]\n",
    "    emag_f200w = (1.086 * (res2['flux_unc'] / res2['flux_fit']))[idx[sep_constraint]]\n",
    "\n",
    "    match_phot_single['x_0_' + filt1] = x_0_f115w\n",
    "    match_phot_single['y_0_' + filt1] = y_0_f115w\n",
    "    match_phot_single['x_fit_' + filt1] = x_fit_f115w\n",
    "    match_phot_single['y_fit_' + filt1] = y_fit_f115w\n",
    "    match_phot_single['radec_' + filt1] = radec_f115w\n",
    "    match_phot_single['mag_' + filt1] = mag_f115w\n",
    "    match_phot_single['emag_' + filt1] = emag_f115w\n",
    "    match_phot_single['x_0_' + filt2] = x_0_f200w\n",
    "    match_phot_single['y_0_' + filt2] = y_0_f200w\n",
    "    match_phot_single['x_fit_' + filt2] = x_fit_f200w\n",
    "    match_phot_single['y_fit_' + filt2] = y_fit_f200w\n",
    "    match_phot_single['radec_' + filt2] = radec_f200w\n",
    "    match_phot_single['mag_' + filt2] = mag_f200w\n",
    "    match_phot_single['emag_' + filt2] = emag_f200w\n",
    "\n",
    "    matches_phot_single.append(match_phot_single)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Color-Magnitude Diagrams (Instrumental Magnitudes) for the 4 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 16))\n",
    "plt.clf()\n",
    "\n",
    "for i in np.arange(0, len(matches_phot_single), 1):\n",
    "    ax = plt.subplot(2, 2, i + 1)\n",
    "\n",
    "    j = str(i + 1)\n",
    "\n",
    "    xlim0 = -0.5\n",
    "    xlim1 = 0.8\n",
    "    ylim0 = -1\n",
    "    ylim1 = -9\n",
    "\n",
    "    ax.set_xlim(xlim0, xlim1)\n",
    "    ax.set_ylim(ylim0, ylim1)\n",
    "\n",
    "    ax.xaxis.set_major_locator(ticker.AutoLocator())\n",
    "    ax.xaxis.set_minor_locator(ticker.AutoMinorLocator())\n",
    "    ax.yaxis.set_major_locator(ticker.AutoLocator())\n",
    "    ax.yaxis.set_minor_locator(ticker.AutoMinorLocator())\n",
    "\n",
    "    f115w_single = matches_phot_single[i]['mag_' + filt1]\n",
    "    f200w_single = matches_phot_single[i]['mag_' + filt2]\n",
    "\n",
    "    ax.scatter(f115w_single - f200w_single, f115w_single, s=1, color='k')\n",
    "\n",
    "    ax.set_xlabel(filt1 + '-' + filt2, fontdict=font2)\n",
    "    ax.set_ylabel(filt1, fontdict=font2)\n",
    "    ax.text(xlim0 + 0.1, -8.65, \"Image %s\" % j, fontdict=font2)\n",
    "    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Difference in retrieved positions (in pixels) between daofind an PSF routine\n",
    "\n",
    "We show the difference in the stars position derived from daofind and the psf fitting algorithm. We also show the difference $\\Delta$X and $\\Delta$Y as a function of the instrumental magnitudes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "ax1 = plt.subplot(1, 2, 1)\n",
    "\n",
    "xlim0 = -1\n",
    "xlim1 = 1\n",
    "ylim0 = -1\n",
    "ylim1 = 1\n",
    "\n",
    "ax1.set_xlim(xlim0, xlim1)\n",
    "ax1.set_ylim(ylim0, ylim1)\n",
    "\n",
    "ax1.xaxis.set_major_locator(ticker.AutoLocator())\n",
    "ax1.xaxis.set_minor_locator(ticker.AutoMinorLocator())\n",
    "ax1.yaxis.set_major_locator(ticker.AutoLocator())\n",
    "ax1.yaxis.set_minor_locator(ticker.AutoMinorLocator())\n",
    "\n",
    "x_find_f115w = results_clean_f115w[0]['x_0']\n",
    "y_find_f115w = results_clean_f115w[0]['y_0']\n",
    "\n",
    "x_psf_f115w = results_clean_f115w[0]['x_fit']\n",
    "y_psf_f115w = results_clean_f115w[0]['y_fit']\n",
    "\n",
    "delta_x_f115w = x_find_f115w - x_psf_f115w\n",
    "delta_y_f115w = y_find_f115w - y_psf_f115w\n",
    "\n",
    "_, d_x_f115w, sigma_d_x_f115w = sigma_clipped_stats(delta_x_f115w)\n",
    "_, d_y_f115w, sigma_d_y_f115w = sigma_clipped_stats(delta_y_f115w)\n",
    "\n",
    "ax1.scatter(delta_x_f115w, delta_y_f115w, s=1, color='gray')\n",
    "\n",
    "ax1.set_xlabel('$\\Delta$ X (px)', fontdict=font2)\n",
    "ax1.set_ylabel('$\\Delta$ Y (px)', fontdict=font2)\n",
    "ax1.set_title(filt1, fontdict=font2)\n",
    "ax1.text(xlim0 + 0.05, ylim1 - 0.15, ' $\\Delta$ X = %5.3f $\\pm$ %5.3f' % (d_x_f115w, sigma_d_x_f115w),\n",
    "         color='k', fontdict=font2)\n",
    "ax1.text(xlim0 + 0.05, ylim1 - 0.30, ' $\\Delta$ Y = %5.3f $\\pm$ %5.3f' % (d_y_f115w, sigma_d_y_f115w),\n",
    "         color='k', fontdict=font2)\n",
    "ax1.plot([0, 0], [ylim0, ylim1], color='k', lw=2, ls='--')\n",
    "ax1.plot([xlim0, xlim1], [0, 0], color='k', lw=2, ls='--')\n",
    "\n",
    "ax2 = plt.subplot(1, 2, 2)\n",
    "\n",
    "ax2.set_xlim(xlim0, xlim1)\n",
    "ax2.set_ylim(ylim0, ylim1)\n",
    "\n",
    "ax2.xaxis.set_major_locator(ticker.AutoLocator())\n",
    "ax2.xaxis.set_minor_locator(ticker.AutoMinorLocator())\n",
    "ax2.yaxis.set_major_locator(ticker.AutoLocator())\n",
    "ax2.yaxis.set_minor_locator(ticker.AutoMinorLocator())\n",
    "\n",
    "x_find_f200w = results_clean_f200w[0]['x_0']\n",
    "y_find_f200w = results_clean_f200w[0]['y_0']\n",
    "\n",
    "x_psf_f200w = results_clean_f200w[0]['x_fit']\n",
    "y_psf_f200w = results_clean_f200w[0]['y_fit']\n",
    "\n",
    "delta_x_f200w = x_find_f200w - x_psf_f200w\n",
    "delta_y_f200w = y_find_f200w - y_psf_f200w\n",
    "\n",
    "_, d_x_f200w, sigma_d_x_f200w = sigma_clipped_stats(delta_x_f200w)\n",
    "_, d_y_f200w, sigma_d_y_f200w = sigma_clipped_stats(delta_y_f200w)\n",
    "\n",
    "ax2.scatter(delta_x_f200w, delta_y_f200w, s=1, color='gray')\n",
    "ax2.text(xlim0 + 0.05, ylim1 - 0.15, ' $\\Delta$ X = %5.3f $\\pm$ %5.3f' % (d_x_f200w, sigma_d_x_f200w),\n",
    "         color='k', fontdict=font2)\n",
    "ax2.text(xlim0 + 0.05, ylim1 - 0.30, ' $\\Delta$ Y = %5.3f $\\pm$ %5.3f' % (d_y_f200w, sigma_d_y_f200w),\n",
    "         color='k', fontdict=font2)\n",
    "ax2.plot([0, 0], [ylim0, ylim1], color='k', lw=2, ls='--')\n",
    "ax2.plot([xlim0, xlim1], [0, 0], color='k', lw=2, ls='--')\n",
    "\n",
    "ax2.set_xlabel('$\\Delta$ X (px)', fontdict=font2)\n",
    "ax2.set_ylabel('$\\Delta$ Y (px)', fontdict=font2)\n",
    "ax2.set_title(filt2, fontdict=font2)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "ax1 = plt.subplot(2, 2, 1)\n",
    "\n",
    "xlim0 = -9\n",
    "xlim1 = -1\n",
    "ylim0 = -1\n",
    "ylim1 = 1\n",
    "\n",
    "ax1.set_xlim(xlim0, xlim1)\n",
    "ax1.set_ylim(ylim0, ylim1)\n",
    "\n",
    "ax1.xaxis.set_major_locator(ticker.AutoLocator())\n",
    "ax1.xaxis.set_minor_locator(ticker.AutoMinorLocator())\n",
    "ax1.yaxis.set_major_locator(ticker.AutoLocator())\n",
    "ax1.yaxis.set_minor_locator(ticker.AutoMinorLocator())\n",
    "\n",
    "mag_inst_f115w = -2.5 * np.log10(results_clean_f115w[0]['flux_fit'])\n",
    "\n",
    "ax1.scatter(mag_inst_f115w, delta_x_f115w, s=1, color='gray')\n",
    "ax1.plot([xlim0, xlim1], [0, 0], color='k', lw=2, ls='--')\n",
    "\n",
    "ax1.set_xlabel(filt1 + '_inst', fontdict=font2)\n",
    "ax1.set_ylabel('$\\Delta$ X (px)', fontdict=font2)\n",
    "\n",
    "ax2 = plt.subplot(2, 2, 2)\n",
    "\n",
    "ax2.set_xlim(xlim0, xlim1)\n",
    "ax2.set_ylim(ylim0, ylim1)\n",
    "\n",
    "ax2.xaxis.set_major_locator(ticker.AutoLocator())\n",
    "ax2.xaxis.set_minor_locator(ticker.AutoMinorLocator())\n",
    "ax2.yaxis.set_major_locator(ticker.AutoLocator())\n",
    "ax2.yaxis.set_minor_locator(ticker.AutoMinorLocator())\n",
    "\n",
    "ax2.scatter(mag_inst_f115w, delta_y_f115w, s=1, color='gray')\n",
    "ax2.plot([xlim0, xlim1], [0, 0], color='k', lw=2, ls='--')\n",
    "\n",
    "ax2.set_xlabel(filt1 + '_inst', fontdict=font2)\n",
    "ax2.set_ylabel('$\\Delta$ Y (px)', fontdict=font2)\n",
    "\n",
    "ax3 = plt.subplot(2, 2, 3)\n",
    "\n",
    "ax3.set_xlim(xlim0, xlim1)\n",
    "ax3.set_ylim(ylim0, ylim1)\n",
    "\n",
    "ax3.xaxis.set_major_locator(ticker.AutoLocator())\n",
    "ax3.xaxis.set_minor_locator(ticker.AutoMinorLocator())\n",
    "ax3.yaxis.set_major_locator(ticker.AutoLocator())\n",
    "ax3.yaxis.set_minor_locator(ticker.AutoMinorLocator())\n",
    "\n",
    "mag_inst_f200w = -2.5 * np.log10(results_clean_f200w[0]['flux_fit'])\n",
    "\n",
    "ax3.scatter(mag_inst_f200w, delta_x_f200w, s=1, color='gray')\n",
    "ax3.plot([xlim0, xlim1], [0, 0], color='k', lw=2, ls='--')\n",
    "\n",
    "ax3.set_xlabel(filt2 + '_inst', fontdict=font2)\n",
    "ax3.set_ylabel('$\\Delta$ X (px)', fontdict=font2)\n",
    "\n",
    "ax4 = plt.subplot(2, 2, 4)\n",
    "\n",
    "ax4.set_xlim(xlim0, xlim1)\n",
    "ax4.set_ylim(ylim0, ylim1)\n",
    "\n",
    "ax4.xaxis.set_major_locator(ticker.AutoLocator())\n",
    "ax4.xaxis.set_minor_locator(ticker.AutoMinorLocator())\n",
    "ax4.yaxis.set_major_locator(ticker.AutoLocator())\n",
    "ax4.yaxis.set_minor_locator(ticker.AutoMinorLocator())\n",
    "\n",
    "ax4.scatter(mag_inst_f200w, delta_y_f200w, s=1, color='gray')\n",
    "ax4.plot([xlim0, xlim1], [0, 0], color='k', lw=2, ls='--')\n",
    "\n",
    "ax4.set_xlabel(filt2 + '_inst', fontdict=font2)\n",
    "ax4.set_ylabel('$\\Delta$ Y (px)', fontdict=font2)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-match the 4 catalogs for each filter\n",
    "\n",
    "To obtain a final color-magnitude diagram, we need to cross-match all the catalogs for each filters and then cross-match the derived final catalogs.\n",
    "\n",
    "**Note**: this is the most conservative approach since we impose that a star must be found in all 4 catalogs.\n",
    "\n",
    "### Note for developer: \n",
    "\n",
    "I couldn't find an easier way to write this function, where you need to match the first two catalogs, derive a sub-catalogs with only the matches and then iterate for all the other catalogs available. We should also think on how to create a function that allows to keep the stars also if they are available in X out of Y catalogs (i.e., if for some reasons, a measure is not available in 1 of the images, but the star is well measured in the other 3, it doesn't make sense to discard the object)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossmatch_filter(table=None):\n",
    "\n",
    "    num = 0\n",
    "    num_cat = np.char.mod('%d', np.arange(1, len(table) + 1, 1))\n",
    "\n",
    "    idx_12, d2d_12, _ = match_coordinates_sky(table[num]['radec'], table[num + 1]['radec'])\n",
    "\n",
    "    sep_constraint_12 = d2d_12 < max_sep\n",
    "\n",
    "    matches_12 = Table()\n",
    "\n",
    "    matches_12['radec_' + num_cat[num]] = table[num]['radec'][sep_constraint_12]\n",
    "    matches_12['mag_' + num_cat[num]] = (-2.5 * np.log10(table[num]['flux_fit']))[sep_constraint_12]\n",
    "    matches_12['emag_' + num_cat[num]] = (1.086 * (table[num]['flux_unc'] / \n",
    "                                                   table[num]['flux_fit']))[sep_constraint_12]\n",
    "\n",
    "    matches_12['radec_' + num_cat[num + 1]] = table[num + 1]['radec'][idx_12[sep_constraint_12]]\n",
    "    matches_12['mag_' + num_cat[num + 1]] = (-2.5 * np.log10(table[num + 1]['flux_fit']))[idx_12[sep_constraint_12]]\n",
    "    matches_12['emag_' + num_cat[num + 1]] = (1.086 * (table[num + 1]['flux_unc'] /\n",
    "                                                       table[num + 1]['flux_fit']))[idx_12[sep_constraint_12]]\n",
    "\n",
    "    idx_123, d2d_123, _ = match_coordinates_sky(matches_12['radec_' + num_cat[num]], table[num + 2]['radec'])\n",
    "\n",
    "    sep_constraint_123 = d2d_123 < max_sep\n",
    "\n",
    "    matches_123 = Table()\n",
    "\n",
    "    matches_123['radec_' + num_cat[num]] = matches_12['radec_' + num_cat[num]][sep_constraint_123]\n",
    "    matches_123['mag_' + num_cat[num]] = matches_12['mag_' + num_cat[num]][sep_constraint_123]\n",
    "    matches_123['emag_' + num_cat[num]] = matches_12['emag_' + num_cat[num]][sep_constraint_123]\n",
    "    matches_123['radec_' + num_cat[num + 1]] = matches_12['radec_' + num_cat[num + 1]][sep_constraint_123]\n",
    "    matches_123['mag_' + num_cat[num + 1]] = matches_12['mag_' + num_cat[num + 1]][sep_constraint_123]\n",
    "    matches_123['emag_' + num_cat[num + 1]] = matches_12['emag_' + num_cat[num + 1]][sep_constraint_123]\n",
    "    matches_123['radec_' + num_cat[num + 2]] = table[num + 2]['radec'][idx_123[sep_constraint_123]]\n",
    "    matches_123['mag_' + num_cat[num + 2]] = (-2.5 * np.log10(table[num + 2]['flux_fit']))[idx_123[sep_constraint_123]]\n",
    "    matches_123['emag_' + num_cat[num + 2]] = (1.086 * (table[num + 2]['flux_unc'] /\n",
    "                                                        table[num + 2]['flux_fit']))[idx_123[sep_constraint_123]]\n",
    "\n",
    "    idx_1234, d2d_1234, _ = match_coordinates_sky(matches_123['radec_' + num_cat[num]], table[num + 3]['radec'])\n",
    "\n",
    "    sep_constraint_1234 = d2d_1234 < max_sep\n",
    "\n",
    "    matches_1234 = Table()\n",
    "\n",
    "    matches_1234['radec_' + num_cat[num]] = matches_123['radec_' + num_cat[num]][sep_constraint_1234]\n",
    "    matches_1234['mag_' + num_cat[num]] = matches_123['mag_' + num_cat[num]][sep_constraint_1234]\n",
    "    matches_1234['emag_' + num_cat[num]] = matches_123['emag_' + num_cat[num]][sep_constraint_1234]\n",
    "    matches_1234['radec_' + num_cat[num + 1]] = matches_123['radec_' + num_cat[num + 1]][sep_constraint_1234]\n",
    "    matches_1234['mag_' + num_cat[num + 1]] = matches_123['mag_' + num_cat[num + 1]][sep_constraint_1234]\n",
    "    matches_1234['emag_' + num_cat[num + 1]] = matches_123['emag_' + num_cat[num + 1]][sep_constraint_1234]\n",
    "    matches_1234['radec_' + num_cat[num + 2]] = matches_123['radec_' + num_cat[num + 2]][sep_constraint_1234]\n",
    "    matches_1234['mag_' + num_cat[num + 2]] = matches_123['mag_' + num_cat[num + 2]][sep_constraint_1234]\n",
    "    matches_1234['emag_' + num_cat[num + 2]] = matches_123['emag_' + num_cat[num + 2]][sep_constraint_1234]\n",
    "    matches_1234['radec_' + num_cat[num + 3]] = table[num + 3]['radec'][idx_1234[sep_constraint_1234]]\n",
    "    matches_1234['mag_' + num_cat[num + 3]] = (-2.5 * np.log10(table[num + 3]['flux_fit']))[idx_1234[sep_constraint_1234]]\n",
    "    matches_1234['emag_' + num_cat[num + 3]] = (1.086 * (table[num + 3]['flux_unc'] /\n",
    "                                                         table[num + 3]['flux_fit']))[idx_1234[sep_constraint_1234]]\n",
    "\n",
    "    matches_1234\n",
    "\n",
    "    return matches_1234"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_f115w = crossmatch_filter(table=results_clean_f115w)\n",
    "matches_f200w = crossmatch_filter(table=results_clean_f200w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the final catalog, we assume that the magnitude is the mean of the 4 measures and the error on the magnitude is its standard deviation.\n",
    "\n",
    "To easily perform this arithmetic operation on the table, we convert the table to pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_f115w = matches_f115w.to_pandas()\n",
    "df_f200w = matches_f200w.to_pandas()\n",
    "\n",
    "df_f115w['RA_' + filt1] = df_f115w[['radec_1.ra', 'radec_2.ra', 'radec_3.ra', 'radec_4.ra']].mean(axis=1)\n",
    "df_f115w['e_RA_' + filt1] = df_f115w[['radec_1.ra', 'radec_2.ra', 'radec_3.ra', 'radec_4.ra']].std(axis=1)\n",
    "df_f115w['Dec_' + filt1] = df_f115w[['radec_1.dec', 'radec_2.dec', 'radec_3.dec', 'radec_4.dec']].mean(axis=1)\n",
    "df_f115w['e_Dec_' + filt1] = df_f115w[['radec_1.dec', 'radec_2.dec', 'radec_3.dec', 'radec_4.dec']].std(axis=1)\n",
    "df_f115w[filt1 + '_inst'] = df_f115w[['mag_1', 'mag_2', 'mag_3', 'mag_4']].mean(axis=1)\n",
    "df_f115w['e' + filt1 + '_inst'] = df_f115w[['mag_1', 'mag_2', 'mag_3', 'mag_4']].std(axis=1)\n",
    "\n",
    "df_f200w['RA_' + filt2] = df_f200w[['radec_1.ra', 'radec_2.ra', 'radec_3.ra', 'radec_4.ra']].mean(axis=1)\n",
    "df_f200w['e_RA_' + filt2] = df_f200w[['radec_1.ra', 'radec_2.ra', 'radec_3.ra', 'radec_4.ra']].std(axis=1)\n",
    "df_f200w['Dec_' + filt2] = df_f200w[['radec_1.dec', 'radec_2.dec', 'radec_3.dec', 'radec_4.dec']].mean(axis=1)\n",
    "df_f200w['e_Dec_' + filt2] = df_f200w[['radec_1.dec', 'radec_2.dec', 'radec_3.dec', 'radec_4.dec']].std(axis=1)\n",
    "df_f200w[filt2 + '_inst'] = df_f200w[['mag_1', 'mag_2', 'mag_3', 'mag_4']].mean(axis=1)\n",
    "df_f200w['e' + filt2 + '_inst'] = df_f200w[['mag_1', 'mag_2', 'mag_3', 'mag_4']].std(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Color-Magnitude Diagram (Instrumental Magnitudes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 14))\n",
    "plt.clf()\n",
    "\n",
    "ax1 = plt.subplot(1, 2, 1)\n",
    "\n",
    "ax1.set_xlabel(filt1 + '_inst -' + filt2 + '_inst', fontdict=font2)\n",
    "ax1.set_ylabel(filt1 + '_inst', fontdict=font2)\n",
    "\n",
    "xlim0 = -0.5\n",
    "xlim1 = 0.8\n",
    "ylim0 = -1.5\n",
    "ylim1 = -9\n",
    "\n",
    "ax1.set_xlim(xlim0, xlim1)\n",
    "ax1.set_ylim(ylim0, ylim1)\n",
    "\n",
    "ax1.xaxis.set_major_locator(ticker.AutoLocator())\n",
    "ax1.xaxis.set_minor_locator(ticker.AutoMinorLocator())\n",
    "ax1.yaxis.set_major_locator(ticker.AutoLocator())\n",
    "ax1.yaxis.set_minor_locator(ticker.AutoMinorLocator())\n",
    "\n",
    "radec_f115w_inst = SkyCoord(df_f115w['RA_' + filt1], df_f115w['Dec_' + filt1], unit='deg')\n",
    "radec_f200w_inst = SkyCoord(df_f200w['RA_' + filt2], df_f200w['Dec_' + filt2], unit='deg')\n",
    "\n",
    "idx_inst, d2d_inst, _ = match_coordinates_sky(radec_f115w_inst, radec_f200w_inst)\n",
    "\n",
    "sep_constraint_inst = d2d_inst < max_sep\n",
    "\n",
    "f115w_inst = np.array(df_f115w[filt1 + '_inst'][sep_constraint_inst])\n",
    "ef115w_inst = np.array(df_f115w['e' + filt1 + '_inst'][sep_constraint_inst])\n",
    "radec_f115w = radec_f115w_inst[sep_constraint_inst]\n",
    "\n",
    "f200w_inst = np.array(df_f200w[filt2 + '_inst'][idx_inst[sep_constraint_inst]])\n",
    "ef200w_inst = np.array(df_f200w['e' + filt2 + '_inst'][idx_inst[sep_constraint_inst]])\n",
    "radec_f200w = radec_f200w_inst[idx_inst[sep_constraint_inst]]\n",
    "\n",
    "ax1.scatter(f115w_inst - f200w_inst, f115w_inst, s=1, color='k')\n",
    "\n",
    "ax2 = plt.subplot(2, 2, 2)\n",
    "\n",
    "ax2.set_xlabel(filt1 + '_inst', fontdict=font2)\n",
    "ax2.set_ylabel('$\\sigma$' + filt1, fontdict=font2)\n",
    "\n",
    "xlim0 = -9\n",
    "xlim1 = -1.5\n",
    "ylim0 = -0.01 \n",
    "ylim1 = 1\n",
    "\n",
    "ax2.set_xlim(xlim0, xlim1)\n",
    "ax2.set_ylim(ylim0, ylim1)\n",
    "\n",
    "ax2.xaxis.set_major_locator(ticker.AutoLocator())\n",
    "ax2.xaxis.set_minor_locator(ticker.AutoMinorLocator())\n",
    "ax2.yaxis.set_major_locator(ticker.AutoLocator())\n",
    "ax2.yaxis.set_minor_locator(ticker.AutoMinorLocator())\n",
    "\n",
    "ax2.scatter(df_f115w[filt1 + '_inst'], df_f115w['e' + filt1 + '_inst'], s=1, color='k')\n",
    "\n",
    "ax3 = plt.subplot(2, 2, 4)\n",
    "\n",
    "ax3.set_xlabel(filt2 + '_inst', fontdict=font2)\n",
    "ax3.set_ylabel('$\\sigma$' + filt2, fontdict=font2)\n",
    "\n",
    "ax3.set_xlim(xlim0, xlim1)\n",
    "ax3.set_ylim(ylim0, ylim1)\n",
    "\n",
    "ax3.xaxis.set_major_locator(ticker.AutoLocator())\n",
    "ax3.xaxis.set_minor_locator(ticker.AutoMinorLocator())\n",
    "ax3.yaxis.set_major_locator(ticker.AutoLocator())\n",
    "ax3.yaxis.set_minor_locator(ticker.AutoMinorLocator())\n",
    "\n",
    "ax3.scatter(df_f200w[filt2 + '_inst'], df_f200w['e' + filt2 + '_inst'], s=1, color='k')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Photometric Zeropoints\n",
    "\n",
    "To obtain the final calibrated color-magnitude diagram, we need to calculate the photometric zeropoints. Hence we need to perform aperture photometry on the calibrated images (Level-3), apply the appropriate aperture correction for the finite aperture adopted (the values provided in the dictionary above are for an infinite aperture) and then compare it with the PSF photometry. Hence, we can summarize the steps as follows:\n",
    "\n",
    "* perform aperture photometry \n",
    "* apply appropriate aperture correction\n",
    "* apply tabulated zeropoint\n",
    "* cross-match with psf photometry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the calibrated and rectified images (Level 3 imaging pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_images_combined = {'NRCA1': {}, 'NRCA2': {}, 'NRCA3': {}, 'NRCA4': {}, 'NRCA5': {},\n",
    "                        'NRCB1': {}, 'NRCB2': {}, 'NRCB3': {}, 'NRCB4': {}, 'NRCB5': {}}\n",
    "\n",
    "dict_filter_short = {}\n",
    "dict_filter_long = {}\n",
    "\n",
    "ff_short = []\n",
    "det_short = []\n",
    "det_long = []\n",
    "ff_long = []\n",
    "detlist_short = []\n",
    "detlist_long = []\n",
    "filtlist_short = []\n",
    "filtlist_long = []\n",
    "\n",
    "if not glob.glob('./*combined*fits'):\n",
    "\n",
    "    print(\"Downloading images\")\n",
    "\n",
    "    boxlink_images_lev3 = 'https://data.science.stsci.edu/redirect/JWST/jwst-data_analysis_tools/stellar_photometry/images_level3.tar.gz'\n",
    "    boxfile_images_lev3 = './images_level3.tar.gz'\n",
    "    urllib.request.urlretrieve(boxlink_images_lev3, boxfile_images_lev3)\n",
    "\n",
    "    tar = tarfile.open(boxfile_images_lev3, 'r')\n",
    "    tar.extractall()\n",
    "\n",
    "    images_dir = './'\n",
    "    files_singles = sorted(glob.glob(os.path.join(images_dir, \"*combined*fits\")))\n",
    "\n",
    "else:\n",
    "\n",
    "    images_dir = './'\n",
    "    files_singles = sorted(glob.glob(os.path.join(images_dir, \"*combined*fits\")))\n",
    "\n",
    "for file in files_singles:\n",
    "\n",
    "    im = fits.open(file)\n",
    "    f = im[0].header['FILTER']\n",
    "    d = im[0].header['DETECTOR']\n",
    "\n",
    "    if d == 'NRCBLONG':\n",
    "        d = 'NRCB5'\n",
    "    elif d == 'NRCALONG':\n",
    "        d = 'NRCA5'\n",
    "    else:\n",
    "        d = d\n",
    "\n",
    "    wv = np.float(f[1:3])\n",
    "\n",
    "    if wv > 24:\n",
    "        ff_long.append(f)\n",
    "        det_long.append(d)\n",
    "\n",
    "    else:\n",
    "        ff_short.append(f)\n",
    "        det_short.append(d)\n",
    "\n",
    "    detlist_short = sorted(list(dict.fromkeys(det_short)))\n",
    "    detlist_long = sorted(list(dict.fromkeys(det_long)))\n",
    "\n",
    "    unique_list_filters_short = []\n",
    "    unique_list_filters_long = []\n",
    "\n",
    "    for x in ff_short:\n",
    "\n",
    "        if x not in unique_list_filters_short:\n",
    "\n",
    "            dict_filter_short.setdefault(x, {})\n",
    "\n",
    "    for x in ff_long:\n",
    "        if x not in unique_list_filters_long:\n",
    "            dict_filter_long.setdefault(x, {})\n",
    "\n",
    "    for d_s in detlist_short:\n",
    "        dict_images_combined[d_s] = dict_filter_short\n",
    "\n",
    "    for d_l in detlist_long:\n",
    "        dict_images_combined[d_l] = dict_filter_long\n",
    "\n",
    "    filtlist_short = sorted(list(dict.fromkeys(dict_filter_short)))\n",
    "    filtlist_long = sorted(list(dict.fromkeys(dict_filter_long)))\n",
    "\n",
    "    if len(dict_images_combined[d][f]) == 0:\n",
    "        dict_images_combined[d][f] = {'images': [file]}\n",
    "    else:\n",
    "        dict_images_combined[d][f]['images'].append(file)\n",
    "\n",
    "print(\"Available Detectors for SW channel:\", detlist_short)\n",
    "print(\"Available Detectors for LW channel:\", detlist_long)\n",
    "print(\"Available SW Filters:\", filtlist_short)\n",
    "print(\"Available LW Filters:\", filtlist_long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Display the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 14))\n",
    "\n",
    "for det in dets_short:\n",
    "    for i, filt in enumerate(filts_short):\n",
    "\n",
    "        image = fits.open(dict_images_combined[det][filt]['images'][0])\n",
    "        data_sb = image[1].data\n",
    "\n",
    "        ax = plt.subplot(1, len(filts_short), i + 1)\n",
    "\n",
    "        norm = simple_norm(data_sb, 'sqrt', percent=99.)\n",
    "        plt.xlabel(\"X [px]\", fontdict=font2)\n",
    "        plt.ylabel(\"Y [px]\", fontdict=font2)\n",
    "        plt.title(filt, fontdict=font2)\n",
    "\n",
    "        ax.imshow(data_sb, norm=norm, cmap='Greys')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aperture Photometry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have done previously, we create a dictionary that contains the tables with the derived aperture photometry for each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_aper = {}\n",
    "\n",
    "for det in dets_short:\n",
    "\n",
    "    dict_aper.setdefault(det, {})\n",
    "    for j, filt in enumerate(filts_short):\n",
    "\n",
    "        dict_aper[det].setdefault(filt, {})\n",
    "\n",
    "        dict_aper[det][filt]['stars for ap phot'] = None\n",
    "        dict_aper[det][filt]['stars for ap phot matched'] = None\n",
    "        dict_aper[det][filt]['aperture phot table'] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find bright isolated stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_bright_stars(det='NRCA1', filt='F070W', dist_sel=False):\n",
    "\n",
    "    bkgrms = MADStdBackgroundRMS()\n",
    "    mmm_bkg = MMMBackground()\n",
    "\n",
    "    image = fits.open(dict_images_combined[det][filt]['images'][i])\n",
    "    data_sb = image[1].data\n",
    "    imh = image[1].header\n",
    "\n",
    "    print(\"Selecting stars for aperture photometry on image {number} of filter {f}, detector {d}\".format(number=i + 1, f=filt, d=det))\n",
    "\n",
    "    data = data_sb / imh['PHOTMJSR']\n",
    "    print(\"Conversion factor from {units} to DN/s for filter {f}:\".format(units=imh['BUNIT'], f=filt), imh['PHOTMJSR'])\n",
    "\n",
    "    sigma_psf = dict_utils[filt]['psf fwhm']\n",
    "\n",
    "    print(\"FWHM for the filter {f}:\".format(f=filt), sigma_psf, \"px\")\n",
    "\n",
    "    std = bkgrms(data)\n",
    "    bkg = mmm_bkg(data)\n",
    "    daofind = DAOStarFinder(threshold=th[j] * std + bkg, fwhm=sigma_psf, roundhi=1.0, roundlo=-1.0,\n",
    "                            sharplo=0.30, sharphi=1.40)\n",
    "\n",
    "    apcorr_stars = daofind(data)\n",
    "    dict_aper[det][filt]['stars for ap phot'] = apcorr_stars\n",
    "    \n",
    "    if dist_sel:\n",
    "\n",
    "        print(\"\")\n",
    "        print(\"Calculating closest neigbhour distance\")\n",
    "\n",
    "        d = []\n",
    "\n",
    "        daofind_tot = DAOStarFinder(threshold=10 * std + bkg, fwhm=sigma_psf, roundhi=1.0, roundlo=-1.0,\n",
    "                                    sharplo=0.30, sharphi=1.40)\n",
    "\n",
    "        stars_tot = daofind_tot(data)\n",
    "\n",
    "        x_tot = stars_tot['xcentroid']\n",
    "        y_tot = stars_tot['ycentroid']\n",
    "\n",
    "        for xx, yy in zip(apcorr_stars['xcentroid'], apcorr_stars['ycentroid']):\n",
    "\n",
    "            sep = []\n",
    "            dist = np.sqrt((x_tot - xx)**2 + (y_tot - yy)**2)\n",
    "            sep = np.sort(dist)[1:2][0]\n",
    "            d.append(sep)\n",
    "\n",
    "        apcorr_stars['min distance'] = d\n",
    "        mask_dist = (apcorr_stars['min distance'] > min_sep[j])\n",
    "\n",
    "        apcorr_stars = apcorr_stars[mask_dist]\n",
    "\n",
    "        dict_aper[det][filt]['stars for ap phot'] = apcorr_stars\n",
    "\n",
    "        print(\"Minimum distance required:\", min_sep[j], \"px\")\n",
    "        print(\"\")\n",
    "        print(\"Number of bright isolated sources found in the image for {f}:\".format(f=filt), len(apcorr_stars))\n",
    "        print(\"-----------------------------------------------------\")\n",
    "        print(\"\")\n",
    "    else:\n",
    "        print(\"\")\n",
    "        print(\"Number of bright sources found in the image for {f}:\".format(f=filt), len(apcorr_stars))\n",
    "        print(\"--------------------------------------------\")\n",
    "        print(\"\")    \n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.perf_counter()\n",
    "\n",
    "th = [700, 500]  # threshold level for the two filters (length must match number of filters analyzed)\n",
    "min_sep = [10, 10]  # minimum separation acceptable for zp stars from closest neighbour\n",
    "\n",
    "\n",
    "for det in dets_short:\n",
    "    for j, filt in enumerate(filts_short):\n",
    "        for i in np.arange(0, len(dict_images_combined[det][filt]['images']), 1):\n",
    "\n",
    "            find_bright_stars(det=det, filt=filt, dist_sel=False)\n",
    "\n",
    "toc = time.perf_counter()\n",
    "\n",
    "print(\"Elapsed Time for finding stars for Aperture Photometry:\", toc - tic)            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a further way to obtain a good quality sample, we cross-match the catalogs from the two filters and retain only the stars in common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for det in dets_short:\n",
    "    for j, filt in enumerate(filts_short):\n",
    "        for i in np.arange(0, len(dict_images_combined[det][filt]['images']), 1):\n",
    "\n",
    "            image = ImageModel(dict_images_combined[det][filt]['images'][i])\n",
    "\n",
    "            ra, dec = image.meta.wcs(dict_aper[det][filt]['stars for ap phot']['xcentroid'],\n",
    "                                     dict_aper[det][filt]['stars for ap phot']['ycentroid'])\n",
    "        \n",
    "            radec = SkyCoord(ra, dec, unit='deg')\n",
    "            dict_aper[det][filt]['stars for ap phot']['radec'] = radec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_ap, d2d_ap, _ = match_coordinates_sky(dict_aper[det][filt1]['stars for ap phot']['radec'],\n",
    "                                          dict_aper[det][filt2]['stars for ap phot']['radec'])\n",
    "\n",
    "sep_constraint_ap = d2d_ap < max_sep\n",
    "\n",
    "matched_apcorr_f115w = Table()\n",
    "matched_apcorr_f200w = Table()\n",
    "\n",
    "matched_apcorr_f115w = dict_aper[det][filt1]['stars for ap phot'][sep_constraint_ap]\n",
    "matched_apcorr_f200w = dict_aper[det][filt2]['stars for ap phot'][idx_ap[sep_constraint_ap]]\n",
    "\n",
    "dict_aper[det][filt1]['stars for ap phot matched'] = matched_apcorr_f115w\n",
    "dict_aper[det][filt2]['stars for ap phot matched'] = matched_apcorr_f200w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load aperture correction table\n",
    "\n",
    "**Note**: these values are obtained from the study of the synthetic WebbPSF PSFs. They will be updated once we have in-flight measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile('./aperture_correction_table.txt'):\n",
    "    ap_tab = './aperture_correction_table.txt'\n",
    "else:\n",
    "    print(\"Downloading the aperture correction table\")\n",
    "\n",
    "    boxlink_apcorr_table = 'https://data.science.stsci.edu/redirect/JWST/jwst-data_analysis_tools/stellar_photometry/aperture_correction_table.txt'\n",
    "    boxfile_apcorr_table = './aperture_correction_table.txt'\n",
    "    urllib.request.urlretrieve(boxlink_apcorr_table, boxfile_apcorr_table)\n",
    "    ap_tab = './aperture_correction_table.txt'\n",
    "\n",
    "aper_table = pd.read_csv(ap_tab, header=None, sep='\\s+', index_col=0,\n",
    "                         names=['filter', 'pupil', 'wave', 'r10', 'r20', 'r30', 'r40', 'r50', 'r60', 'r70', 'r80',\n",
    "                                'r85', 'r90', 'sky_flux_px', 'apcorr10', 'apcorr20', 'apcorr30', 'apcorr40',\n",
    "                                'apcorr50', 'apcorr60', 'apcorr70', 'apcorr80', 'apcorr85', 'apcorr90', 'sky_in',\n",
    "                                'sky_out'], comment='#', skiprows=0, usecols=range(0, 26))\n",
    "aper_table.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform Aperture Photometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aperture_phot(det=det, filt='F070W'):\n",
    "\n",
    "    radii = [aper_table.loc[filt]['r70']]\n",
    "\n",
    "    ees = '70'.split()\n",
    "    ee_radii = dict(zip(ees, radii))\n",
    "\n",
    "    positions = np.transpose((dict_aper[det][filt]['stars for ap phot matched']['xcentroid'],\n",
    "                              dict_aper[det][filt]['stars for ap phot matched']['ycentroid']))\n",
    "\n",
    "    image = fits.open(dict_images_combined[det][filt]['images'][0])\n",
    "    data_sb = image[1].data\n",
    "    imh = image[1].header\n",
    "    data = data_sb / imh['PHOTMJSR']\n",
    "\n",
    "    # sky from the aperture correction table:\n",
    "\n",
    "    sky = {\"sky_in\": aper_table.loc[filt]['r80'], \"sky_out\": aper_table.loc[filt]['r85']}\n",
    "\n",
    "    tic = time.perf_counter()\n",
    "\n",
    "    table_aper = Table()\n",
    "\n",
    "    for ee, radius in ee_radii.items():\n",
    "        print(\"Performing aperture photometry for radius equivalent to EE = {0}% for filter {1}\".format(ee, filt))\n",
    "        aperture = CircularAperture(positions, r=radius)\n",
    "        annulus_aperture = CircularAnnulus(positions, r_in=sky[\"sky_in\"], r_out=sky[\"sky_out\"])\n",
    "        annulus_mask = annulus_aperture.to_mask(method='center')\n",
    "\n",
    "        bkg_median = []\n",
    "        for mask in annulus_mask:\n",
    "            annulus_data = mask.multiply(data)\n",
    "            annulus_data_1d = annulus_data[mask.data > 0]\n",
    "            _, median_sigclip, _ = sigma_clipped_stats(annulus_data_1d)\n",
    "            bkg_median.append(median_sigclip)\n",
    "        bkg_median = np.array(bkg_median)\n",
    "\n",
    "        phot = aperture_photometry(data, aperture, method='exact')\n",
    "        phot['annulus_median'] = bkg_median\n",
    "        phot['aper_bkg'] = bkg_median * aperture.area\n",
    "        phot['aper_sum_bkgsub'] = phot['aperture_sum'] - phot['aper_bkg']\n",
    "\n",
    "        apcorr = [aper_table.loc[filt]['apcorr70']]\n",
    "\n",
    "        phot['aper_sum_corrected'] = phot['aper_sum_bkgsub'] * apcorr\n",
    "\n",
    "        phot['mag_corrected'] = -2.5 * np.log10(phot['aper_sum_corrected']) + dict_utils[filt]['VegaMAG zp modB']\n",
    "\n",
    "        table_aper.add_column(phot['aperture_sum'], name='aper_sum_' + ee)\n",
    "        table_aper.add_column(phot['annulus_median'], name='annulus_median_' + ee)\n",
    "        table_aper.add_column(phot['aper_bkg'], name='aper_bkg_ee_' + ee)\n",
    "        table_aper.add_column(phot['aper_sum_bkgsub'], name='aper_sum_bkgsub_' + ee)\n",
    "        table_aper.add_column(phot['aper_sum_corrected'], name='aper_sum_corrected_' + filt) \n",
    "        table_aper.add_column(phot['mag_corrected'], name='mag_corrected_' + filt)\n",
    "\n",
    "        dict_aper[det][filt]['aperture phot table'] = table_aper\n",
    "\n",
    "    toc = time.perf_counter()\n",
    "    print(\"Time Elapsed:\", toc - tic)\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aperture_phot(det=det, filt=filt1)\n",
    "aperture_phot(det=det, filt=filt2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Derive Zeropoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 8))\n",
    "plt.clf()\n",
    "\n",
    "ax1 = plt.subplot(2, 1, 1)\n",
    "\n",
    "ax1.set_xlabel(filt1, fontdict=font2)\n",
    "ax1.set_ylabel('Zeropoint', fontdict=font2)\n",
    "\n",
    "idx_zp_1, d2d_zp_1, _ = match_coordinates_sky(dict_aper[det][filt1]['stars for ap phot matched']['radec'], radec_f115w_inst)\n",
    "\n",
    "sep_constraint_zp_1 = d2d_zp_1 < max_sep\n",
    "\n",
    "f115w_ap_matched = np.array(dict_aper[det][filt1]['aperture phot table']['mag_corrected_' + filt1][sep_constraint_zp_1])\n",
    "f115w_psf_matched = np.array(df_f115w[filt1 + '_inst'][idx_zp_1[sep_constraint_zp_1]])\n",
    "\n",
    "diff_f115w = f115w_ap_matched - f115w_psf_matched\n",
    "_, zp_f115w, zp_sigma_f115w = sigma_clipped_stats(diff_f115w)\n",
    "\n",
    "xlim0 = -9\n",
    "xlim1 = -5\n",
    "ylim0 = np.mean(diff_f115w) - 0.5\n",
    "ylim1 = np.mean(diff_f115w) + 0.5\n",
    "\n",
    "ax1.set_xlim(xlim0, xlim1)\n",
    "ax1.set_ylim(ylim0, ylim1)\n",
    "\n",
    "ax1.xaxis.set_major_locator(ticker.AutoLocator())\n",
    "ax1.xaxis.set_minor_locator(ticker.AutoMinorLocator())\n",
    "ax1.yaxis.set_major_locator(ticker.AutoLocator())\n",
    "ax1.yaxis.set_minor_locator(ticker.AutoMinorLocator())\n",
    "\n",
    "ax1.scatter(f115w_psf_matched, diff_f115w, s=50, color='k')\n",
    "ax1.plot([xlim0, xlim1], [zp_f115w, zp_f115w], color='r', lw=5, ls='--')\n",
    "ax1.text(xlim0 + 0.05, ylim1 - 0.15, filt1 + ' Zeropoint = %5.3f $\\pm$ %5.3f' % (zp_f115w, zp_sigma_f115w), color='k', fontdict=font2)\n",
    "                \n",
    "ax2 = plt.subplot(2, 1, 2)\n",
    "\n",
    "ax2.set_xlabel(filt2, fontdict=font2)\n",
    "ax2.set_ylabel('Zeropoint', fontdict=font2)\n",
    "\n",
    "idx_zp_2, d2d_zp_2, _ = match_coordinates_sky(dict_aper[det][filt2]['stars for ap phot matched']['radec'], radec_f200w_inst)\n",
    "\n",
    "sep_constraint_zp_2 = d2d_zp_2 < max_sep\n",
    "\n",
    "f200w_ap_matched = np.array(dict_aper[det][filt2]['aperture phot table']['mag_corrected_' + filt2][sep_constraint_zp_2])\n",
    "f200w_psf_matched = np.array(df_f200w[filt2 + '_inst'][idx_zp_2[sep_constraint_zp_2]])\n",
    "\n",
    "diff_f200w = f200w_ap_matched - f200w_psf_matched\n",
    "_, zp_f200w, zp_sigma_f200w = sigma_clipped_stats(diff_f200w)\n",
    "\n",
    "xlim0 = -9\n",
    "xlim1 = -5\n",
    "ylim0 = np.mean(diff_f200w) - 0.5\n",
    "ylim1 = np.mean(diff_f200w) + 0.5\n",
    "\n",
    "ax2.set_xlim(xlim0, xlim1)\n",
    "ax2.set_ylim(ylim0, ylim1)\n",
    "\n",
    "ax2.xaxis.set_major_locator(ticker.AutoLocator())\n",
    "ax2.xaxis.set_minor_locator(ticker.AutoMinorLocator())\n",
    "ax2.yaxis.set_major_locator(ticker.AutoLocator())\n",
    "ax2.yaxis.set_minor_locator(ticker.AutoMinorLocator())\n",
    "\n",
    "ax2.scatter(f200w_psf_matched, diff_f200w, s=50, color='k')\n",
    "ax2.plot([xlim0, xlim1], [zp_f200w, zp_f200w], color='r', lw=5, ls='--')\n",
    "ax2.text(xlim0 + 0.05, ylim1 - 0.15, filt2 + ' Zeropoint = %5.3f $\\pm$ %5.3f' % (zp_f200w, zp_sigma_f200w), color='k', fontdict=font2)\n",
    "                \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import input photometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile('./pointsource.cat'):\n",
    "    input_cat = './pointsource.cat'\n",
    "\n",
    "else:\n",
    "    \n",
    "    print(\"Downloading input pointsource catalog\")\n",
    "\n",
    "    boxlink_input_cat = 'https://data.science.stsci.edu/redirect/JWST/jwst-data_analysis_tools/stellar_photometry/pointsource.cat'\n",
    "    boxfile_input_cat = './pointsource.cat'\n",
    "    urllib.request.urlretrieve(boxlink_input_cat, boxfile_input_cat)\n",
    "    input_cat = './pointsource.cat'\n",
    "\n",
    "cat = pd.read_csv(input_cat, header=None, sep='\\s+', names=['ra_in', 'dec_in', 'f070w_in', 'f115w_in',\n",
    "                                                            'f200w_in', 'f277w_in', 'f356w_in', 'f444w_in'],\n",
    "                  comment='#', skiprows=7, usecols=range(0, 8))\n",
    "\n",
    "cat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract from the input catalog the stars in the same region as the one analyzed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lim_ra_min = np.min(radec_f115w.ra)\n",
    "lim_ra_max = np.max(radec_f115w.ra)\n",
    "lim_dec_min = np.min(radec_f115w.dec)\n",
    "lim_dec_max = np.max(radec_f115w.dec)\n",
    "\n",
    "cat_sel = cat[(cat['ra_in'] > lim_ra_min) & (cat['ra_in'] < lim_ra_max) & (cat['dec_in'] > lim_dec_min)\n",
    "              & (cat['dec_in'] < lim_dec_max)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calibrated Color-Magnitude Diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 14))\n",
    "plt.clf()\n",
    "\n",
    "ax1 = plt.subplot(1, 2, 1)\n",
    "\n",
    "mag1_in = np.array(cat_sel['f115w_in'])\n",
    "mag2_in = np.array(cat_sel['f200w_in'])\n",
    "diff_in = mag1_in - mag2_in\n",
    "\n",
    "xlim0 = -0.25\n",
    "xlim1 = 1.75\n",
    "ylim0 = 25\n",
    "ylim1 = 15 \n",
    "ax1.set_xlim(xlim0, xlim1)\n",
    "ax1.set_ylim(ylim0, ylim1)\n",
    "\n",
    "ax1.xaxis.set_major_locator(ticker.AutoLocator())\n",
    "ax1.xaxis.set_minor_locator(ticker.AutoMinorLocator())\n",
    "ax1.yaxis.set_major_locator(ticker.AutoLocator())\n",
    "ax1.yaxis.set_minor_locator(ticker.AutoMinorLocator())\n",
    "\n",
    "ax1.scatter(mag1_in - mag2_in, mag1_in, s=1, color='k')\n",
    "\n",
    "ax1.set_xlabel(filt1 + ' - ' + filt2, fontdict=font2)\n",
    "ax1.set_ylabel(filt1, fontdict=font2)\n",
    "ax1.text(xlim0 + 0.15, 15.5, \"Input\", fontdict=font2)\n",
    "\n",
    "ax2 = plt.subplot(1, 2, 2)\n",
    "\n",
    "ax2.set_xlim(xlim0, xlim1)\n",
    "ax2.set_ylim(ylim0, ylim1)\n",
    "\n",
    "ax2.xaxis.set_major_locator(ticker.AutoLocator())\n",
    "ax2.xaxis.set_minor_locator(ticker.AutoMinorLocator())\n",
    "ax2.yaxis.set_major_locator(ticker.AutoLocator())\n",
    "ax2.yaxis.set_minor_locator(ticker.AutoMinorLocator())\n",
    "\n",
    "f115w = f115w_inst + zp_f115w \n",
    "f200w = f200w_inst + zp_f200w\n",
    "\n",
    "maglim = np.arange(18, 25, 1)\n",
    "mags = []\n",
    "errs_mag = []\n",
    "errs_col = []\n",
    "\n",
    "for i in np.arange(0, len(maglim) - 1, 1):\n",
    "\n",
    "    mag = (maglim[i] + maglim[i + 1]) / 2\n",
    "    err_mag1 = ef115w_inst[(f115w > maglim[i]) & (f115w < maglim[i + 1])]\n",
    "    err_mag2 = ef200w_inst[(f115w > maglim[i]) & (f115w < maglim[i + 1])]\n",
    "    err_mag = np.mean(err_mag1[i])\n",
    "    err_temp = np.sqrt(err_mag1**2 + err_mag2**2)\n",
    "    err_col = np.mean(err_temp[i])\n",
    "\n",
    "    errs_mag.append(err_mag)                  \n",
    "    errs_col.append(err_col)\n",
    "    mags.append(mag)\n",
    "\n",
    "col = [0] * (len(maglim) - 1)\n",
    "\n",
    "ax2.errorbar(col, mags, yerr=errs_mag, xerr=errs_col, fmt='o', color='k')\n",
    "        \n",
    "ax2.scatter(f115w - f200w, f115w, s=1, color='k')\n",
    "ax2.text(xlim0 + 0.15, 15.5, \"Output\", fontdict=font2)\n",
    "\n",
    "ax2.set_xlabel(filt1 + ' - ' + filt2, fontdict=font2)\n",
    "ax2.set_ylabel(filt1, fontdict=font2)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison between input and output photometry "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 8))\n",
    "plt.clf()\n",
    "\n",
    "ax1 = plt.subplot(2, 1, 1)\n",
    "\n",
    "ax1.set_xlabel(filt1, fontdict=font2)\n",
    "ax1.set_ylabel('$\\Delta$ Mag', fontdict=font2)\n",
    "\n",
    "radec_input = SkyCoord(cat_sel['ra_in'], cat_sel['dec_in'], unit='deg')\n",
    "\n",
    "idx_f115w_cfr, d2d_f115w_cfr, _ = match_coordinates_sky(radec_input, radec_f115w)\n",
    "\n",
    "sep_f115w_cfr = d2d_f115w_cfr < max_sep\n",
    "\n",
    "f115w_inp_cfr = np.array(cat_sel['f115w_in'][sep_f115w_cfr])\n",
    "f115w_psf_cfr = np.array(f115w[idx_f115w_cfr[sep_f115w_cfr]])\n",
    "\n",
    "diff_f115w_cfr = f115w_inp_cfr - f115w_psf_cfr\n",
    "_, med_diff_f115w_cfr, sig_diff_f115w_cfr = sigma_clipped_stats(diff_f115w_cfr)\n",
    "\n",
    "xlim0 = 16\n",
    "xlim1 = 24.5\n",
    "ylim0 = np.mean(diff_f115w_cfr) - 0.5\n",
    "ylim1 = np.mean(diff_f115w_cfr) + 0.5\n",
    "\n",
    "ax1.set_xlim(xlim0, xlim1)\n",
    "ax1.set_ylim(ylim0, ylim1)\n",
    "\n",
    "ax1.xaxis.set_major_locator(ticker.AutoLocator())\n",
    "ax1.xaxis.set_minor_locator(ticker.AutoMinorLocator())\n",
    "ax1.yaxis.set_major_locator(ticker.AutoLocator())\n",
    "ax1.yaxis.set_minor_locator(ticker.AutoMinorLocator())\n",
    "\n",
    "ax1.scatter(f115w_psf_cfr, diff_f115w_cfr, s=5, color='k')\n",
    "ax1.plot([xlim0, xlim1], [0, 0], color='r', lw=5, ls='--')\n",
    "ax1.text(xlim0 + 0.05, ylim1 - 0.15, filt1 + ' $\\Delta$ Mag = %5.3f $\\pm$ %5.3f'\n",
    "         % (med_diff_f115w_cfr, sig_diff_f115w_cfr), color='k', fontdict=font2)\n",
    "\n",
    "ax2 = plt.subplot(2, 1, 2)\n",
    "\n",
    "ax2.set_xlabel(filt2, fontdict=font2)\n",
    "ax2.set_ylabel('$\\Delta$ Mag', fontdict=font2)\n",
    "\n",
    "idx_f200w_cfr, d2d_f200w_cfr, _ = match_coordinates_sky(radec_input, radec_f200w)\n",
    "\n",
    "sep_f200w_cfr = d2d_f200w_cfr < max_sep\n",
    "\n",
    "f200w_inp_cfr = np.array(cat_sel['f200w_in'][sep_f200w_cfr])\n",
    "f200w_psf_cfr = np.array(f200w[idx_f200w_cfr[sep_f200w_cfr]])\n",
    "\n",
    "diff_f200w_cfr = f200w_inp_cfr - f200w_psf_cfr\n",
    "_, med_diff_f200w_cfr, sig_diff_f200w_cfr = sigma_clipped_stats(diff_f200w_cfr)\n",
    "\n",
    "xlim0 = 16\n",
    "xlim1 = 24\n",
    "ylim0 = np.mean(diff_f200w_cfr) - 0.5 \n",
    "ylim1 = np.mean(diff_f200w_cfr) + 0.5\n",
    "\n",
    "ax2.set_xlim(xlim0, xlim1)\n",
    "ax2.set_ylim(ylim0, ylim1)\n",
    "\n",
    "ax2.xaxis.set_major_locator(ticker.AutoLocator())\n",
    "ax2.xaxis.set_minor_locator(ticker.AutoMinorLocator())\n",
    "ax2.yaxis.set_major_locator(ticker.AutoLocator())\n",
    "ax2.yaxis.set_minor_locator(ticker.AutoMinorLocator())\n",
    "\n",
    "ax2.scatter(f200w_psf_cfr, diff_f200w_cfr, s=5, color='k')\n",
    "ax2.plot([xlim0, xlim1], [0, 0], color='r', lw=5, ls='--')\n",
    "ax2.text(xlim0 + 0.05, ylim1 - 0.15, filt2 + ' $\\Delta$ Mag = %5.3f $\\pm$ %5.3f'\n",
    "         % (med_diff_f200w_cfr, sig_diff_f200w_cfr), color='k', fontdict=font2)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "ax1 = plt.subplot(1, 2, 1)\n",
    "\n",
    "xlim0 = -10\n",
    "xlim1 = 10\n",
    "ylim0 = -10\n",
    "ylim1 = 10\n",
    "\n",
    "ax1.set_xlim(xlim0, xlim1)\n",
    "ax1.set_ylim(ylim0, ylim1)\n",
    "\n",
    "ax1.xaxis.set_major_locator(ticker.AutoLocator())\n",
    "ax1.xaxis.set_minor_locator(ticker.AutoMinorLocator())\n",
    "ax1.yaxis.set_major_locator(ticker.AutoLocator())\n",
    "ax1.yaxis.set_minor_locator(ticker.AutoMinorLocator())\n",
    "\n",
    "ax1.set_xlabel('$\\Delta$ RA (mas)', fontdict=font2)\n",
    "ax1.set_ylabel('$\\Delta$ Dec (mas)', fontdict=font2)\n",
    "ax1.set_title(filt1, fontdict=font2)\n",
    "\n",
    "ra_f115w_inp_cfr = np.array(cat_sel['ra_in'][sep_f115w_cfr])\n",
    "ra_f115w_psf_cfr = np.array(radec_f115w.ra[idx_f115w_cfr[sep_f115w_cfr]])\n",
    "\n",
    "dec_f115w_inp_cfr = np.array(cat_sel['dec_in'][sep_f115w_cfr])\n",
    "dec_f115w_psf_cfr = np.array(radec_f115w.dec[idx_f115w_cfr[sep_f115w_cfr]])\n",
    "\n",
    "dec_rad_f115w = np.radians(dec_f115w_psf_cfr)\n",
    "\n",
    "diffra_f115w_cfr = ((((ra_f115w_inp_cfr - ra_f115w_psf_cfr) * np.cos(dec_rad_f115w)) * u.deg).to(u.mas) / (1 * u.mas))\n",
    "\n",
    "_, med_diffra_f115w_cfr, sig_diffra_f115w_cfr = sigma_clipped_stats(diffra_f115w_cfr)\n",
    "\n",
    "diffdec_f115w_cfr = (((dec_f115w_inp_cfr - dec_f115w_psf_cfr) * u.deg).to(u.mas) / (1 * u.mas))\n",
    "\n",
    "_, med_diffdec_f115w_cfr, sig_diffdec_f115w_cfr = sigma_clipped_stats(diffdec_f115w_cfr)\n",
    "\n",
    "ax1.scatter(diffra_f115w_cfr, diffdec_f115w_cfr, s=1, color='k')\n",
    "ax1.plot([0, 0], [ylim0, ylim1], color='k', lw=2, ls='--')\n",
    "ax1.plot([xlim0, xlim1], [0, 0], color='k', lw=2, ls='--')\n",
    "\n",
    "ax1.text(xlim0 + 0.05, ylim1 - 1.50, ' $\\Delta$ RA (mas) = %5.3f $\\pm$ %5.3f'\n",
    "         % (med_diffra_f115w_cfr, sig_diffra_f115w_cfr), color='k', fontdict=font2)\n",
    "ax1.text(xlim0 + 0.05, ylim1 - 3.0, ' $\\Delta$ Dec (mas) = %5.3f $\\pm$ %5.3f'\n",
    "         % (med_diffdec_f115w_cfr, sig_diffdec_f115w_cfr), color='k', fontdict=font2)\n",
    "\n",
    "ax2 = plt.subplot(1, 2, 2)\n",
    "\n",
    "xlim0 = -10\n",
    "xlim1 = 10\n",
    "ylim0 = -10\n",
    "ylim1 = 10\n",
    "\n",
    "ax2.set_xlim(xlim0, xlim1)\n",
    "ax2.set_ylim(ylim0, ylim1)\n",
    "ax2.set_title(filt2, fontdict=font2)\n",
    "\n",
    "ax2.xaxis.set_major_locator(ticker.AutoLocator())\n",
    "ax2.xaxis.set_minor_locator(ticker.AutoMinorLocator())\n",
    "ax2.yaxis.set_major_locator(ticker.AutoLocator())\n",
    "ax2.yaxis.set_minor_locator(ticker.AutoMinorLocator())\n",
    "\n",
    "ax2.set_xlabel('$\\Delta$ RA (mas)', fontdict=font2)\n",
    "ax2.set_ylabel('$\\Delta$ Dec (mas)', fontdict=font2)\n",
    "\n",
    "ra_f200w_inp_cfr = np.array(cat_sel['ra_in'][sep_f200w_cfr])\n",
    "ra_f200w_psf_cfr = np.array(radec_f200w.ra[idx_f200w_cfr[sep_f200w_cfr]])\n",
    "\n",
    "dec_f200w_inp_cfr = np.array(cat_sel['dec_in'][sep_f200w_cfr])\n",
    "dec_f200w_psf_cfr = np.array(radec_f200w.dec[idx_f200w_cfr[sep_f200w_cfr]])\n",
    "\n",
    "dec_rad_f200w = np.radians(dec_f200w_psf_cfr)\n",
    "\n",
    "diffra_f200w_cfr = ((((ra_f200w_inp_cfr - ra_f200w_psf_cfr) * np.cos(dec_rad_f200w)) * u.deg).to(u.mas) / (1 * u.mas))\n",
    "\n",
    "_, med_diffra_f200w_cfr, sig_diffra_f200w_cfr = sigma_clipped_stats(diffra_f200w_cfr)\n",
    "\n",
    "diffdec_f200w_cfr = (((dec_f200w_inp_cfr - dec_f200w_psf_cfr) * u.deg).to(u.mas) / (1 * u.mas))\n",
    "\n",
    "_, med_diffdec_f200w_cfr, sig_diffdec_f200w_cfr = sigma_clipped_stats(diffdec_f200w_cfr)\n",
    "\n",
    "ax2.scatter(diffra_f200w_cfr, diffdec_f200w_cfr, s=1, color='k')\n",
    "ax2.plot([0, 0], [ylim0, ylim1], color='k', lw=2, ls='--')\n",
    "ax2.plot([xlim0, xlim1], [0, 0], color='k', lw=2, ls='--')\n",
    "\n",
    "ax2.text(xlim0 + 0.05, ylim1 - 1.50, ' $\\Delta$ RA (mas) = %5.3f $\\pm$ %5.3f'\n",
    "         % (med_diffra_f200w_cfr, sig_diffra_f200w_cfr), color='k', fontdict=font2)\n",
    "ax2.text(xlim0 + 0.05, ylim1 - 3.0, ' $\\Delta$ Dec (mas) = %5.3f $\\pm$ %5.3f'\n",
    "         % (med_diffdec_f200w_cfr, sig_diffdec_f200w_cfr), color='k', fontdict=font2)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final notes\n",
    "\n",
    "This notebook provides a general overview on how to perform PSF photometry using the [PhotUtils](https://photutils.readthedocs.io/en/stable/) package. The choice of the different parameters adopted in all the reduction steps as well as the choice of the PSF model depend on the specific user science case. Moreover, a detailed analysis that allow to provide recommendations on how to set those parameters and outline the differences in the output photometry when different PSF models are adopted (single vs PSF grid, number of PSFs in the grid, etc.) will be possible only when real data will be available after the instrument commissioning. In this context, we note that one of the selected ERS program (ERS 1334 - The Resolved Stellar Populations Early Release Science Program) will provide a fundamental test benchmark to explore how the different choices outlined above will impact the quality of the PSF photometry in a crowded stellar region."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About this Notebook\n",
    "\n",
    "**Author**: Matteo Correnti, JWST/NIRCam STScI Scientist II \\\n",
    "**Updated on**: 2021-01-15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top of Page](#top)\n",
    "\n",
    "<img style=\"float: right;\" src=\"https://raw.githubusercontent.com/spacetelescope/notebooks/master/assets/stsci_pri_combo_mark_horizonal_white_bkgd.png\" alt=\"Space Telescope Logo\" width=\"200px\"/>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
